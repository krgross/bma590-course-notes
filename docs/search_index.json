[["maximum-likelihood-estimation.html", "Computing companion for BMA / ST 590, Fall 2021 Chapter 1 Maximum likelihood estimation 1.1 A very simple example with a single observation 1.2 Horse-kick data 1.3 Myxomatosis data 1.4 Tadpole data", " Computing companion for BMA / ST 590, Fall 2021 Kevin Gross 2021-09-13 Chapter 1 Maximum likelihood estimation 1.1 A very simple example with a single observation Suppose we observe a single observation from a Poisson distribution. Suppose that observation is \\(X=2\\). We can use the dpois function to evaluate the likelihood for this single observation. For example, we can evaluate the likelihood at \\(\\lambda = 1.5\\): dpois(x = 2, lambda = 1.5) ## [1] 0.2510214 Or we could evaluate the likelihood at \\(\\lambda = 2\\) or \\(\\lambda = 2.5\\): dpois(x = 2, lambda = c(2, 2.5)) ## [1] 0.2706706 0.2565156 Now lets evaluate the likelihood at a sequence of \\(\\lambda\\) values: lambda.vals &lt;- seq(from = 0, to = 5, by = 0.01) my.lhood &lt;- dpois(x = 2, lambda = lambda.vals) plot(lambda.vals, my.lhood, xlab = expression(lambda), ylab = &quot;Likelihood&quot;, type = &quot;l&quot;) We might guess that the likelihood is maximized at \\(\\lambda = 2\\). Wed be right. plot(lambda.vals, my.lhood, xlab = expression(lambda), ylab = &quot;Likelihood&quot;, type = &quot;l&quot;) abline(v = 2, col = &quot;red&quot;) 1.2 Horse-kick data Most real data sets contain more than a single observation. Here is a data set that we can use to illustrate maximum likelihood estimation with a single parameter. Famously, Ladislaus van Bortkewitsch (1868 - 1931) published how many members of the Prussiam army were killed by horse kicks in each of 20 years, for each of 14 army corps. As a caveat, these data are often used to illustrate the Poisson distribution, as we will use them. They match the Poisson distribution more neatly than we might expect for most data sets. First import the data. Note that the path name used here is specific to the file directory that was used to create this file. The path name that you use will likely differ. horse &lt;- read.table(&quot;data/horse.txt&quot;, header = TRUE) Ask for a summary of the data to make sure the data have been imported correctly. summary(horse) ## year corps deaths ## Min. :1875 Length:280 Min. :0.0 ## 1st Qu.:1880 Class :character 1st Qu.:0.0 ## Median :1884 Mode :character Median :0.0 ## Mean :1884 Mean :0.7 ## 3rd Qu.:1889 3rd Qu.:1.0 ## Max. :1894 Max. :4.0 We can also learn about the data by asking to see the first few records using the head command head(horse) ## year corps deaths ## 1 1875 GC 0 ## 2 1876 GC 2 ## 3 1877 GC 2 ## 4 1878 GC 1 ## 5 1879 GC 0 ## 6 1880 GC 0 or we can see the last few records using the tail command: tail(horse) ## year corps deaths ## 275 1889 C15 2 ## 276 1890 C15 2 ## 277 1891 C15 0 ## 278 1892 C15 0 ## 279 1893 C15 0 ## 280 1894 C15 0 Another useful function to keep in mind is the `str function which tells you about the [str]ucture of an R object: str(horse) ## &#39;data.frame&#39;: 280 obs. of 3 variables: ## $ year : int 1875 1876 1877 1878 1879 1880 1881 1882 1883 1884 ... ## $ corps : chr &quot;GC&quot; &quot;GC&quot; &quot;GC&quot; &quot;GC&quot; ... ## $ deaths: int 0 2 2 1 0 0 1 1 0 3 ... Lets plot a histogram of the values: hist(horse$deaths, breaks = seq(from = min(horse$deaths) - 0.5, to = max(horse$deaths) + 0.5, by = 1)) 1.2.1 Calculate and plot the log-likelihood function Create a function that calculates the log-likelihood for a value of \\(\\lambda\\): horse.ll &lt;- function(my.lambda){ ll.vals &lt;- dpois(x = horse$deaths, lambda = my.lambda, log = TRUE) sum(ll.vals) } We can use this function to calculate the log-likelihood for any value of \\(\\lambda\\), such as \\(\\lambda = 1\\): horse.ll(1) ## [1] -328.2462 Lets calculate the log-likelihood for many values of \\(\\lambda\\), in preparation for making a plot. Well use a loop here, and not worry about vectorization. # create a vector of lambda values using the &#39;seq&#39;uence command lambda.vals &lt;- seq(from = 0.01, to = 2.0, by = 0.01) # create an empty vector to store the values of the log-likelihood ll.vals &lt;- double(length = length(lambda.vals)) # use a loop to find the log-likelihood for each value in lambda.vals for (i.lambda in 1:length(lambda.vals)) { ll.vals[i.lambda] &lt;- horse.ll(lambda.vals[i.lambda]) } Now plot the log-likelihood values vs. the values of \\(\\lambda\\): plot(ll.vals ~ lambda.vals, xlab = &quot;lambda&quot;, ylab = &quot;log likelihood&quot;, type = &quot;l&quot;) abline(v = 0.7, col = &quot;red&quot;) 1.2.2 Find the MLE numerically using optimize Bolkers book illustrates numerical optimization using the optim function. The R documentation recommends using optimize for one-dimensional optimization, and optim for optimizing a function in several dimensions. So, we will use optimize here. We will enclose the entire call to optimize in parentheses so that the output is dumped to the command line in addition to being stored as horse.mle. (horse.mle &lt;- optimize(f = horse.ll, interval = c(0.1, 2), maximum = TRUE)) ## $maximum ## [1] 0.7000088 ## ## $objective ## [1] -314.1545 The optimize function returns a list. A list is an R object that contains components of different types. The numerically calculated MLE is \\(\\hat{\\lambda} \\approx 0.7\\). The objective component of gives the value of the log-likelihood at that point. 1.3 Myxomatosis data The myxomatosis data are in Bolkers library emdbook. First load the library. If the library is not found, you will first have to download and install the library on your computer, using the Packages tab in RStudio. The call to data loads the particular myxomatosis data set that we want into memory. library(emdbook) data(MyxoTiter_sum) Inspect the data to make sure they have been imported correctly. summary(MyxoTiter_sum) ## grade day titer ## Min. :1.000 Min. : 2.000 Min. :1.958 ## 1st Qu.:3.000 1st Qu.: 4.000 1st Qu.:5.400 ## Median :4.000 Median : 8.000 Median :6.612 ## Mean :3.604 Mean : 9.564 Mean :6.331 ## 3rd Qu.:5.000 3rd Qu.:13.000 3rd Qu.:7.489 ## Max. :5.000 Max. :28.000 Max. :9.021 head(MyxoTiter_sum) ## grade day titer ## 1 1 2 5.207 ## 2 1 2 5.734 ## 3 1 2 6.613 ## 4 1 3 5.997 ## 5 1 3 6.612 ## 6 1 3 6.810 Extract the subset of the data that corresponds to the grade 1 viral strain. myxo &lt;- subset(MyxoTiter_sum, grade == 1) summary(myxo) ## grade day titer ## Min. :1 Min. :2.000 Min. :4.196 ## 1st Qu.:1 1st Qu.:3.500 1st Qu.:6.556 ## Median :1 Median :5.000 Median :7.112 ## Mean :1 Mean :5.037 Mean :6.924 ## 3rd Qu.:1 3rd Qu.:6.000 3rd Qu.:7.543 ## Max. :1 Max. :9.000 Max. :8.499 Out of curiosity, lets make a scatterplot of the titer vs. the day with(myxo, plot(titer ~ day)) For the sake of this example, we will ignore the apparent (and unsurprising) relationship between titer and day, and instead will consider only the titer data. We will regard these data as a random sample from a normal distribution. For the sake of illustration, we will estimate the mean and variance of the normal distribution using the optim function in R. First, we write a function to calculate the log likelihood. myxo.ll &lt;- function(m, v){ ll.vals &lt;- dnorm(myxo$titer, mean = m, sd = sqrt(v), log = TRUE) sum(ll.vals) } Note that Rs function for the pdf of a normal distribution  dnorm  is parameterized by the mean and standard deviation (SD) of the normal distribution. Although it would be just as easy to find the MLE of the standard deviation \\(\\sigma\\), for the sake of illustration, we will seek the MLE of the variance, \\(\\sigma^2\\). (It turns out that, if we write the MLE of the standard deviation as \\(\\hat{\\sigma}\\) and the MLE of the variance as \\(\\hat{\\sigma}^2\\), then \\(\\hat{\\sigma} = \\sqrt{\\hat{\\sigma}^2}\\). This is an example of the {} of MLEs.) We can use our function to calculate the likelihood for any choice of mean and variance. For example, lets try \\(\\mu = 6\\) and \\(\\sigma^2 = 1\\). myxo.ll(m = 6, v = 1) ## [1] -47.91229 We want to maximize the likelihood using optim. Unfortuantely, optim is a little finicky. To use optim, we have to re-write our function myxo.ll so that the parameters to be estimated are passed to the function as a single vector. Also, by default, optim performs minimization instead of maximization. We can change this behavior when we call optim. Alternatively, we can just re-define the function to return the negative log likelihood. myxo.neg.ll &lt;- function(pars){ m &lt;- pars[1] v &lt;- pars[2] ll.vals &lt;- dnorm(myxo$titer, mean = m, sd = sqrt(v), log = TRUE) -sum(ll.vals) } Now we can use optim: (myxo.mle &lt;- optim(par = c(7, 1), # starting values, just a ballpark guess fn = myxo.neg.ll)) ## $par ## [1] 6.9241029 0.8571471 ## ## $value ## [1] 36.23228 ## ## $counts ## function gradient ## 55 NA ## ## $convergence ## [1] 0 ## ## $message ## NULL Note that the MLE of the variance is \\[ \\hat{\\sigma}^2 = \\frac{\\sum_i (x_i - \\bar{x})}{n}. \\] Lets verify this by calculating the same quantity at the command line: residuals &lt;- with(myxo, titer - mean(titer)) ss &lt;- sum(residuals^2) n &lt;- length(myxo$titer) ss / n ## [1] 0.8572684 Compare this to the answer given by var, and to the more usual calculation of the variance as \\[ s^2 = \\frac{\\sum_i (x_i - \\bar{x})}{n-1}. \\] (var.usual &lt;- ss / (n - 1)) ## [1] 0.8902403 var(myxo$titer) ## [1] 0.8902403 One main take-home of this example is that when we use maximum likelihood to estimate variances for normally distributed data, the MLE is biased low. In other words, it underestimates the true variance. When we study hierarchical models later in the semester, we will regularly find ourselves estimating variances for normally distributed effects, and will have to deal with the consequences of the fact that the MLEs of these variances are biased low. For models with 2 parameters, we can visualize the likelihood surface with a contour plot. To do so, the first step is to define a lattice of values at which we want to calculate the log-likelihood. Well do so by defining vectors for \\(\\mu\\) and \\(\\sigma^2\\): m.vals &lt;- seq(from = 6, to = 8, by = 0.05) v.vals &lt;- seq(from = 0.3, to = 2.5, by = 0.05) Here is some fancy R code that shows this lattice. Dont worry about how this plot is created, as it isnt critical for what follows. plot(rep(m.vals, length(v.vals)), rep(v.vals, rep(length(m.vals), length(v.vals))), xlab = expression(mu), ylab = expression(sigma^2)) Now we will define the matrix that will store the values of the log-likelihood for each combination of \\(\\mu\\) and \\(\\sigma^2\\) in the lattice shown above. ll.vals &lt;- matrix(nrow = length(m.vals), ncol = length(v.vals)) Next, we will write a nested loop that cycles through the lattice points, calculates the log-likelihood for each, and stores the value of the log likelihood in the matrix ll.vals that we just created. for (i.m in 1:length(m.vals)) { for(i.v in 1:length(v.vals)) { ll.vals[i.m, i.v] &lt;- myxo.ll(m = m.vals[i.m], v = v.vals[i.v]) } } Now we will use the contour function to build the contour plot, and then add a red dot for the MLE. contour(x = m.vals, y = v.vals, z = ll.vals, nlevels = 100, xlab = expression(mu), ylab = expression(sigma^2)) # show the MLE points(x = myxo.mle$par[1], y = myxo.mle$par[2], col = &quot;red&quot;) 1.4 Tadpole data Finally, well take a look at the data from the functional response experiment of Vonesh &amp; Bolker (2005), described in section 6.3.1.1 of Bolkers book. This is another example of using likelihood to estimate parameters in a two-parameter model. This example differs from the previous two examples because we wont assume that the data constitute a simple random sample from some known distribution like the Gaussian or Poisson distribution. Instead, well build a somewhat more customized model for these data that incorporates some ecological ideas. This process of building a customized model is more typical of how one would analyze a real data set. Well start by using the rm command to clean up the workspace. rm(list = ls()) First, well read in the data and explore them in various ways. library(emdbook) data(&quot;ReedfrogFuncresp&quot;) # rename something shorter frog &lt;- ReedfrogFuncresp rm(ReedfrogFuncresp) summary(frog) ## Initial Killed ## Min. : 5.00 Min. : 1.00 ## 1st Qu.: 13.75 1st Qu.: 5.75 ## Median : 25.00 Median :10.00 ## Mean : 38.12 Mean :13.25 ## 3rd Qu.: 56.25 3rd Qu.:18.75 ## Max. :100.00 Max. :35.00 head(frog) ## Initial Killed ## 1 5 1 ## 2 5 2 ## 3 10 5 ## 4 10 6 ## 5 15 10 ## 6 15 9 plot(Killed ~ Initial, data = frog) Following Bolker, well assume that the number of individuals killed takes a binomial distribution, where the number of trials equals the initial tadpole density, and the probability that a tadpole is killed is given by the expression \\[ p_i = \\dfrac{a}{1 + a h N_i} \\] The two parameters to estimate are \\(a\\), which we interpret as the attack rate when the prey density is low, and \\(h\\), which is the handling time. Well first construct the negative log-likelihood function. # negative log-likelihood, for use with optim frog.neg.ll &lt;- function(params){ a &lt;- params[1] h &lt;- params[2] prob.vals &lt;- a / (1 + a * h * frog$Initial) ll.vals &lt;- dbinom(frog$Killed, size = frog$Initial, prob = prob.vals, log = TRUE) -1 * sum(ll.vals) } Now well find the MLE using optim (frog.mle &lt;- optim(par = c(0.5, 1/40), fn = frog.neg.ll)) ## Warning in dbinom(frog$Killed, size = frog$Initial, prob = prob.vals, log = ## TRUE): NaNs produced ## $par ## [1] 0.52592567 0.01660454 ## ## $value ## [1] 46.72136 ## ## $counts ## function gradient ## 59 NA ## ## $convergence ## [1] 0 ## ## $message ## NULL # note the warnings a.mle &lt;- frog.mle$par[1] h.mle &lt;- frog.mle$par[2] Well plot the data and overlay a fitted line. # add a line to our plot to show the fitted curve plot(Killed ~ Initial, data = frog) init.values &lt;- with(frog, seq(from = min(Initial), to = max(Initial), length = 100)) pred.values &lt;- a.mle * init.values / (1 + a.mle * h.mle * init.values) lines(x = init.values, y = pred.values, col = &quot;red&quot;) Finally, well plot the likelihood contours. # plot negative likelihood contours a.vals &lt;- seq(from = 0.3, to = 0.75, by = 0.01) h.vals &lt;- seq(from = 0.001, to = 0.03, by = 0.001) ll.vals &lt;- matrix(nrow = length(a.vals), ncol = length(h.vals)) for (i.a in 1:length(a.vals)) { for(i.h in 1:length(h.vals)) { ll.vals[i.a, i.h] &lt;- frog.neg.ll(c(a.vals[i.a], h.vals[i.h])) } } contour(x = a.vals, y = h.vals, z = ll.vals, nlevels = 100, xlab = &quot;a&quot;, ylab = &quot;h&quot;) points(x = a.mle, y = h.mle, col = &quot;red&quot;) Note that, in contrast to the Myxomatosis data, here the likelihood contours form regions whose major axes are not parallel to the parameter axes. Well reflect on the implications of this shape in the next section. "],["beyond-the-mle-confidence-regions-and-hypothesis-tests-using-the-likelihood-function.html", "Chapter 2 Beyond the MLE: Confidence regions and hypothesis tests using the likelihood function 2.1 Confidence intervals for single parameters 2.2 Confidence regions, profile likelihoods, and associated univariate intervals 2.3 Locally quadratic approximations to confidence intervals and regions 2.4 Comparing models: Likelihood ratio test and AIC 2.5 Transformable constraints 2.6 The negative binomial distriution, revisited", " Chapter 2 Beyond the MLE: Confidence regions and hypothesis tests using the likelihood function Likelihood can be used for more than simply isolating the MLE. The likelihood can also be used to generate confidence intervals for single parameters, or confidence regions for several parameters. Well start by using the horse-kick data to see how to generate a confidence interval for a single parameter, and then move on to considering models with more than one parameter. 2.1 Confidence intervals for single parameters First well read in the data and recreate the negative log likelihood function. ################# ## Preparation ################ # read in the data horse &lt;- read.table(&quot;data/horse.txt&quot;, header = TRUE) horse.neg.ll &lt;- function(my.lambda) { ll.vals &lt;- dpois(x = horse$deaths, lambda = my.lambda, log = TRUE) -1 * sum(ll.vals) } # create a vector of lambda values using the &#39;seq&#39;uence command lambda.vals &lt;- seq(from = 0.5, to = 1.0, by = 0.01) # create an empty vector to store the values of the log-likelihood ll.vals &lt;- double(length = length(lambda.vals)) # use a loop to find the log-likelihood for each value in lambda.vals for (i.lambda in 1:length(lambda.vals)) { ll.vals[i.lambda] &lt;- horse.neg.ll(lambda.vals[i.lambda]) } plot(ll.vals ~ lambda.vals, xlab = &quot;lambda&quot;, ylab = &quot;negative log likelihood&quot;, type = &quot;l&quot;) Now well find the a (asymptotic) 95% confidence interval for \\(\\lambda\\) directly. cutoff.ll &lt;- horse.neg.ll(0.7) + qchisq(0.95, df = 1) / 2 # recreate the plot and add a line plot(ll.vals ~ lambda.vals, xlab = &quot;lambda&quot;, ylab = &quot;negative log likelihood&quot;, type = &quot;l&quot;) abline(h = cutoff.ll, col = &quot;red&quot;, lty = &quot;dashed&quot;) # use uniroot to find the confidence bounds precisely my.function &lt;- function(my.lambda){ horse.neg.ll(0.7) + qchisq(0.95, df = 1) / 2 - horse.neg.ll(my.lambda) } (lower &lt;- uniroot(f = my.function, interval = c(0.6, 0.7))) ## $root ## [1] 0.6065198 ## ## $f.root ## [1] -3.556854e-05 ## ## $iter ## [1] 4 ## ## $init.it ## [1] NA ## ## $estim.prec ## [1] 6.103516e-05 (upper &lt;- uniroot(f = my.function, interval = c(0.7, 0.9))) ## $root ## [1] 0.8026265 ## ## $f.root ## [1] -0.0001007316 ## ## $iter ## [1] 6 ## ## $init.it ## [1] NA ## ## $estim.prec ## [1] 6.103516e-05 As an alternative programming style, we could have defined the objective function on the fly, and not bothered to create my.function. (lower &lt;- uniroot(f = function(x) horse.neg.ll(0.7) + qchisq(0.95, df = 1) / 2 - horse.neg.ll(x) , interval = c(0.6, 0.7))) ## $root ## [1] 0.6065198 ## ## $f.root ## [1] -3.556854e-05 ## ## $iter ## [1] 4 ## ## $init.it ## [1] NA ## ## $estim.prec ## [1] 6.103516e-05 Lets recreate the plot and add vertical lines to indicate the confidence interval. plot(ll.vals ~ lambda.vals, xlab = &quot;lambda&quot;, ylab = &quot;negative log likelihood&quot;, type = &quot;l&quot;) abline(h = cutoff.ll, col = &quot;red&quot;, lty = &quot;dashed&quot;) abline(v = c(lower$root, upper$root), col = &quot;red&quot;) # clean up the workspace rm(list = ls()) Thus, the 95% CI for \\(\\lambda\\) is \\((0.607, 0.803)\\). 2.2 Confidence regions, profile likelihoods, and associated univariate intervals With a 2-parameter model, we can plot a confidence region directly. First some housekeeping to get started: library(emdbook) data(&quot;ReedfrogFuncresp&quot;) # rename something shorter frog &lt;- ReedfrogFuncresp rm(ReedfrogFuncresp) frog.neg.ll &lt;- function(params){ a &lt;- params[1] h &lt;- params[2] prob.vals &lt;- a / (1 + a * h * frog$Initial) ll.vals &lt;- dbinom(frog$Killed, size = frog$Initial, prob = prob.vals, log = TRUE) -1 * sum(ll.vals) } (frog.mle &lt;- optim(par = c(0.5, 1/60), fn = frog.neg.ll)) ## Warning in dbinom(frog$Killed, size = frog$Initial, prob = prob.vals, log = ## TRUE): NaNs produced ## $par ## [1] 0.52585566 0.01660104 ## ## $value ## [1] 46.72136 ## ## $counts ## function gradient ## 61 NA ## ## $convergence ## [1] 0 ## ## $message ## NULL a.mle &lt;- frog.mle$par[1] h.mle &lt;- frog.mle$par[2] # plot negative likelihood contours a.vals &lt;- seq(from = 0.3, to = 0.75, by = 0.01) h.vals &lt;- seq(from = 0.001, to = 0.03, by = 0.001) ll.vals &lt;- matrix(nrow = length(a.vals), ncol = length(h.vals)) for (i.a in 1:length(a.vals)) { for(i.h in 1:length(h.vals)) { ll.vals[i.a, i.h] &lt;- frog.neg.ll(c(a.vals[i.a], h.vals[i.h])) } } contour(x = a.vals, y = h.vals, z = ll.vals, nlevels = 100, xlab = &quot;a&quot;, ylab = &quot;h&quot;) points(x = a.mle, y = h.mle, col = &quot;red&quot;) Equipped with the contour plot, graphing the appropriate confidence region is straightforward. cut.off &lt;- frog.neg.ll(c(a.mle, h.mle)) + (1 / 2) * qchisq(.95, df = 2) # recreate the plot and add a line for the 95% confidence region contour(x = a.vals, y = h.vals, z = ll.vals, nlevels = 100, xlab = &quot;a&quot;, ylab = &quot;h&quot;) points(x = a.mle, y = h.mle, col = &quot;red&quot;) contour(x = a.vals, y = h.vals, z = ll.vals, levels = cut.off, add = TRUE, col = &quot;red&quot;, lwd = 2) However, there are several drawbacks to confidence regions. First, while a two-dimensional confidence region can be readily visualized, it is hard to summarize or describe. Second, and more importantly, most models have more than two parameters. In these models, a confidence region would have more than 2 dimensions, and thus would be impractical to visualize. Thus it is helpful, or even essential, to be able to generate univariate confidence intervals for single parameters from high-dimensional likelihoods. One approach to doing so is to calculate the so-called profile likelihood for a given parameter, and then to derive the univariate interval from this profile likelihood. We will illustrate this approach by computing a profile-based confidence interval for the attack rate \\(a\\) in the tadpole data. # profile log-likelihood function for the attack rate a profile.ll &lt;- function(my.a) { # Calculate the minimum log likelihood value for a given value of a, the attack rate my.ll &lt;- function(h) frog.neg.ll(c(my.a, h)) my.profile &lt;- optimize(f = my.ll, interval = c(0, 0.03), maximum = FALSE) my.profile$objective } # plot the profile likelihood vs. a # not necessary for finding the CI, but useful for understanding a.values &lt;- seq(from = 0.3, to = 0.8, by = 0.01) a.profile &lt;- double(length = length(a.values)) for (i in 1:length(a.values)) { a.profile[i] &lt;- profile.ll(a.values[i]) } plot(x = a.values, y = a.profile, xlab = &quot;a&quot;, ylab = &quot;negative log-likelihood&quot;, type = &quot;l&quot;) Now well follow the same steps as before to compute the profile-based 95% CI. # Now follow the same steps as before to find the profile 95% CI cut.off &lt;- profile.ll(a.mle) + qchisq(0.95, df = 1) / 2 (lower &lt;- uniroot(f = function(x) cut.off - profile.ll(x) , interval = c(0.3, a.mle))) ## $root ## [1] 0.4024268 ## ## $f.root ## [1] -0.0001303772 ## ## $iter ## [1] 6 ## ## $init.it ## [1] NA ## ## $estim.prec ## [1] 6.103516e-05 (upper &lt;- uniroot(f = function(x) cut.off - profile.ll(x) , interval = c(a.mle, 0.8))) ## $root ## [1] 0.6824678 ## ## $f.root ## [1] -9.763258e-06 ## ## $iter ## [1] 6 ## ## $init.it ## [1] NA ## ## $estim.prec ## [1] 6.103516e-05 plot(x = a.values, y = a.profile, xlab = &quot;a&quot;, ylab = &quot;negative log-likelihood&quot;, type = &quot;l&quot;) abline(v = c(lower$root, upper$root), col = &quot;blue&quot;) abline(h = cut.off, col = &quot;blue&quot;, lty = &quot;dashed&quot;) So, the 95% profile CI for \\(a\\) is (0.402, 0.682). 2.3 Locally quadratic approximations to confidence intervals and regions Likelihood profiling provides a straightforward way to summarize a high-dimensional confidence region by univariate confidence intervals. However, these profile intervals can still involve quite a bit of computation. Further, they are not able to capture possible correlations among parameter estimates, which are revealed in (two-dimensional) confidence regions. (Recall the shape of the joint confidence region for the parameters \\(a\\) and \\(h\\) in the tadpole data.) Locally quadratic approximations provide a way to approximate the (already approximate) univariate confidence intervals and bivariate confidence regions using only information about the curvature of the likelihood surface at the MLE. Well first start by revisiting the horse-kick data again. Of course, with the more precise \\(\\chi^2\\) based confidence interval in hand, there is no reason to seek an approximation. But doing so allows us to illustrate the calculations involved, and to see how well the approximation fares in this case. First some housekeepign to read the data into memory, etc. # clean up rm(list = ls()) # read in the data horse &lt;- read.table(&quot;data/horse.txt&quot;, header = TRUE) horse.neg.ll &lt;- function(my.lambda) { ll.vals &lt;- dpois(x = horse$deaths, lambda = my.lambda, log = TRUE) -1 * sum(ll.vals) } # use uniroot to find the confidence bounds precisely my.function &lt;- function(my.lambda){ horse.neg.ll(0.7) + qchisq(0.95, df = 1) / 2 - horse.neg.ll(my.lambda) } lower &lt;- uniroot(f = my.function, interval = c(0.6, 0.7)) upper &lt;- uniroot(f = my.function, interval = c(0.7, 0.9)) Now we will proceed to use a locally quadratic approximation to the negative log likelihood. ## this function finds the second derivative at the MLE by finite differences second.deriv &lt;- function(delta.l) { (horse.neg.ll(0.7 + delta.l) - 2 * horse.neg.ll(0.7) + horse.neg.ll(0.7 - delta.l)) / delta.l ^ 2 } (horse.D2 &lt;- second.deriv(1e-04)) ## [1] 400 # see how the answer changes if we change delta second.deriv(1e-05) ## [1] 400.0003 Lets compare this answer to the answer obtained by numDeriv::hessian. numDeriv::hessian(func = horse.neg.ll, x = 0.7) ## [,1] ## [1,] 400 The approximate standard error of \\(\\hat{\\lambda}\\) is the square root of the inverse of the second derivative of the likelihood function. (lambda.se &lt;- sqrt(1 / horse.D2)) ## [1] 0.05 Now we can approximate the 95% confidence interval by using critical values from a standard normal distribution. (lower.approx &lt;- 0.7 - qnorm(.975) * lambda.se) ## [1] 0.6020018 (upper.approx &lt;- 0.7 + qnorm(.975) * lambda.se) ## [1] 0.7979982 Compare the approximation to the exact values lower$root ## [1] 0.6065198 upper$root ## [1] 0.8026265 Make a plot # create a vector of lambda values using the &#39;seq&#39;uence command lambda.vals &lt;- seq(from = 0.5, to = 1.0, by = 0.01) # create an empty vector to store the values of the log-likelihood ll.vals &lt;- double(length = length(lambda.vals)) # use a loop to find the log-likelihood for each value in lambda.vals for (i.lambda in 1:length(lambda.vals)) { ll.vals[i.lambda] &lt;- horse.neg.ll(lambda.vals[i.lambda]) } plot(ll.vals ~ lambda.vals, xlab = &quot;lambda&quot;, ylab = &quot;negative log likelihood&quot;, type = &quot;l&quot;) ################################### ## Now find the confidence interval, and plot it #################################### cutoff.ll &lt;- horse.neg.ll(0.7) + qchisq(0.95, df = 1) / 2 # add a line to the plot abline(h = cutoff.ll, col = &quot;red&quot;, lty = &quot;dashed&quot;) abline(v = c(lower$root, upper$root), col = &quot;red&quot;) abline(v = c(lower.approx, upper.approx), col = &quot;blue&quot;) legend(x = 0.65, y = 326, leg = c(&quot;exact&quot;, &quot;approximate&quot;), pch = 16, col = c(&quot;red&quot;, &quot;blue&quot;), bty = &quot;n&quot;) # clean up rm(list = ls()) Notice that the full \\(\\chi^2\\)-based confidence intervals capture the asymmetry in the information about \\(\\lambda\\). The intervals based on the quadratic approximation are symmetric. Now, use the quadratic approximation to find standard errors for \\(\\hat{a}\\) and \\(\\hat{h}\\) in the tadpole predation data. The first part is preparatory work from old classes. library(emdbook) data(&quot;ReedfrogFuncresp&quot;) # rename something shorter frog &lt;- ReedfrogFuncresp rm(ReedfrogFuncresp) frog.neg.ll &lt;- function(params){ a &lt;- params[1] h &lt;- params[2] prob.vals &lt;- a / (1 + a * h * frog$Initial) ll.vals &lt;- dbinom(frog$Killed, size = frog$Initial, prob = prob.vals, log = TRUE) -1 * sum(ll.vals) } frog.mle &lt;- optim(par = c(0.5, 1/60), fn = frog.neg.ll) ## Warning in dbinom(frog$Killed, size = frog$Initial, prob = prob.vals, log = ## TRUE): NaNs produced (a.mle &lt;- frog.mle$par[1]) ## [1] 0.5258557 (h.mle &lt;- frog.mle$par[2]) ## [1] 0.01660104 Now find the hessian: (D2 &lt;- numDeriv::hessian(func = frog.neg.ll, x = c(a.mle, h.mle))) ## [,1] [,2] ## [1,] 616.5606 -7394.263 ## [2,] -7394.2628 130640.685 The matrix inverse of the hessian is the variance-covariance matrix of the parameters. Note that R uses the function solve to find the inverse of a matrix. # invert to get var-cov matrix (var.matrix &lt;- solve(D2)) ## [,1] [,2] ## [1,] 0.0050493492 2.857932e-04 ## [2,] 0.0002857932 2.383048e-05 We can use the handy cov2cor function to convert the variance matrix into a correlation matrix: cov2cor(var.matrix) ## [,1] [,2] ## [1,] 1.0000000 0.8238872 ## [2,] 0.8238872 1.0000000 Note the large correlation between \\(\\hat{a}\\) and \\(\\hat{h}\\). Compare with Figure 6.13 of Bolker. The standard errors of \\(\\hat{a}\\) and \\(\\hat{h}\\) are the square roots of the diagaonal elements of the variance-covariance matrix. (a.se &lt;- sqrt(var.matrix[1, 1])) ## [1] 0.07105877 (h.se &lt;- sqrt(var.matrix[2, 2])) ## [1] 0.004881647 Note the large correlation between \\(\\hat{a}\\) and \\(\\hat{h}\\). Lets use the (approximate) standard error of \\(\\hat{a}\\) to calculate an (approximate) 95% confidence interval: (ci.approx &lt;- a.mle + qnorm(c(0.025, .975)) * a.se) ## [1] 0.3865830 0.6651283 Recall that the 95% confidence interval we calculated by the profile likelihood was \\((0.402, 0.682)\\). So the quadratic approximation has gotten the width of the interval more or less correct, but it has fared less at capturing the asymmetry of the interval. 2.4 Comparing models: Likelihood ratio test and AIC Obtaining a parsimonious statistical description of data often requires arbitrating between competing model fits. Likelihood provides two tools for comparing models: likelihood ratio tests (LRTs) and information criteria. Of the latter, the best known information criterion is due to Akaike, and takes the name AIC. (Akaike didnt name AIC after himself; he used AIC to refer to An information criterion. In his honor, the acronym is now largely taken to stand for Akaikes information criterion.) LRTs and information criteria have complementary strengths and weaknesses. LRTs are direct, head-to-head comparisons of nested models. By nested, we mean that one model can be obtained as a special case of the other. The reduced, or less flexible (and thus more parsimonious) model plays the role of the null hypothesis, and the full, or more flexible (and thus less parsimonious) model plays the role of the alternative hypothesis. The LRT then formally evaluates whether the improvement in fit offered by the full model is statistically significant, that is, greater than what we would expect merely by chance. On the other hand, information criteria provide a penalized goodness-of-fit measure that can be used to compare many models at once. Information criteria produce a ranking of model fits, and thus a best-fitting model. The downside to information criteria is that there are no hard and fast guidelines to determine when one model provides a significantly better fit than another. The properties of information criteria are also less well understood than the properties of LRTs. To illustrate both, we will use the study of cone production by fir trees studied in \\(\\S\\) 6.6 of Bolker. These data are originally from work by Dodd and Silvertown. The data are much richer than we will examine here. Like Bolker, we will focus on whether the relationship between tree size (as measured by diameter at breast height, or dbh) and the number of cones produces differs between populations that have experienced wave-like die-offs and those that have not. First some preparatory work to import and assemble the data: require(emdbook) data(&quot;FirDBHFec&quot;) # give the data a simpler name fir &lt;- FirDBHFec rm(FirDBHFec) fir &lt;- fir[, c(&quot;WAVE_NON&quot;, &quot;DBH&quot;, &quot;TOTCONES&quot;)] # select just the variables we want summary(fir) ## WAVE_NON DBH TOTCONES ## n:166 Min. : 3.200 Min. : 0.0 ## w:205 1st Qu.: 6.400 1st Qu.: 14.0 ## Median : 7.600 Median : 36.0 ## Mean : 8.169 Mean : 49.9 ## 3rd Qu.: 9.700 3rd Qu.: 66.0 ## Max. :17.400 Max. :297.0 ## NA&#39;s :26 NA&#39;s :114 names(fir) &lt;- c(&quot;wave&quot;, &quot;dbh&quot;, &quot;cones&quot;) # rename the variables # get rid of the incomplete records fir &lt;- na.omit(fir) par(mfrow = c(1, 2)) plot(cones ~ dbh, data = fir, type = &quot;n&quot;, main = &quot;wave&quot;) points(cones ~ dbh, data = subset(fir, wave == &quot;w&quot;)) plot(cones ~ dbh, data = fir, type = &quot;n&quot;, main = &quot;non-wave&quot;) points(cones ~ dbh, data = subset(fir, wave == &quot;n&quot;)) # any non-integral responses? with(fir, table(cones == round(cones))) # illustrate the use of &#39;with&#39; ## ## FALSE TRUE ## 6 236 # round the non-integral values fir$cones &lt;- round(fir$cones) # check with(fir, table(cones == round(cones))) ## ## TRUE ## 242 Like Bolker, we will assume that the average number of cones produced (\\(\\mu\\)) has a power-law relationship with tree dbh (\\(x\\)). We will also assume that the actual number of cones produced (\\(Y\\)) takes a negative binomial distribution with size-dependent mean and overdispersion parameter \\(k\\). That is, our model is \\[\\begin{align*} \\mu(x) &amp; = a x ^ b \\\\ Y &amp; \\sim \\mbox{NB}(\\mu(x), k) \\end{align*}\\] To head in a slightly different direction from Bolker, we will compare two models. In the first, or reduced, model the same parameters will prevail for both wave and non-wave populations. Thus this model has three parameters: \\(a\\), \\(b\\), and \\(k\\). In the second, or full, model, we will allow the \\(a\\) and \\(b\\) parameters to differ between the wave and non-wave populations. (We will continue to assume a common \\(k\\) for both population types.) Using subscripts on \\(a\\) and \\(b\\) to distinguish population types, the full model then has 5 parameters: \\(a_w\\), \\(a_n\\), \\(b_w\\), \\(b_n\\), and \\(k\\). Well fit the reduced model first. To do so, well use the dnbinom function in R, in which the \\(k\\) parameter is located in the formal argument size. fir.neg.ll &lt;- function(parms, x, y){ a &lt;- parms[1] b &lt;- parms[2] k &lt;- parms[3] my.mu &lt;- a * x^b ll.values &lt;- dnbinom(y, size = k, mu = my.mu, log = TRUE) neg.ll &lt;- -1 * sum(ll.values) return(neg.ll) } Note a subtle difference here. In preparation for fitting this same model to different subsets of the data, the function fir.neg.ll has formal arguments that receive the values of the \\(x\\) and \\(y\\) variables. In the call to optim, we can supply those additional values as subsequent arguments in the optim function, as illustrated below. # fit reduced model (fir.reduced &lt;- optim(f = fir.neg.ll, par = c(a = 1, b = 1, k = 1), x = fir$dbh, y = fir$cones)) ## $par ## a b k ## 0.3041425 2.3190142 1.5033525 ## ## $value ## [1] 1136.015 ## ## $counts ## function gradient ## 134 NA ## ## $convergence ## [1] 0 ## ## $message ## NULL a.mle &lt;- fir.reduced$par[1] b.mle &lt;- fir.reduced$par[2] k.mle &lt;- fir.reduced$par[3] Make a plot of the reduced model fit, with both populations pooled together: dbh.vals &lt;- seq(from = min(fir$dbh), to = max(fir$dbh), length = 100) fit.vals &lt;- double(length = length(dbh.vals)) for (i in seq(along = dbh.vals)) { fit.vals[i] &lt;- a.mle * dbh.vals[i] ^ b.mle } par(mfrow = c(1, 1)) # don&#39;t break the next figure into two panels with(fir, plot(cones ~ dbh)) # plot the data points lines(fit.vals ~ dbh.vals, col = &quot;blue&quot;) Now fit the full model with separate values of \\(a\\) and \\(b\\) for each population: fir.neg.ll.full &lt;- function(parms) { a.w &lt;- parms[1] b.w &lt;- parms[2] a.n &lt;- parms[3] b.n &lt;- parms[4] k &lt;- parms[5] wave &lt;- subset(fir, wave == &quot;w&quot;) nonwave &lt;- subset(fir, wave == &quot;n&quot;) # note how we call fir.neg.ll here, but each time only # passing a subset of the data neg.ll.wave &lt;- fir.neg.ll(parms = c(a = a.w, b = b.w, k = k), x = wave$dbh, y = wave$cones) neg.ll.nonwave &lt;- fir.neg.ll(parms = c(a = a.n, b = b.n, k = k), x = nonwave$dbh, y = nonwave$cones) total.ll &lt;- neg.ll.wave + neg.ll.nonwave return(total.ll) } (fir.full &lt;- optim(f = fir.neg.ll.full, par = c(a.w = 1, b.w = 1, a.n = 1, b.n = 1, k = 1))) ## $par ## a.w b.w a.n b.n k ## 0.4136414 2.1417941 0.2874122 2.3550753 1.5083974 ## ## $value ## [1] 1135.677 ## ## $counts ## function gradient ## 502 NA ## ## $convergence ## [1] 1 ## ## $message ## NULL Lets make a plot to show the different fits. a.w.mle &lt;- fir.full$par[1] b.w.mle &lt;- fir.full$par[2] a.n.mle &lt;- fir.full$par[3] b.n.mle &lt;- fir.full$par[4] par(mfrow = c(1, 2)) # wave populations fit.vals.wave &lt;- fit.vals.non &lt;- double(length = length(dbh.vals)) plot(cones ~ dbh, data = fir, type = &quot;n&quot;, main = &quot;wave&quot;) points(cones ~ dbh, data = subset(fir, wave == &quot;w&quot;)) for (i in seq(along = dbh.vals)) { fit.vals.wave[i] &lt;- a.w.mle * dbh.vals[i] ^ b.w.mle } lines(fit.vals.wave ~ dbh.vals, col = &quot;blue&quot;) # non-wave populations plot(cones ~ dbh, data = fir, type = &quot;n&quot;, main = &quot;non-wave&quot;) points(cones ~ dbh, data = subset(fir, wave == &quot;n&quot;)) for (i in seq(along = dbh.vals)) { fit.vals.non[i] &lt;- a.n.mle * dbh.vals[i] ^ b.n.mle } lines(fit.vals.non ~ dbh.vals, col = &quot;red&quot;) Note that to compute the negative log likelihood for the full model, we compute the negative log likelihood for each population separately, and then sum the two negative log likelihoods. We can see the justification for doing so by writing out the log likelihood function explicitly: \\[\\begin{eqnarray*} \\ln L(a_w, a_n, b_w, b_n, k; \\mathbf{y}) &amp; = &amp; \\ln \\prod_{i \\in \\left\\{w, n \\right\\}} \\prod_{j=1}^{n_i} f(y_{ij}; a_w, a_n, b_w, b_n, k) \\\\ &amp; = &amp; \\sum_{i \\in \\left\\{w, n \\right\\}} \\sum_{j=1}^{n_i} \\ln f(y_{ij}; a_w, a_n, b_w, b_n, k) \\\\ &amp; = &amp; \\sum_{j=1}^{n_w} \\ln f(y_{w,j}; a_w, b_w, k) + \\sum_{j=1}^{n_n} \\ln f(y_{2, n}; a_n, b_n, k) \\end{eqnarray*}\\] Now conduct the likelihood ratio test: (lrt.stat &lt;- 2 * (fir.reduced$value - fir.full$value)) # compute the likelihood ratio test statistic ## [1] 0.6762567 (lrt.pvalue &lt;- pchisq(q = lrt.stat, df = 2, lower.tail = FALSE)) # calculate the p-vlaue ## [1] 0.7131037 The LRT suggests that the full model does not provide a significantly better fit than the reduced model (\\(\\chi^2_2 = 0.676\\), \\(p=0.71\\)). In other words, there is no evidence that the two population types have different relationships between tree size and avearage fecundity. Now compare AIC values for the two models. Because we have already done the LRT, this AIC comparison is for illustration. (aic.reduced &lt;- 2 * fir.reduced$value + 2 * 3) ## [1] 2278.03 (aic.full &lt;- 2 * fir.full$value + 2 * 5) ## [1] 2281.354 (delta.aic &lt;- aic.full - aic.reduced) ## [1] 3.323743 The reduced model is AIC-best, although the \\(\\Delta AIC\\) is only moderately large. We can also fit a Poisson model to these data. Because we have ruled out the need for different models for the two population type, we fit a Poisson model to the data with the two populations pooled together. fir.neg.ll.pois &lt;- function(parms, x, y){ a &lt;- parms[1] b &lt;- parms[2] my.mu &lt;- a * x^b ll.values &lt;- dpois(y, lambda = my.mu, log = TRUE) -1 * sum(ll.values) } (fir.pois &lt;- optim(f = fir.neg.ll.pois, par = c(a = 1, b = 1), x = fir$dbh, y = fir$cones)) ## $par ## a b ## 0.2613297 2.3883860 ## ## $value ## [1] 3161.832 ## ## $counts ## function gradient ## 115 NA ## ## $convergence ## [1] 0 ## ## $message ## NULL a.mle.pois &lt;- fir.pois$par[1] b.mle.pois &lt;- fir.pois$par[2] Calculate the AIC for this model: # calculate AIC (aic.pois &lt;- 2 * fir.pois$value + 2 * 2) ## [1] 6327.664 Whoa! The AIC suggests the negative binomial model is an overwhelmingly better fit. Finally, make a plot to compare the two fits: with(fir, plot(cones ~ dbh)) lines(fit.vals ~ dbh.vals, col = &quot;blue&quot;) # plot the fit from the NegBin model ## calculate and plot the fit for the Poisson model fit.vals.pois &lt;- double(length = length(dbh.vals)) for (i in seq(along = dbh.vals)) { fit.vals.pois[i] &lt;- a.mle.pois * dbh.vals[i] ^ b.mle.pois } lines(fit.vals.pois ~ dbh.vals, col = &quot;red&quot;) legend(x = 4, y = 280, leg = c(&quot;Neg Bin&quot;, &quot;Poisson&quot;), col = c(&quot;blue&quot;, &quot;red&quot;), pch = 16, bty = &quot;n&quot;) 2.5 Transformable constraints So far, we have not thought much about the numerical optimization routines that R uses to find MLEs. If time allowed, we really should think more deeply about how these routines work. Indeed, Bolker devotes an entire chapter (his chapter 7) to numerical optimization. Because time is short, we wont go that deeply into understanding these methods now, although Bolkers chapter is worth a read if you are so inclined. There is one topic that deserves more of our attention, which is the issue of constriants on the allowable parameter space. (Bolker touches on this in his \\(\\S\\) 7.4.5.) Many times, we write down models with parameters that only make biological sense in a certain range. For example, in the fir data, we know that the parameter \\(a\\) (the average cone production for trees of size \\(x = 1\\)) must be positive. We also know that \\(k\\), the overdispersion parameter in the negative binomial model, must also be positive. However, most numerical optimization routines are not terribly well suited to optimizing over a constrained space. (The presence of constraints is one of the reasons why it is important to initiate numerical optimization routines with reasonalbe starting values.) One exception is the L-BFGS-B method, available in optim, which will permit so-called rectangular constraints. An alternative approach that will work with any numerical optimization scheme is to transform the constraints away. That is, transform the parameterization to a new scale that is unconstrained. Because of the invariance principle of MLEs, these transformations wont change the MLEs that we eventually find, as long as the MLEs are not on the edge of the original, constrained space. To illustrate, consider the fir data again, and consider the negative-binomial model fit to the entire data set, ignoring differences between wave vs. non-wave populations. To transform away the constraints on \\(a\\) and \\(k\\), re-parameterize the model in terms of the logs of both parameters. That is, define \\[\\begin{align*} a^* &amp; = \\ln (a) \\\\ k^* &amp; = \\ln (k) \\\\ \\end{align*}\\] so that the model is now \\[\\begin{align*} \\mu(x) &amp; = \\exp(a^*) \\times x ^ b \\\\ Y &amp; \\sim \\mbox{NB}(\\mu(x), \\exp(k^*)) \\end{align*}\\] Fitting proceeds in the usual way: fir.neg.ll &lt;- function(parms, x, y){ a &lt;- exp(parms[1]) b &lt;- parms[2] k &lt;- exp(parms[3]) my.mu &lt;- a * x^b ll.values &lt;- dnbinom(y, size = k, mu = my.mu, log = TRUE) -1 * sum(ll.values) } (fir.reduced &lt;- optim(f = fir.neg.ll, par = c(a = 0, b = 1, k = 0), x = fir$dbh, y = fir$cones)) ## $par ## a b k ## -1.1914367 2.3195050 0.4074672 ## ## $value ## [1] 1136.015 ## ## $counts ## function gradient ## 158 NA ## ## $convergence ## [1] 0 ## ## $message ## NULL Back-transforming to the original scale recovers the previous MLEs: (a.mle &lt;- exp(fir.reduced$par[1])) ## a ## 0.3037845 (b.mle &lt;- fir.reduced$par[2]) ## b ## 2.319505 (k.mle &lt;- exp(fir.reduced$par[3])) ## k ## 1.503006 The constraint issue also explains why we received warnings from R when we first found the MLEs for the tadpole predation data in Section 2.2. Another example that one frequently encounters in ecology are parameters that are constrained to lie between 0 and 1, such as a survival probability. A logit (or log odds) transformation will eliminate the constraints on a parameter that lies between 0 and 1. 2.6 The negative binomial distriution, revisited The negative binomial distribution is a funny distribution that is frequently misunderstood by ecologists. In ecology, the negative binomial distribution is typically parameterized by the distributions mean (which we typically write as \\(\\mu\\)) and the overdispersion parameter, almost always written as \\(k\\). In this parameterization, if \\(X\\) has a negative binomial distribution with mean \\(\\mu\\) and overdispersion parameter \\(k\\), then the variance of \\(X\\) is \\[ Var(X) = \\mu + \\frac{\\mu^2}{k} \\] Thus, for fixed \\(\\mu\\), the variance increases as \\(k\\) decreases. As \\(k\\) gets large, the variance approaches \\(\\mu\\), and the negative binomial distribution approaches a Poisson distribution. There are a few occasions in ecology where the overdispersion parameter \\(k\\) has a mechanistic interpretation. In all other cases, though, \\(k\\) is merely a phenomenological descriptor that captures the relationship between the mean and variance for one particular value of \\(\\mu\\). The error that most ecologists make is to assume that a single value of \\(k\\) should prevail across several values of \\(\\mu\\). If \\(k\\) is phenomenological, there is no reason that \\(k\\) should remain fixed as \\(\\mu\\) changes. The fit to the fir data exemplifies this error, as so far we have assumed that one value of \\(k\\) must prevail across all sizes of trees. By assuming that \\(k\\) is fixed, we impose a relationship on the data where the variance must increase quadratically as the mean increases. This may be a reasonable model for the relationship between the variance and the mean, or it may not be. Instead of assuming \\(k\\) constant, another equally viable approach might be to assume that \\(k\\) is a linear function of \\(\\mu\\). In other words, We might set \\(k = \\kappa \\mu\\) for some value of \\(\\kappa\\). In this case, for a given mean \\(\\mu\\), the variance would be \\(\\mu + \\frac{\\mu^2}{\\kappa \\mu} = \\mu \\left(1 + \\frac{1}{\\kappa}\\right)\\), so that the variance would increase linearly as the mean increases. We can try fitting this alternative model to the fir tree data, again pooling wave and non-wave populations together. fir.alt.neg.ll &lt;- function(parms, x, y){ a &lt;- exp(parms[1]) b &lt;- parms[2] k &lt;- exp(parms[3]) my.mu &lt;- a * x^b ll.values &lt;- dnbinom(y, size = k * my.mu, mu = my.mu, log = TRUE) -1 * sum(ll.values) } (fir.alt &lt;- optim(f = fir.alt.neg.ll, par = c(a = 0, b = 1, k = 0), x = fir$dbh, y = fir$cones)) ## $par ## a b k ## -1.008373 2.243545 -3.278311 ## ## $value ## [1] 1128.403 ## ## $counts ## function gradient ## 182 NA ## ## $convergence ## [1] 0 ## ## $message ## NULL (a.mle.alt &lt;- exp(fir.alt$par[1])) ## a ## 0.3648121 (b.mle.alt &lt;- fir.alt$par[2]) ## b ## 2.243545 (k.mle.alt &lt;- exp(fir.alt$par[3])) ## k ## 0.03769186 If we compare the fits graphically, the alternative model doesnt generate a dramatically different fit for the relationship between the average cone production and tree size: fit.vals.alt &lt;- double(length = length(dbh.vals)) for (i in seq(along = dbh.vals)) { fit.vals.alt[i] &lt;- a.mle.alt * dbh.vals[i] ^ b.mle.alt } with(fir, plot(cones ~ dbh)) lines(fit.vals ~ dbh.vals, col = &quot;blue&quot;) lines(fit.vals.alt ~ dbh.vals, col = &quot;red&quot;) legend(&quot;topleft&quot;, col = c(&quot;blue&quot;, &quot;red&quot;), pch = 16, leg = c(&quot;original&quot;, &quot;alternate&quot;)) However, the two models imply very different relationships between the variance in cone production and tree size. Lets look at the implied relationship between the standard deviation of cone production and tree size: mu.vals &lt;- seq(from = 0, to = max(fit.vals), length = 100) sd.vals.nb1 &lt;- sqrt(mu.vals + mu.vals ^ 2 / k.mle) sd.vals.nb2 &lt;- sqrt(mu.vals * (1 + 1 / k.mle.alt)) plot(mu.vals, sd.vals.nb1, xlab = &quot;mean&quot;, ylab = &quot;SD&quot;, type = &quot;l&quot;, col = &quot;blue&quot;) lines(mu.vals, sd.vals.nb2, col = &quot;red&quot;) legend(&quot;topleft&quot;, col = c(&quot;blue&quot;, &quot;red&quot;), pch = 16, leg = c(&quot;original&quot;, &quot;alternate&quot;)) We can calculate the AIC for this alternate parameterization as well: (aic.alt &lt;- 2 * fir.alt$value + 2 * 3) ## [1] 2262.805 Recall that the AIC value for the original fit was 2278.0. Thus the model with the alternative parameterization is considerably better by AIC. "],["bayesian-computation.html", "Chapter 3 Bayesian computation 3.1 Computations with conjugate priors 3.2 JAGS in R 3.3 rstanarm", " Chapter 3 Bayesian computation This chapter of the computing companion will focus solely on the computing aspects of Bayesian computation in R. See the course notes or relevant sections of Bolker for the underlying theory. The landscape of computing tools available to fit Bayesian models is fluid. Here, we will look at three tools currently available: R2jags, which is based on the JAGS (Just Another Gibbs Sampler) platform, rstan, which is based on the computer program Stan (itself based on Hamiltonian Monte Carlo, or HMC), and the recent rstanarm, which seeks to put much of the computational details in the background. (The arm portion of the name rstanarm is an acronym for applied regression modeling.) Throughout, we will be working with two data sets: the horse kick data (again), and a data set that details how the rate at which a cricket chirps depends on the air temperature. The horse kick data are useful in this context because a Gamma distribution is a conjugate prior for Poisson data. Thus, if we use a Gamma prior, then we know the posterior exactly. Therefore, we can compare the approximations provided by stochastic sampling schemes to the known posterior. The cricket data set will be used as an example of a simple linear regression, even though the data hint that the actual relationship between temperature and the rate of chirping is nonlinear. 3.1 Computations with conjugate priors Suppose that we observe an iid random sample \\(X_1, \\ldots, X_n\\) from a Poisson distribution with unknown parameter \\(\\lambda\\). (This is the setting for the horse-kick data.) If we place a Gamma prior with shape parameter \\(a\\) and rate parameter \\(r\\) on \\(\\lambda\\), then the posterior distribution is also Gamma with shape parameter \\(a + \\sum_n X_n\\) and rate parameter \\(r + n\\). In other words, \\[\\begin{align*} \\lambda &amp; \\sim \\mbox{Gamma}(a, r) \\\\ X_1, \\ldots, X_n &amp; \\sim \\mbox{Pois}(\\lambda) \\\\ \\lambda | X_1, \\ldots, X_n &amp; \\sim \\mbox{Gamma}(a + \\sum_n X_n, r + n) \\\\ \\end{align*}\\] In the horse kick data, \\(\\sum_n x_n = 196\\) and \\(n = 280\\). Suppose we start with the vague Gamma prior \\(a=.01\\), \\(r = .01\\) on \\(\\lambda\\). This prior has mean \\(a/r = 1\\) and variance \\(a/r^2 = 100\\). The posterior distribution for \\(\\lambda\\) is then a Gamma with shape parameter \\(a = 196.01\\) and rate parameter \\(280.01\\). We can plot it: horse &lt;- read.table(&quot;data/horse.txt&quot;, header = TRUE, stringsAsFactors = TRUE) l.vals &lt;- seq(from = 0, to = 2, length = 200) plot(l.vals, dgamma(l.vals, shape = 196.01, rate = 280.01), type = &quot;l&quot;, xlab = expression(lambda), ylab = &quot;&quot;) lines(l.vals, dgamma(l.vals, shape = .01, rate = .01), lty = &quot;dashed&quot;) abline(v = 0.7, col = &quot;red&quot;) legend(&quot;topleft&quot;, leg = c(&quot;prior&quot;, &quot;posterior&quot;), lty = c(&quot;dashed&quot;, &quot;solid&quot;)) The red line shows the MLE, which is displaced slightly from the posterior mode. As a point estimate, we might consider any of the following. The posterior mean can be found exactly as \\(a/r\\) = 0.70001. Alternatively, we might consider the posterior median qgamma(0.5, shape = 196.01, rate = 280.01) ## [1] 0.6988206 Finally, we might conisder the posterior mode: optimize(f = function(x) dgamma(x, shape = 196.01, rate = 280.01), interval = c(0.5, 1), maximum = TRUE) ## $maximum ## [1] 0.6964383 ## ## $objective ## [1] 7.995941 To find a 95% confidence interval, we might consider the central 95% interval: qgamma(c(0.025, 0.975), shape = 196.01, rate = 280.01) ## [1] 0.6054387 0.8013454 A 95% highest posterior density (HPD) interval takes a bit more work: diff.in.pdf &lt;- function(x){ upper &lt;- qgamma(p = x, shape = 196.01, rate = 280.01) lower &lt;- qgamma(p = x - .95, shape = 196.01, rate = 280.01) dgamma(upper, shape = 196.01, rate = 280.01) - dgamma(lower, shape = 196.01, rate = 280.01) } (upper.qtile &lt;- uniroot(diff.in.pdf, interval = c(0.95, 1))$root) ## [1] 0.9722176 (hpd.ci &lt;- qgamma(p = c(upper.qtile - .95, upper.qtile), shape = 196.01, rate = 280.01)) ## [1] 0.6031732 0.7988576 We might also ask questions like: What is the posterior probability that \\(\\lambda &gt; 2/3\\)? These caluclations are straightforward in a Bayesian context, and they make full sense. pgamma(2/3, shape = 196.01, rate = 280.01, lower.tail = FALSE) ## [1] 0.7434032 Thus we would say that there is a 0.743 posterior probability that \\(\\lambda &gt; 2/3\\). As an illustration, note that if we had begun with a more informative prior  say, a gamma distribution with shape parameter \\(a = 50\\) and rate parameter = \\(100\\)  then the posterior would have been more of a compromise between the prior and the information in the data: plot(l.vals, dgamma(l.vals, shape = 196 + 50, rate = 100 + 280), type = &quot;l&quot;, xlab = expression(lambda), ylab = &quot;&quot;) lines(l.vals, dgamma(l.vals, shape = 50, rate = 100), lty = &quot;dashed&quot;) abline(v = 0.7, col = &quot;red&quot;) legend(&quot;topleft&quot;, leg = c(&quot;prior&quot;, &quot;posterior&quot;), lty = c(&quot;dashed&quot;, &quot;solid&quot;)) 3.2 JAGS in R All of the computational tools that we will examine in this section involve some form of stochastic sampling from the posterior. This computing companion will largely use the default settings, though in real practice the analyst will often have to do considerable work adjusting the settings to obtain a satisfactory approximation. Well use JAGS through R, using the library r2jags. Here is JAGS code to approximate the posterior to \\(\\lambda\\) for the horse kick data, using the vague prior. require(R2jags) ## Loading required package: R2jags ## Warning: package &#39;R2jags&#39; was built under R version 4.1.1 ## Loading required package: rjags ## Warning: package &#39;rjags&#39; was built under R version 4.1.1 ## Loading required package: coda ## Linked to JAGS 4.3.0 ## Loaded modules: basemod,bugs ## ## Attaching package: &#39;R2jags&#39; ## The following object is masked from &#39;package:coda&#39;: ## ## traceplot horse.model &lt;- function() { for (j in 1:J) { # J = 280, number of data points y[j] ~ dpois (lambda) # data model: the likelihood } lambda ~ dgamma (0.01, 0.01) # prior # note that BUGS / JAGS parameterizes # gamma by shape, rate } jags.data &lt;- list(y = horse$deaths, J = length(horse$deaths)) jags.params &lt;- c(&quot;lambda&quot;) jags.inits &lt;- function(){ list(&quot;lambda&quot; = rgamma(0.01, 0.01)) } jagsfit &lt;- jags(data = jags.data, inits = jags.inits, parameters.to.save = jags.params, model.file = horse.model, n.chains = 3, n.iter = 5000) ## module glm loaded ## Compiling model graph ## Resolving undeclared variables ## Allocating nodes ## Graph information: ## Observed stochastic nodes: 280 ## Unobserved stochastic nodes: 1 ## Total graph size: 283 ## ## Initializing model Lets take a look at some summary statistics of the fit print(jagsfit) ## Inference for Bugs model at &quot;C:/Users/krgross/AppData/Local/Temp/RtmpkNru5X/model22904ae71ca7.txt&quot;, fit using jags, ## 3 chains, each with 5000 iterations (first 2500 discarded), n.thin = 2 ## n.sims = 3750 iterations saved ## mu.vect sd.vect 2.5% 25% 50% 75% 97.5% Rhat n.eff ## lambda 0.700 0.051 0.604 0.665 0.699 0.734 0.803 1.001 2500 ## deviance 629.364 1.522 628.311 628.421 628.785 629.696 633.562 1.004 2400 ## ## For each parameter, n.eff is a crude measure of effective sample size, ## and Rhat is the potential scale reduction factor (at convergence, Rhat=1). ## ## DIC info (using the rule, pD = var(deviance)/2) ## pD = 1.2 and DIC = 630.5 ## DIC is an estimate of expected predictive error (lower deviance is better). The Rhat values suggest that our chains have converged, as we might hope for such a simple model. We can generate a trace plot using traceplot to inspect convergence visually, but beware that visual assessment of convergence is prone to error. For an rjags object, the raw MCMC samples are stored in BUGSoutput$sims.list. Sometimes it is helpful to analyze these samples directly. For example, with these samples we can estimate other posterior quantities, such as the posterior median of \\(\\lambda\\), or generate a 95% central posterior confidence interval directly: mcmc.output &lt;- as.data.frame(jagsfit$BUGSoutput$sims.list) summary(mcmc.output) ## deviance lambda ## Min. :628.3 Min. :0.5365 ## 1st Qu.:628.4 1st Qu.:0.6647 ## Median :628.8 Median :0.6992 ## Mean :629.4 Mean :0.6999 ## 3rd Qu.:629.7 3rd Qu.:0.7337 ## Max. :644.2 Max. :0.9188 median(mcmc.output$lambda) ## [1] 0.6991852 quantile(mcmc.output$lambda, c(.025, .975)) ## 2.5% 97.5% ## 0.6036116 0.8028820 We can also use the lattice package to construct smoothed estimates of the posterior density: require(lattice) ## Loading required package: lattice jagsfit.mcmc &lt;- as.mcmc(jagsfit) densityplot(jagsfit.mcmc) For a more involved example, lets take a look at the simple regression fit to the cricket data. First, well make a plot of the data and fit a SLR model by least squares. cricket &lt;- read.table(&quot;data/cricket.txt&quot;, header = TRUE) cricket.slr &lt;- lm(chirps ~ temperature, data = cricket) summary(cricket.slr) ## ## Call: ## lm(formula = chirps ~ temperature, data = cricket) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.56009 -0.57930 0.03129 0.59020 1.53259 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.30914 3.10858 -0.099 0.922299 ## temperature 0.21193 0.03871 5.475 0.000107 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.9715 on 13 degrees of freedom ## Multiple R-squared: 0.6975, Adjusted R-squared: 0.6742 ## F-statistic: 29.97 on 1 and 13 DF, p-value: 0.0001067 plot(chirps ~ temperature, data = cricket) abline(cricket.slr) Now well fit the same model in JAGS, using vague priors for all model parameters cricket.model &lt;- function() { for (j in 1:J) { # J = number of data points y[j] ~ dnorm (mu[j], tau) # data model: the likelihood # note that BUGS / JAGS uses precision # instead of variance mu[j] &lt;- b0 + b1 * x[j] # compute the mean for each observation } b0 ~ dnorm (0.0, 1E-6) # prior for intercept b1 ~ dnorm (0.0, 1E-6) # prior for slope tau ~ dgamma (0.01, 0.01) # prior for tau # note that BUGS / JAGS parameterizes # gamma by shape, rate sigma &lt;- pow(tau, -1/2) # the SD of the residaul errors } jags.data &lt;- list(y = cricket$chirps, x = cricket$temperature, J = nrow(cricket)) jags.params &lt;- c(&quot;b0&quot;, &quot;b1&quot;, &quot;tau&quot;, &quot;sigma&quot;) jags.inits &lt;- function(){ list(&quot;b0&quot; = rnorm(1), &quot;b1&quot; = rnorm(1), &quot;tau&quot; = runif(1)) } jagsfit &lt;- jags(data = jags.data, inits = jags.inits, parameters.to.save = jags.params, model.file = cricket.model, n.chains = 3, n.iter = 5000) ## Compiling model graph ## Resolving undeclared variables ## Allocating nodes ## Graph information: ## Observed stochastic nodes: 15 ## Unobserved stochastic nodes: 3 ## Total graph size: 70 ## ## Initializing model print(jagsfit) ## Inference for Bugs model at &quot;C:/Users/krgross/AppData/Local/Temp/RtmpkNru5X/model229040922cb7.txt&quot;, fit using jags, ## 3 chains, each with 5000 iterations (first 2500 discarded), n.thin = 2 ## n.sims = 3750 iterations saved ## mu.vect sd.vect 2.5% 25% 50% 75% 97.5% Rhat n.eff ## b0 -0.269 3.364 -6.743 -2.470 -0.280 1.859 6.430 1.001 3800 ## b1 0.211 0.042 0.129 0.185 0.212 0.239 0.293 1.001 3800 ## sigma 1.031 0.224 0.706 0.876 0.995 1.147 1.549 1.001 3700 ## tau 1.063 0.415 0.417 0.760 1.009 1.305 2.005 1.001 3700 ## deviance 42.888 2.715 39.827 40.925 42.204 44.055 49.855 1.002 1500 ## ## For each parameter, n.eff is a crude measure of effective sample size, ## and Rhat is the potential scale reduction factor (at convergence, Rhat=1). ## ## DIC info (using the rule, pD = var(deviance)/2) ## pD = 3.7 and DIC = 46.6 ## DIC is an estimate of expected predictive error (lower deviance is better). traceplot(jagsfit) The traces for the intercept arent great, but we havent centered the predictor either. In the usual way, the slope and intercept are strongly negatively correlated in the posterior. We can visualize this posterior correlation: library(hexbin) ## Warning: package &#39;hexbin&#39; was built under R version 4.1.1 library(RColorBrewer) rf &lt;- colorRampPalette(rev(brewer.pal(11, &#39;Spectral&#39;))) with(jagsfit$BUGSoutput$sims.list, hexbinplot(b1 ~ b0, colramp = rf)) We can estimate the posterior correlation between the intercept and the slope by accessing the raw MCMC samples mcmc.output &lt;- as.data.frame(jagsfit$BUGSoutput$sims.list) summary(mcmc.output) ## b0 b1 deviance sigma ## Min. :-14.6988 Min. :0.03208 Min. :39.57 Min. :0.5708 ## 1st Qu.: -2.4700 1st Qu.:0.18505 1st Qu.:40.93 1st Qu.:0.8755 ## Median : -0.2801 Median :0.21158 Median :42.20 Median :0.9954 ## Mean : -0.2686 Mean :0.21137 Mean :42.89 Mean :1.0308 ## 3rd Qu.: 1.8588 3rd Qu.:0.23852 3rd Qu.:44.05 3rd Qu.:1.1474 ## Max. : 13.7429 Max. :0.39724 Max. :64.34 Max. :3.0699 ## tau ## Min. :0.1061 ## 1st Qu.:0.7596 ## Median :1.0092 ## Mean :1.0631 ## 3rd Qu.:1.3046 ## Max. :3.0692 cor(mcmc.output[, -c(3:4)]) ## b0 b1 tau ## b0 1.000000e+00 -0.996634026 2.176845e-05 ## b1 -9.966340e-01 1.000000000 1.487399e-03 ## tau 2.176845e-05 0.001487399 1.000000e+00 Thus we estimate that the intercept and slope have a posterior correlation of -0.997. We could make life easier on ourselves by centering the predictor and trying again: cricket$temp.ctr &lt;- cricket$temperature - mean(cricket$temperature) jags.data &lt;- list(y = cricket$chirps, x = cricket$temp.ctr, J = nrow(cricket)) jags.params &lt;- c(&quot;b0&quot;, &quot;b1&quot;, &quot;tau&quot;, &quot;sigma&quot;) jags.inits &lt;- function(){ list(&quot;b0&quot; = rnorm(1), &quot;b1&quot; = rnorm(1), &quot;tau&quot; = runif(1)) } jagsfit &lt;- jags(data = jags.data, inits = jags.inits, parameters.to.save = jags.params, model.file = cricket.model, n.chains = 3, n.iter = 5000) ## Compiling model graph ## Resolving undeclared variables ## Allocating nodes ## Graph information: ## Observed stochastic nodes: 15 ## Unobserved stochastic nodes: 3 ## Total graph size: 70 ## ## Initializing model print(jagsfit) ## Inference for Bugs model at &quot;C:/Users/krgross/AppData/Local/Temp/RtmpkNru5X/model2290450834ec.txt&quot;, fit using jags, ## 3 chains, each with 5000 iterations (first 2500 discarded), n.thin = 2 ## n.sims = 3750 iterations saved ## mu.vect sd.vect 2.5% 25% 50% 75% 97.5% Rhat n.eff ## b0 16.651 0.275 16.102 16.475 16.653 16.832 17.179 1.003 780 ## b1 0.211 0.042 0.128 0.186 0.211 0.238 0.298 1.002 3800 ## sigma 1.035 0.221 0.702 0.877 1.002 1.150 1.563 1.001 3800 ## tau 1.053 0.412 0.409 0.756 0.995 1.301 2.030 1.001 3800 ## deviance 42.911 2.737 39.769 40.911 42.180 44.247 50.021 1.001 3800 ## ## For each parameter, n.eff is a crude measure of effective sample size, ## and Rhat is the potential scale reduction factor (at convergence, Rhat=1). ## ## DIC info (using the rule, pD = var(deviance)/2) ## pD = 3.7 and DIC = 46.7 ## DIC is an estimate of expected predictive error (lower deviance is better). traceplot(jagsfit) The posteriors for the intercept and slope are now uncorrelated: library(hexbin) library(RColorBrewer) rf &lt;- colorRampPalette(rev(brewer.pal(11, &#39;Spectral&#39;))) with(jagsfit$BUGSoutput$sims.list, hexbinplot(b1 ~ b0, colramp = rf)) mcmc.output &lt;- as.data.frame(jagsfit$BUGSoutput$sims.list) cor(mcmc.output[, -c(3:4)]) ## b0 b1 tau ## b0 1.000000000 -0.004609648 0.006585541 ## b1 -0.004609648 1.000000000 -0.004604030 ## tau 0.006585541 -0.004604030 1.000000000 3.3 rstanarm The rstanarm package is a recent set of routines that seeks to provide a user-friendly front end to Bayesian analysis with Stan. Specifically, rstanarm provides functions for fitting standard statistical models that are meant to mimic the analogous fitting functions in R. For example, the basic routine for fitting linear models in R is lm; rstanarm provides a function stan_lm that strives to have the same functionality and interface as lm, albeit using Stan under the hood to generate Bayesian inference. (That said, the main workhorse function in rstanarm for model fitting is stan_glm, which attempts to mimic the native R function glm for fitting generalized linear models. Separately, the developers of rstanarm have taken the not unreasonable stance that generalized linear models should supplant general linear models as the analysts default approach to model fitting.) To provide functionality that is similar to Rs native model-fitting routines, the functions in rstanarm make a number of operational decisions behind the scenes. Most notably, the model fitting routines in rstanarm will select default priors and default HMC parameters. While these defaults can always be modified by the analyst, the implementation of software that chooses priors by default is radical. First, the developers of rstanarm have their own particular view about what the role of the prior should be in data analysis. While their view is a considered one, by no means does it reflect a consensus that extends beyond the developers of the software. If you use rstanarms routines out of the box, you are accepting this view as your own if you do not specify the priors yourself. Second, as best I understand, the methods by which rstanarm chooses default priors still appear to be in some flux. That means that future versions of rstanarm may supply different default priors than those that are supplied today. As a result, the behavior of rstanarm today may differ from its behavior tomorrow, if you use the default priors. All that said, here is how you might use rstanarm most simply to fit the two working examples in this chapter. Well begin by fitting the horse-kick data: require(rstanarm) ## Loading required package: rstanarm ## Loading required package: Rcpp ## This is rstanarm version 2.21.1 ## - See https://mc-stan.org/rstanarm/articles/priors for changes to default priors! ## - Default priors may change, so it&#39;s safest to specify priors, even if equivalent to the defaults. ## - For execution on a local, multicore CPU with excess RAM we recommend calling ## options(mc.cores = parallel::detectCores()) stanarm.horse.fit &lt;- stan_glm(deaths ~ 1, data = horse, family = poisson, seed = 1) ## ## SAMPLING FOR MODEL &#39;count&#39; NOW (CHAIN 1). ## Chain 1: ## Chain 1: Gradient evaluation took 0 seconds ## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds. ## Chain 1: Adjust your expectations accordingly! ## Chain 1: ## Chain 1: ## Chain 1: Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 1: Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 1: Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 1: Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 1: Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 1: Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 1: Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 1: Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 1: Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 1: Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 1: Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 1: Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 1: ## Chain 1: Elapsed Time: 0.234 seconds (Warm-up) ## Chain 1: 0.227 seconds (Sampling) ## Chain 1: 0.461 seconds (Total) ## Chain 1: ## ## SAMPLING FOR MODEL &#39;count&#39; NOW (CHAIN 2). ## Chain 2: ## Chain 2: Gradient evaluation took 0 seconds ## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds. ## Chain 2: Adjust your expectations accordingly! ## Chain 2: ## Chain 2: ## Chain 2: Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 2: Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 2: Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 2: Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 2: Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 2: Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 2: Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 2: Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 2: Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 2: Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 2: Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 2: Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 2: ## Chain 2: Elapsed Time: 0.213 seconds (Warm-up) ## Chain 2: 0.279 seconds (Sampling) ## Chain 2: 0.492 seconds (Total) ## Chain 2: ## ## SAMPLING FOR MODEL &#39;count&#39; NOW (CHAIN 3). ## Chain 3: ## Chain 3: Gradient evaluation took 0 seconds ## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds. ## Chain 3: Adjust your expectations accordingly! ## Chain 3: ## Chain 3: ## Chain 3: Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 3: Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 3: Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 3: Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 3: Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 3: Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 3: Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 3: Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 3: Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 3: Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 3: Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 3: Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 3: ## Chain 3: Elapsed Time: 0.205 seconds (Warm-up) ## Chain 3: 0.265 seconds (Sampling) ## Chain 3: 0.47 seconds (Total) ## Chain 3: ## ## SAMPLING FOR MODEL &#39;count&#39; NOW (CHAIN 4). ## Chain 4: ## Chain 4: Gradient evaluation took 0 seconds ## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds. ## Chain 4: Adjust your expectations accordingly! ## Chain 4: ## Chain 4: ## Chain 4: Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 4: Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 4: Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 4: Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 4: Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 4: Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 4: Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 4: Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 4: Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 4: Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 4: Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 4: Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 4: ## Chain 4: Elapsed Time: 0.194 seconds (Warm-up) ## Chain 4: 0.254 seconds (Sampling) ## Chain 4: 0.448 seconds (Total) ## Chain 4: The model formula (deaths ~ 1) requires a bit of explanation. Essentially, we are fitting a regression model that only includes an intercept. In R, the way to fit a model with only an intercept is to include a 1 on the right-hand side of the model formula. The call to stan_glm is meant to mimic the call Here we have supplied the random number seed for the HMC sampling. Lets take a look: print(stanarm.horse.fit, digits = 3) ## stan_glm ## family: poisson [log] ## formula: deaths ~ 1 ## observations: 280 ## predictors: 1 ## ------ ## Median MAD_SD ## (Intercept) -0.355 0.073 ## ## ------ ## * For help interpreting the printed output see ?print.stanreg ## * For info on the priors used see ?prior_summary.stanreg The parameter labeled (Intercept) is \\(\\log(\\lambda)\\). Now well fit the simple regression to the cricket data: stanarm.cricket.fit &lt;- stan_glm(chirps ~ temp.ctr, data = cricket, family = gaussian, seed = 1) ## ## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 1). ## Chain 1: ## Chain 1: Gradient evaluation took 0 seconds ## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds. ## Chain 1: Adjust your expectations accordingly! ## Chain 1: ## Chain 1: ## Chain 1: Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 1: Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 1: Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 1: Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 1: Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 1: Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 1: Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 1: Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 1: Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 1: Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 1: Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 1: Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 1: ## Chain 1: Elapsed Time: 0.11 seconds (Warm-up) ## Chain 1: 0.095 seconds (Sampling) ## Chain 1: 0.205 seconds (Total) ## Chain 1: ## ## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 2). ## Chain 2: ## Chain 2: Gradient evaluation took 0 seconds ## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds. ## Chain 2: Adjust your expectations accordingly! ## Chain 2: ## Chain 2: ## Chain 2: Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 2: Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 2: Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 2: Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 2: Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 2: Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 2: Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 2: Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 2: Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 2: Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 2: Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 2: Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 2: ## Chain 2: Elapsed Time: 0.089 seconds (Warm-up) ## Chain 2: 0.073 seconds (Sampling) ## Chain 2: 0.162 seconds (Total) ## Chain 2: ## ## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 3). ## Chain 3: ## Chain 3: Gradient evaluation took 0 seconds ## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds. ## Chain 3: Adjust your expectations accordingly! ## Chain 3: ## Chain 3: ## Chain 3: Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 3: Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 3: Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 3: Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 3: Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 3: Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 3: Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 3: Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 3: Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 3: Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 3: Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 3: Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 3: ## Chain 3: Elapsed Time: 0.065 seconds (Warm-up) ## Chain 3: 0.065 seconds (Sampling) ## Chain 3: 0.13 seconds (Total) ## Chain 3: ## ## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 4). ## Chain 4: ## Chain 4: Gradient evaluation took 0 seconds ## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds. ## Chain 4: Adjust your expectations accordingly! ## Chain 4: ## Chain 4: ## Chain 4: Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 4: Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 4: Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 4: Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 4: Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 4: Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 4: Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 4: Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 4: Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 4: Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 4: Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 4: Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 4: ## Chain 4: Elapsed Time: 0.071 seconds (Warm-up) ## Chain 4: 0.061 seconds (Sampling) ## Chain 4: 0.132 seconds (Total) ## Chain 4: print(stanarm.cricket.fit, digits = 3) ## stan_glm ## family: gaussian [identity] ## formula: chirps ~ temp.ctr ## observations: 15 ## predictors: 2 ## ------ ## Median MAD_SD ## (Intercept) 16.648 0.257 ## temp.ctr 0.210 0.041 ## ## Auxiliary parameter(s): ## Median MAD_SD ## sigma 1.008 0.198 ## ## ------ ## * For help interpreting the printed output see ?print.stanreg ## * For info on the priors used see ?prior_summary.stanreg "]]
