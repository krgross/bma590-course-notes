<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Bayesian computation | Computing companion for BMA / ST 590, Fall 2021</title>
  <meta name="description" content="Computing companion for BMA / ST 590, Statistical Modeling in Ecology, NCSU, Fall 2021." />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Bayesian computation | Computing companion for BMA / ST 590, Fall 2021" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Computing companion for BMA / ST 590, Statistical Modeling in Ecology, NCSU, Fall 2021." />
  <meta name="github-repo" content="krgross/bma590-course-notes" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Bayesian computation | Computing companion for BMA / ST 590, Fall 2021" />
  
  <meta name="twitter:description" content="Computing companion for BMA / ST 590, Statistical Modeling in Ecology, NCSU, Fall 2021." />
  

<meta name="author" content="Kevin Gross" />


<meta name="date" content="2021-10-11" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="beyond-the-mle-confidence-regions-and-hypothesis-tests-using-the-likelihood-function.html"/>
<link rel="next" href="smooth-regression.html"/>
<script src="libs/header-attrs-2.9/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html"><i class="fa fa-check"></i><b>1</b> Maximum likelihood estimation</a>
<ul>
<li class="chapter" data-level="1.1" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#a-very-simple-example-with-a-single-observation"><i class="fa fa-check"></i><b>1.1</b> A very simple example with a single observation</a></li>
<li class="chapter" data-level="1.2" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#horse-kick-data"><i class="fa fa-check"></i><b>1.2</b> Horse-kick data</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#calculate-and-plot-the-log-likelihood-function"><i class="fa fa-check"></i><b>1.2.1</b> Calculate and plot the log-likelihood function</a></li>
<li class="chapter" data-level="1.2.2" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#find-the-mle-numerically-using-optimize"><i class="fa fa-check"></i><b>1.2.2</b> Find the MLE numerically using ‘optimize’</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#myxomatosis-data"><i class="fa fa-check"></i><b>1.3</b> Myxomatosis data</a></li>
<li class="chapter" data-level="1.4" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#tadpole-data"><i class="fa fa-check"></i><b>1.4</b> Tadpole data</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="beyond-the-mle-confidence-regions-and-hypothesis-tests-using-the-likelihood-function.html"><a href="beyond-the-mle-confidence-regions-and-hypothesis-tests-using-the-likelihood-function.html"><i class="fa fa-check"></i><b>2</b> Beyond the MLE: Confidence regions and hypothesis tests using the likelihood function</a>
<ul>
<li class="chapter" data-level="2.1" data-path="beyond-the-mle-confidence-regions-and-hypothesis-tests-using-the-likelihood-function.html"><a href="beyond-the-mle-confidence-regions-and-hypothesis-tests-using-the-likelihood-function.html#confidence-intervals-for-single-parameters"><i class="fa fa-check"></i><b>2.1</b> Confidence intervals for single parameters</a></li>
<li class="chapter" data-level="2.2" data-path="beyond-the-mle-confidence-regions-and-hypothesis-tests-using-the-likelihood-function.html"><a href="beyond-the-mle-confidence-regions-and-hypothesis-tests-using-the-likelihood-function.html#two-param-mle"><i class="fa fa-check"></i><b>2.2</b> Confidence regions, profile likelihoods, and associated univariate intervals</a></li>
<li class="chapter" data-level="2.3" data-path="beyond-the-mle-confidence-regions-and-hypothesis-tests-using-the-likelihood-function.html"><a href="beyond-the-mle-confidence-regions-and-hypothesis-tests-using-the-likelihood-function.html#locally-quadratic-approximations-to-confidence-intervals-and-regions"><i class="fa fa-check"></i><b>2.3</b> Locally quadratic approximations to confidence intervals and regions</a></li>
<li class="chapter" data-level="2.4" data-path="beyond-the-mle-confidence-regions-and-hypothesis-tests-using-the-likelihood-function.html"><a href="beyond-the-mle-confidence-regions-and-hypothesis-tests-using-the-likelihood-function.html#comparing-models-likelihood-ratio-test-and-aic"><i class="fa fa-check"></i><b>2.4</b> Comparing models: Likelihood ratio test and AIC</a></li>
<li class="chapter" data-level="2.5" data-path="beyond-the-mle-confidence-regions-and-hypothesis-tests-using-the-likelihood-function.html"><a href="beyond-the-mle-confidence-regions-and-hypothesis-tests-using-the-likelihood-function.html#transformable-constraints"><i class="fa fa-check"></i><b>2.5</b> Transformable constraints</a></li>
<li class="chapter" data-level="2.6" data-path="beyond-the-mle-confidence-regions-and-hypothesis-tests-using-the-likelihood-function.html"><a href="beyond-the-mle-confidence-regions-and-hypothesis-tests-using-the-likelihood-function.html#the-negative-binomial-distriution-revisited"><i class="fa fa-check"></i><b>2.6</b> The negative binomial distriution, revisited</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="bayesian-computation.html"><a href="bayesian-computation.html"><i class="fa fa-check"></i><b>3</b> Bayesian computation</a>
<ul>
<li class="chapter" data-level="3.1" data-path="bayesian-computation.html"><a href="bayesian-computation.html#computations-with-conjugate-priors"><i class="fa fa-check"></i><b>3.1</b> Computations with conjugate priors</a></li>
<li class="chapter" data-level="3.2" data-path="bayesian-computation.html"><a href="bayesian-computation.html#jags-in-r"><i class="fa fa-check"></i><b>3.2</b> JAGS in R</a></li>
<li class="chapter" data-level="3.3" data-path="bayesian-computation.html"><a href="bayesian-computation.html#rstanarm"><i class="fa fa-check"></i><b>3.3</b> rstanarm</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="smooth-regression.html"><a href="smooth-regression.html"><i class="fa fa-check"></i><b>4</b> Smooth regression</a>
<ul>
<li class="chapter" data-level="4.1" data-path="smooth-regression.html"><a href="smooth-regression.html#loess-smoothers"><i class="fa fa-check"></i><b>4.1</b> Loess smoothers</a></li>
<li class="chapter" data-level="4.2" data-path="smooth-regression.html"><a href="smooth-regression.html#splines"><i class="fa fa-check"></i><b>4.2</b> Splines</a></li>
<li class="chapter" data-level="4.3" data-path="smooth-regression.html"><a href="smooth-regression.html#generalized-additive-models-gams"><i class="fa fa-check"></i><b>4.3</b> Generalized additive models (GAMs)</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="generalized-least-squares.html"><a href="generalized-least-squares.html"><i class="fa fa-check"></i><b>5</b> Generalized Least Squares</a></li>
<li class="chapter" data-level="6" data-path="hierarchical-models.html"><a href="hierarchical-models.html"><i class="fa fa-check"></i><b>6</b> Hierarchical Models</a>
<ul>
<li class="chapter" data-level="6.1" data-path="hierarchical-models.html"><a href="hierarchical-models.html#one-factor-layout-dyestuff-data"><i class="fa fa-check"></i><b>6.1</b> One-factor layout: Dyestuff data</a></li>
<li class="chapter" data-level="6.2" data-path="hierarchical-models.html"><a href="hierarchical-models.html#bayesian-analysis"><i class="fa fa-check"></i><b>6.2</b> Bayesian analysis</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Computing companion for BMA / ST 590, Fall 2021</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="bayesian-computation" class="section level1" number="3">
<h1><span class="header-section-number">Chapter 3</span> Bayesian computation</h1>
<p>This chapter of the computing companion will focus solely on the computing aspects of Bayesian computation in R. See the course notes or relevant sections of Bolker for the underlying theory.</p>
<p>The landscape of computing tools available to fit Bayesian models is fluid. Here, we will look at three tools currently available: <code>R2jags</code>, which is based on the JAGS (Just Another Gibbs Sampler) platform, <code>rstan</code>, which is based on the computer program Stan (itself based on Hamiltonian Monte Carlo, or HMC), and the recent <code>rstanarm</code>, which seeks to put much of the computational details in the background. (The “arm” portion of the name <code>rstanarm</code> is an acronym for applied regression modeling.)</p>
<p>Throughout, we will be working with two data sets: the horse kick data (again), and a data set that details how the rate at which a cricket chirps depends on the air temperature. The horse kick data are useful in this context because a Gamma distribution is a conjugate prior for Poisson data. Thus, if we use a Gamma prior, then we know the posterior exactly. Therefore, we can compare the approximations provided by stochastic sampling schemes to the known posterior. The cricket data set will be used as an example of a simple linear regression, even though the data hint that the actual relationship between temperature and the rate of chirping is nonlinear.</p>
<div id="computations-with-conjugate-priors" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Computations with conjugate priors</h2>
<p>Suppose that we observe an iid random sample <span class="math inline">\(X_1, \ldots, X_n\)</span> from a Poisson distribution with unknown parameter <span class="math inline">\(\lambda\)</span>. (This is the setting for the horse-kick data.) If we place a Gamma prior with shape parameter <span class="math inline">\(a\)</span> and rate parameter <span class="math inline">\(r\)</span> on <span class="math inline">\(\lambda\)</span>, then the posterior distribution is also Gamma with shape parameter <span class="math inline">\(a + \sum_n X_n\)</span> and rate parameter <span class="math inline">\(r + n\)</span>. In other words,
<span class="math display">\[\begin{align*}
\lambda &amp; \sim \mbox{Gamma}(a, r) \\
X_1, \ldots, X_n &amp; \sim \mbox{Pois}(\lambda) \\
\lambda | X_1, \ldots, X_n &amp; \sim \mbox{Gamma}(a + \sum_n X_n, r + n) \\
\end{align*}\]</span></p>
<p>In the horse kick data, <span class="math inline">\(\sum_n x_n = 196\)</span> and <span class="math inline">\(n = 280\)</span>. Suppose we start with the vague Gamma prior <span class="math inline">\(a=.01\)</span>, <span class="math inline">\(r = .01\)</span> on <span class="math inline">\(\lambda\)</span>. This prior has mean <span class="math inline">\(a/r = 1\)</span> and variance <span class="math inline">\(a/r^2 = 100\)</span>. The posterior distribution for <span class="math inline">\(\lambda\)</span> is then a Gamma with shape parameter <span class="math inline">\(a = 196.01\)</span> and rate parameter <span class="math inline">\(280.01\)</span>. We can plot it:</p>
<div class="sourceCode" id="cb171"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb171-1"><a href="bayesian-computation.html#cb171-1" aria-hidden="true" tabindex="-1"></a>horse <span class="ot">&lt;-</span> <span class="fu">read.table</span>(<span class="st">&quot;data/horse.txt&quot;</span>, </span>
<span id="cb171-2"><a href="bayesian-computation.html#cb171-2" aria-hidden="true" tabindex="-1"></a>                    <span class="at">header =</span> <span class="cn">TRUE</span>,</span>
<span id="cb171-3"><a href="bayesian-computation.html#cb171-3" aria-hidden="true" tabindex="-1"></a>                    <span class="at">stringsAsFactors =</span> <span class="cn">TRUE</span>)</span>
<span id="cb171-4"><a href="bayesian-computation.html#cb171-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb171-5"><a href="bayesian-computation.html#cb171-5" aria-hidden="true" tabindex="-1"></a>l.vals <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">2</span>, <span class="at">length =</span> <span class="dv">200</span>)</span>
<span id="cb171-6"><a href="bayesian-computation.html#cb171-6" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(l.vals, <span class="fu">dgamma</span>(l.vals, <span class="at">shape =</span> <span class="fl">196.01</span>, <span class="at">rate =</span> <span class="fl">280.01</span>), <span class="at">type =</span> <span class="st">&quot;l&quot;</span>, </span>
<span id="cb171-7"><a href="bayesian-computation.html#cb171-7" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="fu">expression</span>(lambda), <span class="at">ylab =</span> <span class="st">&quot;&quot;</span>)</span>
<span id="cb171-8"><a href="bayesian-computation.html#cb171-8" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(l.vals, <span class="fu">dgamma</span>(l.vals, <span class="at">shape =</span> .<span class="dv">01</span>, <span class="at">rate =</span> .<span class="dv">01</span>), <span class="at">lty =</span> <span class="st">&quot;dashed&quot;</span>)</span>
<span id="cb171-9"><a href="bayesian-computation.html#cb171-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb171-10"><a href="bayesian-computation.html#cb171-10" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fl">0.7</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span>
<span id="cb171-11"><a href="bayesian-computation.html#cb171-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb171-12"><a href="bayesian-computation.html#cb171-12" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topleft&quot;</span>, <span class="at">leg =</span> <span class="fu">c</span>(<span class="st">&quot;prior&quot;</span>, <span class="st">&quot;posterior&quot;</span>), </span>
<span id="cb171-13"><a href="bayesian-computation.html#cb171-13" aria-hidden="true" tabindex="-1"></a>       <span class="at">lty =</span> <span class="fu">c</span>(<span class="st">&quot;dashed&quot;</span>, <span class="st">&quot;solid&quot;</span>))</span></code></pre></div>
<p><img src="03-BayesianIntro_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p>The red line shows the MLE, which is displaced slightly from the posterior mode.</p>
<p>As a point estimate, we might consider any of the following. The posterior mean can be found exactly as <span class="math inline">\(a/r\)</span> = 0.70001. Alternatively, we might consider the posterior median</p>
<div class="sourceCode" id="cb172"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb172-1"><a href="bayesian-computation.html#cb172-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qgamma</span>(<span class="fl">0.5</span>, <span class="at">shape =</span> <span class="fl">196.01</span>, <span class="at">rate =</span> <span class="fl">280.01</span>)</span></code></pre></div>
<pre><code>## [1] 0.6988206</code></pre>
<p>Finally, we might conisder the posterior mode:</p>
<div class="sourceCode" id="cb174"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb174-1"><a href="bayesian-computation.html#cb174-1" aria-hidden="true" tabindex="-1"></a><span class="fu">optimize</span>(<span class="at">f =</span> <span class="cf">function</span>(x) <span class="fu">dgamma</span>(x, <span class="at">shape =</span> <span class="fl">196.01</span>, <span class="at">rate =</span> <span class="fl">280.01</span>), <span class="at">interval =</span> <span class="fu">c</span>(<span class="fl">0.5</span>, <span class="dv">1</span>), <span class="at">maximum =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## $maximum
## [1] 0.6964383
## 
## $objective
## [1] 7.995941</code></pre>
<p>To find a 95% confidence interval, we might consider the central 95% interval:</p>
<div class="sourceCode" id="cb176"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb176-1"><a href="bayesian-computation.html#cb176-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qgamma</span>(<span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>), <span class="at">shape =</span> <span class="fl">196.01</span>, <span class="at">rate =</span> <span class="fl">280.01</span>)</span></code></pre></div>
<pre><code>## [1] 0.6054387 0.8013454</code></pre>
<p>A 95% highest posterior density (HPD) interval takes a bit more work:</p>
<div class="sourceCode" id="cb178"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb178-1"><a href="bayesian-computation.html#cb178-1" aria-hidden="true" tabindex="-1"></a>diff.in.pdf <span class="ot">&lt;-</span> <span class="cf">function</span>(x){</span>
<span id="cb178-2"><a href="bayesian-computation.html#cb178-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb178-3"><a href="bayesian-computation.html#cb178-3" aria-hidden="true" tabindex="-1"></a>  upper <span class="ot">&lt;-</span> <span class="fu">qgamma</span>(<span class="at">p =</span> x, <span class="at">shape =</span> <span class="fl">196.01</span>, <span class="at">rate =</span> <span class="fl">280.01</span>)</span>
<span id="cb178-4"><a href="bayesian-computation.html#cb178-4" aria-hidden="true" tabindex="-1"></a>  lower <span class="ot">&lt;-</span> <span class="fu">qgamma</span>(<span class="at">p =</span> x <span class="sc">-</span> .<span class="dv">95</span>, <span class="at">shape =</span> <span class="fl">196.01</span>, <span class="at">rate =</span> <span class="fl">280.01</span>)</span>
<span id="cb178-5"><a href="bayesian-computation.html#cb178-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb178-6"><a href="bayesian-computation.html#cb178-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dgamma</span>(upper, <span class="at">shape =</span> <span class="fl">196.01</span>, <span class="at">rate =</span> <span class="fl">280.01</span>) <span class="sc">-</span> <span class="fu">dgamma</span>(lower, <span class="at">shape =</span> <span class="fl">196.01</span>, <span class="at">rate =</span> <span class="fl">280.01</span>)</span>
<span id="cb178-7"><a href="bayesian-computation.html#cb178-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb178-8"><a href="bayesian-computation.html#cb178-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb178-9"><a href="bayesian-computation.html#cb178-9" aria-hidden="true" tabindex="-1"></a>(upper.qtile <span class="ot">&lt;-</span> <span class="fu">uniroot</span>(diff.in.pdf, <span class="at">interval =</span> <span class="fu">c</span>(<span class="fl">0.95</span>, <span class="dv">1</span>))<span class="sc">$</span>root)</span></code></pre></div>
<pre><code>## [1] 0.9722176</code></pre>
<div class="sourceCode" id="cb180"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb180-1"><a href="bayesian-computation.html#cb180-1" aria-hidden="true" tabindex="-1"></a>(hpd.ci <span class="ot">&lt;-</span> <span class="fu">qgamma</span>(<span class="at">p =</span> <span class="fu">c</span>(upper.qtile <span class="sc">-</span> .<span class="dv">95</span>, upper.qtile), <span class="at">shape =</span> <span class="fl">196.01</span>, <span class="at">rate =</span> <span class="fl">280.01</span>))</span></code></pre></div>
<pre><code>## [1] 0.6031732 0.7988576</code></pre>
<p>We might also ask questions like: What is the posterior probability that <span class="math inline">\(\lambda &gt; 2/3\)</span>? These caluclations are straightforward in a Bayesian context, and they make full sense.</p>
<div class="sourceCode" id="cb182"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb182-1"><a href="bayesian-computation.html#cb182-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pgamma</span>(<span class="dv">2</span><span class="sc">/</span><span class="dv">3</span>, <span class="at">shape =</span> <span class="fl">196.01</span>, <span class="at">rate =</span> <span class="fl">280.01</span>, <span class="at">lower.tail =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<pre><code>## [1] 0.7434032</code></pre>
<p>Thus we would say that there is a 0.743 posterior probability that <span class="math inline">\(\lambda &gt; 2/3\)</span>.</p>
<p>As an illustration, note that if we had begun with a more informative prior — say, a gamma distribution with shape parameter <span class="math inline">\(a = 50\)</span> and rate parameter = <span class="math inline">\(100\)</span> — then the posterior would have been more of a compromise between the prior and the information in the data:</p>
<div class="sourceCode" id="cb184"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb184-1"><a href="bayesian-computation.html#cb184-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(l.vals, <span class="fu">dgamma</span>(l.vals, <span class="at">shape =</span> <span class="dv">196</span> <span class="sc">+</span> <span class="dv">50</span>, <span class="at">rate =</span> <span class="dv">100</span> <span class="sc">+</span> <span class="dv">280</span>), <span class="at">type =</span> <span class="st">&quot;l&quot;</span>, </span>
<span id="cb184-2"><a href="bayesian-computation.html#cb184-2" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="fu">expression</span>(lambda), <span class="at">ylab =</span> <span class="st">&quot;&quot;</span>)</span>
<span id="cb184-3"><a href="bayesian-computation.html#cb184-3" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(l.vals, <span class="fu">dgamma</span>(l.vals, <span class="at">shape =</span> <span class="dv">50</span>, <span class="at">rate =</span> <span class="dv">100</span>), <span class="at">lty =</span> <span class="st">&quot;dashed&quot;</span>)</span>
<span id="cb184-4"><a href="bayesian-computation.html#cb184-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb184-5"><a href="bayesian-computation.html#cb184-5" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fl">0.7</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span>
<span id="cb184-6"><a href="bayesian-computation.html#cb184-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb184-7"><a href="bayesian-computation.html#cb184-7" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topleft&quot;</span>, <span class="at">leg =</span> <span class="fu">c</span>(<span class="st">&quot;prior&quot;</span>, <span class="st">&quot;posterior&quot;</span>), </span>
<span id="cb184-8"><a href="bayesian-computation.html#cb184-8" aria-hidden="true" tabindex="-1"></a>       <span class="at">lty =</span> <span class="fu">c</span>(<span class="st">&quot;dashed&quot;</span>, <span class="st">&quot;solid&quot;</span>))</span></code></pre></div>
<p><img src="03-BayesianIntro_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
</div>
<div id="jags-in-r" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> JAGS in R</h2>
<p>All of the computational tools that we will examine in this section involve some form of stochastic sampling from the posterior. This computing companion will largely use the default settings, though in real practice the analyst will often have to do considerable work adjusting the settings to obtain a satisfactory approximation.</p>
<p>We’ll use JAGS through R, using the library <code>r2jags</code>. Here is JAGS code to approximate the posterior to <span class="math inline">\(\lambda\)</span> for the horse kick data, using the vague prior.</p>
<div class="sourceCode" id="cb185"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb185-1"><a href="bayesian-computation.html#cb185-1" aria-hidden="true" tabindex="-1"></a><span class="fu">require</span>(R2jags)</span></code></pre></div>
<pre><code>## Loading required package: R2jags</code></pre>
<pre><code>## Warning: package &#39;R2jags&#39; was built under R version 4.1.1</code></pre>
<pre><code>## Loading required package: rjags</code></pre>
<pre><code>## Warning: package &#39;rjags&#39; was built under R version 4.1.1</code></pre>
<pre><code>## Loading required package: coda</code></pre>
<pre><code>## Linked to JAGS 4.3.0</code></pre>
<pre><code>## Loaded modules: basemod,bugs</code></pre>
<pre><code>## 
## Attaching package: &#39;R2jags&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:coda&#39;:
## 
##     traceplot</code></pre>
<div class="sourceCode" id="cb195"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb195-1"><a href="bayesian-computation.html#cb195-1" aria-hidden="true" tabindex="-1"></a>horse.model <span class="ot">&lt;-</span> <span class="cf">function</span>() {</span>
<span id="cb195-2"><a href="bayesian-computation.html#cb195-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb195-3"><a href="bayesian-computation.html#cb195-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>J) {             <span class="co"># J = 280, number of data points</span></span>
<span id="cb195-4"><a href="bayesian-computation.html#cb195-4" aria-hidden="true" tabindex="-1"></a>    y[j] <span class="sc">~</span> <span class="fu">dpois</span> (lambda)      <span class="co"># data model:  the likelihood      </span></span>
<span id="cb195-5"><a href="bayesian-computation.html#cb195-5" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb195-6"><a href="bayesian-computation.html#cb195-6" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb195-7"><a href="bayesian-computation.html#cb195-7" aria-hidden="true" tabindex="-1"></a>  lambda <span class="sc">~</span> <span class="fu">dgamma</span> (<span class="fl">0.01</span>, <span class="fl">0.01</span>) <span class="co"># prior </span></span>
<span id="cb195-8"><a href="bayesian-computation.html#cb195-8" aria-hidden="true" tabindex="-1"></a>                               <span class="co"># note that BUGS / JAGS parameterizes </span></span>
<span id="cb195-9"><a href="bayesian-computation.html#cb195-9" aria-hidden="true" tabindex="-1"></a>                               <span class="co"># gamma by shape, rate</span></span>
<span id="cb195-10"><a href="bayesian-computation.html#cb195-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb195-11"><a href="bayesian-computation.html#cb195-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb195-12"><a href="bayesian-computation.html#cb195-12" aria-hidden="true" tabindex="-1"></a>jags.data <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">y =</span> horse<span class="sc">$</span>deaths, <span class="at">J =</span> <span class="fu">length</span>(horse<span class="sc">$</span>deaths))</span>
<span id="cb195-13"><a href="bayesian-computation.html#cb195-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb195-14"><a href="bayesian-computation.html#cb195-14" aria-hidden="true" tabindex="-1"></a>jags.params <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;lambda&quot;</span>)</span>
<span id="cb195-15"><a href="bayesian-computation.html#cb195-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb195-16"><a href="bayesian-computation.html#cb195-16" aria-hidden="true" tabindex="-1"></a>jags.inits <span class="ot">&lt;-</span> <span class="cf">function</span>(){</span>
<span id="cb195-17"><a href="bayesian-computation.html#cb195-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">list</span>(<span class="st">&quot;lambda&quot;</span> <span class="ot">=</span> <span class="fu">rgamma</span>(<span class="fl">0.01</span>, <span class="fl">0.01</span>))</span>
<span id="cb195-18"><a href="bayesian-computation.html#cb195-18" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb195-19"><a href="bayesian-computation.html#cb195-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb195-20"><a href="bayesian-computation.html#cb195-20" aria-hidden="true" tabindex="-1"></a>jagsfit <span class="ot">&lt;-</span> <span class="fu">jags</span>(<span class="at">data               =</span> jags.data, </span>
<span id="cb195-21"><a href="bayesian-computation.html#cb195-21" aria-hidden="true" tabindex="-1"></a>                <span class="at">inits              =</span> jags.inits, </span>
<span id="cb195-22"><a href="bayesian-computation.html#cb195-22" aria-hidden="true" tabindex="-1"></a>                <span class="at">parameters.to.save =</span> jags.params,</span>
<span id="cb195-23"><a href="bayesian-computation.html#cb195-23" aria-hidden="true" tabindex="-1"></a>                <span class="at">model.file         =</span> horse.model,</span>
<span id="cb195-24"><a href="bayesian-computation.html#cb195-24" aria-hidden="true" tabindex="-1"></a>                <span class="at">n.chains           =</span> <span class="dv">3</span>,</span>
<span id="cb195-25"><a href="bayesian-computation.html#cb195-25" aria-hidden="true" tabindex="-1"></a>                <span class="at">n.iter             =</span> <span class="dv">5000</span>)</span></code></pre></div>
<pre><code>## module glm loaded</code></pre>
<pre><code>## Compiling model graph
##    Resolving undeclared variables
##    Allocating nodes
## Graph information:
##    Observed stochastic nodes: 280
##    Unobserved stochastic nodes: 1
##    Total graph size: 283
## 
## Initializing model</code></pre>
<p>Let’s take a look at some summary statistics of the fit</p>
<div class="sourceCode" id="cb198"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb198-1"><a href="bayesian-computation.html#cb198-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(jagsfit)</span></code></pre></div>
<pre><code>## Inference for Bugs model at &quot;C:/Users/krgross/AppData/Local/Temp/Rtmp6pTrk2/model668290e7869.txt&quot;, fit using jags,
##  3 chains, each with 5000 iterations (first 2500 discarded), n.thin = 2
##  n.sims = 3750 iterations saved
##          mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
## lambda     0.700   0.050   0.606   0.666   0.699   0.733   0.799 1.001  3800
## deviance 629.296   1.392 628.310 628.403 628.763 629.618 633.333 1.001  3800
## 
## For each parameter, n.eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor (at convergence, Rhat=1).
## 
## DIC info (using the rule, pD = var(deviance)/2)
## pD = 1.0 and DIC = 630.3
## DIC is an estimate of expected predictive error (lower deviance is better).</code></pre>
<p>The Rhat values suggest that our chains have converged, as we might hope for such a simple model. We can generate a trace plot using <code>traceplot</code> to inspect convergence visually, but beware that visual assessment of convergence is prone to error.</p>
<p>For an rjags object, the raw MCMC samples are stored in <code>BUGSoutput$sims.list</code>. Sometimes it is helpful to analyze these samples directly. For example, with these samples we can estimate other posterior quantities, such as the posterior median of <span class="math inline">\(\lambda\)</span>, or generate a 95% central posterior confidence interval directly:</p>
<div class="sourceCode" id="cb200"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb200-1"><a href="bayesian-computation.html#cb200-1" aria-hidden="true" tabindex="-1"></a>mcmc.output <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(jagsfit<span class="sc">$</span>BUGSoutput<span class="sc">$</span>sims.list)</span>
<span id="cb200-2"><a href="bayesian-computation.html#cb200-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mcmc.output)</span></code></pre></div>
<pre><code>##     deviance         lambda      
##  Min.   :628.3   Min.   :0.5376  
##  1st Qu.:628.4   1st Qu.:0.6664  
##  Median :628.8   Median :0.6995  
##  Mean   :629.3   Mean   :0.7001  
##  3rd Qu.:629.6   3rd Qu.:0.7334  
##  Max.   :640.8   Max.   :0.8829</code></pre>
<div class="sourceCode" id="cb202"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb202-1"><a href="bayesian-computation.html#cb202-1" aria-hidden="true" tabindex="-1"></a><span class="fu">median</span>(mcmc.output<span class="sc">$</span>lambda)</span></code></pre></div>
<pre><code>## [1] 0.6994849</code></pre>
<div class="sourceCode" id="cb204"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb204-1"><a href="bayesian-computation.html#cb204-1" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span>(mcmc.output<span class="sc">$</span>lambda, <span class="fu">c</span>(.<span class="dv">025</span>, .<span class="dv">975</span>))</span></code></pre></div>
<pre><code>##      2.5%     97.5% 
## 0.6057162 0.7993681</code></pre>
<p>We can also use the <code>lattice</code> package to construct smoothed estimates of the posterior density:</p>
<div class="sourceCode" id="cb206"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb206-1"><a href="bayesian-computation.html#cb206-1" aria-hidden="true" tabindex="-1"></a><span class="fu">require</span>(lattice)</span></code></pre></div>
<pre><code>## Loading required package: lattice</code></pre>
<div class="sourceCode" id="cb208"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb208-1"><a href="bayesian-computation.html#cb208-1" aria-hidden="true" tabindex="-1"></a>jagsfit.mcmc <span class="ot">&lt;-</span> <span class="fu">as.mcmc</span>(jagsfit)</span>
<span id="cb208-2"><a href="bayesian-computation.html#cb208-2" aria-hidden="true" tabindex="-1"></a><span class="fu">densityplot</span>(jagsfit.mcmc)</span></code></pre></div>
<p><img src="03-BayesianIntro_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>For a more involved example, let’s take a look at the simple regression fit to the cricket data. First, we’ll make a plot of the data and fit a SLR model by least squares.</p>
<div class="sourceCode" id="cb209"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb209-1"><a href="bayesian-computation.html#cb209-1" aria-hidden="true" tabindex="-1"></a>cricket <span class="ot">&lt;-</span> <span class="fu">read.table</span>(<span class="st">&quot;data/cricket.txt&quot;</span>, <span class="at">header =</span> <span class="cn">TRUE</span>)</span>
<span id="cb209-2"><a href="bayesian-computation.html#cb209-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb209-3"><a href="bayesian-computation.html#cb209-3" aria-hidden="true" tabindex="-1"></a>cricket.slr <span class="ot">&lt;-</span> <span class="fu">lm</span>(chirps <span class="sc">~</span> temperature, <span class="at">data =</span> cricket)</span>
<span id="cb209-4"><a href="bayesian-computation.html#cb209-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(cricket.slr)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = chirps ~ temperature, data = cricket)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.56009 -0.57930  0.03129  0.59020  1.53259 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -0.30914    3.10858  -0.099 0.922299    
## temperature  0.21193    0.03871   5.475 0.000107 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9715 on 13 degrees of freedom
## Multiple R-squared:  0.6975, Adjusted R-squared:  0.6742 
## F-statistic: 29.97 on 1 and 13 DF,  p-value: 0.0001067</code></pre>
<div class="sourceCode" id="cb211"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb211-1"><a href="bayesian-computation.html#cb211-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(chirps <span class="sc">~</span> temperature, <span class="at">data =</span> cricket)</span>
<span id="cb211-2"><a href="bayesian-computation.html#cb211-2" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(cricket.slr)</span></code></pre></div>
<p><img src="03-BayesianIntro_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<p>Now we’ll fit the same model in JAGS, using vague priors for all model parameters</p>
<div class="sourceCode" id="cb212"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb212-1"><a href="bayesian-computation.html#cb212-1" aria-hidden="true" tabindex="-1"></a>cricket.model <span class="ot">&lt;-</span> <span class="cf">function</span>() {</span>
<span id="cb212-2"><a href="bayesian-computation.html#cb212-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb212-3"><a href="bayesian-computation.html#cb212-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>J) {             <span class="co"># J = number of data points</span></span>
<span id="cb212-4"><a href="bayesian-computation.html#cb212-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb212-5"><a href="bayesian-computation.html#cb212-5" aria-hidden="true" tabindex="-1"></a>    y[j] <span class="sc">~</span> <span class="fu">dnorm</span> (mu[j], tau)  <span class="co"># data model:  the likelihood </span></span>
<span id="cb212-6"><a href="bayesian-computation.html#cb212-6" aria-hidden="true" tabindex="-1"></a>                               <span class="co"># note that BUGS / JAGS uses precision</span></span>
<span id="cb212-7"><a href="bayesian-computation.html#cb212-7" aria-hidden="true" tabindex="-1"></a>                               <span class="co"># instead of variance</span></span>
<span id="cb212-8"><a href="bayesian-computation.html#cb212-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb212-9"><a href="bayesian-computation.html#cb212-9" aria-hidden="true" tabindex="-1"></a>    mu[j] <span class="ot">&lt;-</span> b0 <span class="sc">+</span> b1 <span class="sc">*</span> x[j]    <span class="co"># compute the mean for each observation</span></span>
<span id="cb212-10"><a href="bayesian-computation.html#cb212-10" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb212-11"><a href="bayesian-computation.html#cb212-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb212-12"><a href="bayesian-computation.html#cb212-12" aria-hidden="true" tabindex="-1"></a>  b0 <span class="sc">~</span> <span class="fu">dnorm</span> (<span class="fl">0.0</span>, <span class="fl">1E-6</span>)       <span class="co"># prior for intercept</span></span>
<span id="cb212-13"><a href="bayesian-computation.html#cb212-13" aria-hidden="true" tabindex="-1"></a>  b1 <span class="sc">~</span> <span class="fu">dnorm</span> (<span class="fl">0.0</span>, <span class="fl">1E-6</span>)       <span class="co"># prior for slope</span></span>
<span id="cb212-14"><a href="bayesian-computation.html#cb212-14" aria-hidden="true" tabindex="-1"></a>  tau <span class="sc">~</span> <span class="fu">dgamma</span> (<span class="fl">0.01</span>, <span class="fl">0.01</span>)    <span class="co"># prior for tau</span></span>
<span id="cb212-15"><a href="bayesian-computation.html#cb212-15" aria-hidden="true" tabindex="-1"></a>                               <span class="co"># note that BUGS / JAGS parameterizes </span></span>
<span id="cb212-16"><a href="bayesian-computation.html#cb212-16" aria-hidden="true" tabindex="-1"></a>                               <span class="co"># gamma by shape, rate</span></span>
<span id="cb212-17"><a href="bayesian-computation.html#cb212-17" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb212-18"><a href="bayesian-computation.html#cb212-18" aria-hidden="true" tabindex="-1"></a>  sigma <span class="ot">&lt;-</span> <span class="fu">pow</span>(tau, <span class="sc">-</span><span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>)      <span class="co"># the SD of the residaul errors</span></span>
<span id="cb212-19"><a href="bayesian-computation.html#cb212-19" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb212-20"><a href="bayesian-computation.html#cb212-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb212-21"><a href="bayesian-computation.html#cb212-21" aria-hidden="true" tabindex="-1"></a>jags.data <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">y =</span> cricket<span class="sc">$</span>chirps, </span>
<span id="cb212-22"><a href="bayesian-computation.html#cb212-22" aria-hidden="true" tabindex="-1"></a>                  <span class="at">x =</span> cricket<span class="sc">$</span>temperature,</span>
<span id="cb212-23"><a href="bayesian-computation.html#cb212-23" aria-hidden="true" tabindex="-1"></a>                  <span class="at">J =</span> <span class="fu">nrow</span>(cricket))</span>
<span id="cb212-24"><a href="bayesian-computation.html#cb212-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb212-25"><a href="bayesian-computation.html#cb212-25" aria-hidden="true" tabindex="-1"></a>jags.params <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;b0&quot;</span>, <span class="st">&quot;b1&quot;</span>, <span class="st">&quot;tau&quot;</span>, <span class="st">&quot;sigma&quot;</span>)</span>
<span id="cb212-26"><a href="bayesian-computation.html#cb212-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb212-27"><a href="bayesian-computation.html#cb212-27" aria-hidden="true" tabindex="-1"></a>jags.inits <span class="ot">&lt;-</span> <span class="cf">function</span>(){</span>
<span id="cb212-28"><a href="bayesian-computation.html#cb212-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">list</span>(<span class="st">&quot;b0&quot;</span> <span class="ot">=</span> <span class="fu">rnorm</span>(<span class="dv">1</span>), <span class="st">&quot;b1&quot;</span> <span class="ot">=</span> <span class="fu">rnorm</span>(<span class="dv">1</span>), <span class="st">&quot;tau&quot;</span> <span class="ot">=</span> <span class="fu">runif</span>(<span class="dv">1</span>))</span>
<span id="cb212-29"><a href="bayesian-computation.html#cb212-29" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb212-30"><a href="bayesian-computation.html#cb212-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb212-31"><a href="bayesian-computation.html#cb212-31" aria-hidden="true" tabindex="-1"></a>jagsfit <span class="ot">&lt;-</span> <span class="fu">jags</span>(<span class="at">data               =</span> jags.data, </span>
<span id="cb212-32"><a href="bayesian-computation.html#cb212-32" aria-hidden="true" tabindex="-1"></a>                <span class="at">inits              =</span> jags.inits, </span>
<span id="cb212-33"><a href="bayesian-computation.html#cb212-33" aria-hidden="true" tabindex="-1"></a>                <span class="at">parameters.to.save =</span> jags.params,</span>
<span id="cb212-34"><a href="bayesian-computation.html#cb212-34" aria-hidden="true" tabindex="-1"></a>                <span class="at">model.file         =</span> cricket.model,</span>
<span id="cb212-35"><a href="bayesian-computation.html#cb212-35" aria-hidden="true" tabindex="-1"></a>                <span class="at">n.chains           =</span> <span class="dv">3</span>,</span>
<span id="cb212-36"><a href="bayesian-computation.html#cb212-36" aria-hidden="true" tabindex="-1"></a>                <span class="at">n.iter             =</span> <span class="dv">5000</span>)</span></code></pre></div>
<pre><code>## Compiling model graph
##    Resolving undeclared variables
##    Allocating nodes
## Graph information:
##    Observed stochastic nodes: 15
##    Unobserved stochastic nodes: 3
##    Total graph size: 70
## 
## Initializing model</code></pre>
<div class="sourceCode" id="cb214"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb214-1"><a href="bayesian-computation.html#cb214-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(jagsfit)</span></code></pre></div>
<pre><code>## Inference for Bugs model at &quot;C:/Users/krgross/AppData/Local/Temp/Rtmp6pTrk2/model66892b785e.txt&quot;, fit using jags,
##  3 chains, each with 5000 iterations (first 2500 discarded), n.thin = 2
##  n.sims = 3750 iterations saved
##          mu.vect sd.vect   2.5%    25%    50%    75%  97.5%  Rhat n.eff
## b0        -0.412   3.427 -7.255 -2.592 -0.414  1.826  6.387 1.001  3800
## b1         0.213   0.043  0.128  0.185  0.213  0.240  0.298 1.001  3800
## sigma      1.036   0.222  0.704  0.880  1.000  1.151  1.555 1.001  3800
## tau        1.053   0.416  0.414  0.755  1.001  1.291  2.017 1.001  3800
## deviance  42.934   2.801 39.782 40.914 42.180 44.191 50.009 1.001  3800
## 
## For each parameter, n.eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor (at convergence, Rhat=1).
## 
## DIC info (using the rule, pD = var(deviance)/2)
## pD = 3.9 and DIC = 46.9
## DIC is an estimate of expected predictive error (lower deviance is better).</code></pre>
<div class="sourceCode" id="cb216"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb216-1"><a href="bayesian-computation.html#cb216-1" aria-hidden="true" tabindex="-1"></a><span class="fu">traceplot</span>(jagsfit)</span></code></pre></div>
<p><img src="03-BayesianIntro_files/figure-html/unnamed-chunk-14-1.png" width="672" /><img src="03-BayesianIntro_files/figure-html/unnamed-chunk-14-2.png" width="672" /><img src="03-BayesianIntro_files/figure-html/unnamed-chunk-14-3.png" width="672" /><img src="03-BayesianIntro_files/figure-html/unnamed-chunk-14-4.png" width="672" /><img src="03-BayesianIntro_files/figure-html/unnamed-chunk-14-5.png" width="672" /></p>
<p>The output of the <code>print</code> function gives the quantiles that one would use to calculate a 95% central credible interval. To find a HPD credible interval, we can use the <code>HPDinterval</code> function in the <code>coda</code> library. The <code>coda</code> library contains a variety of routines for post-processing of MCMC ouput. If we simply pass the <code>jagsfit</code> object to the <code>HPDinterval</code> function, it will return an HPD interval for each of the three chains. This isn’t what we want, so we’ll extract the raw MCMC samples first, and then coerce them to a data frame.</p>
<div class="sourceCode" id="cb217"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb217-1"><a href="bayesian-computation.html#cb217-1" aria-hidden="true" tabindex="-1"></a>mcmc.output <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(jagsfit<span class="sc">$</span>BUGSoutput<span class="sc">$</span>sims.list)</span>
<span id="cb217-2"><a href="bayesian-computation.html#cb217-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mcmc.output)</span></code></pre></div>
<pre><code>##        b0                 b1             deviance         sigma       
##  Min.   :-18.2015   Min.   :0.04798   Min.   :39.56   Min.   :0.5606  
##  1st Qu.: -2.5925   1st Qu.:0.18488   1st Qu.:40.91   1st Qu.:0.8802  
##  Median : -0.4138   Median :0.21337   Median :42.18   Median :0.9997  
##  Mean   : -0.4119   Mean   :0.21311   Mean   :42.93   Mean   :1.0356  
##  3rd Qu.:  1.8257   3rd Qu.:0.24043   3rd Qu.:44.19   3rd Qu.:1.1507  
##  Max.   : 12.8144   Max.   :0.42882   Max.   :61.92   Max.   :2.4996  
##       tau        
##  Min.   :0.1601  
##  1st Qu.:0.7553  
##  Median :1.0006  
##  Mean   :1.0527  
##  3rd Qu.:1.2906  
##  Max.   :3.1819</code></pre>
<p>Now we’ll coerce the data frame <code>mcmc.output</code> to an MCMC object, and pass it to <code>HPDinterval</code>:</p>
<div class="sourceCode" id="cb219"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb219-1"><a href="bayesian-computation.html#cb219-1" aria-hidden="true" tabindex="-1"></a><span class="fu">HPDinterval</span>(<span class="fu">as.mcmc</span>(mcmc.output))</span></code></pre></div>
<pre><code>##               lower      upper
## b0       -7.0448766  6.5628011
## b1        0.1331866  0.3022641
## deviance 39.5593562 48.3675124
## sigma     0.6843394  1.5049924
## tau       0.3468788  1.8829381
## attr(,&quot;Probability&quot;)
## [1] 0.9498667</code></pre>
<p>One of the merits of the Bayesian approach is that the posterior samples provide an immediate tool for propagating uncertainty to (possibly derived) quantities of interest. We can summarize the uncertainty in the regression fit graphically by randomly sampling a subset of these samples (say, 100 of them) and using them to plot a collection of regression lines:</p>
<div class="sourceCode" id="cb221"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb221-1"><a href="bayesian-computation.html#cb221-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(chirps <span class="sc">~</span> temperature, <span class="at">data =</span> cricket, <span class="at">type =</span> <span class="st">&quot;n&quot;</span>)</span>
<span id="cb221-2"><a href="bayesian-computation.html#cb221-2" aria-hidden="true" tabindex="-1"></a><span class="co"># we&#39;ll add the points later so that they lie on top of the lines,</span></span>
<span id="cb221-3"><a href="bayesian-computation.html#cb221-3" aria-hidden="true" tabindex="-1"></a><span class="co"># instead of the other way around</span></span>
<span id="cb221-4"><a href="bayesian-computation.html#cb221-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb221-5"><a href="bayesian-computation.html#cb221-5" aria-hidden="true" tabindex="-1"></a>subset.samples <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="fu">nrow</span>(mcmc.output), <span class="at">size =</span> <span class="dv">100</span>)</span>
<span id="cb221-6"><a href="bayesian-computation.html#cb221-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb221-7"><a href="bayesian-computation.html#cb221-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> subset.samples) {</span>
<span id="cb221-8"><a href="bayesian-computation.html#cb221-8" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb221-9"><a href="bayesian-computation.html#cb221-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">with</span>(mcmc.output, <span class="fu">abline</span>(<span class="at">a =</span> b0[i], <span class="at">b =</span> b1[i], <span class="at">col =</span> <span class="st">&quot;deepskyblue&quot;</span>, <span class="at">lwd =</span> <span class="fl">0.25</span>))</span>
<span id="cb221-10"><a href="bayesian-computation.html#cb221-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb221-11"><a href="bayesian-computation.html#cb221-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb221-12"><a href="bayesian-computation.html#cb221-12" aria-hidden="true" tabindex="-1"></a><span class="fu">with</span>(cricket, <span class="fu">points</span>(chirps <span class="sc">~</span> temperature))</span></code></pre></div>
<p><img src="03-BayesianIntro_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p>We can also propagate the uncertainty to estimate, say, the posterior distribution for the value of the regression line when the temperature is 85 F. This quantifies the uncertainty in the average number of chirps at this temperature. (We can think of it as a vertical slice through the above plot.)</p>
<div class="sourceCode" id="cb222"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb222-1"><a href="bayesian-computation.html#cb222-1" aria-hidden="true" tabindex="-1"></a>avg.chirps<span class="fl">.85</span> <span class="ot">&lt;-</span> <span class="fu">with</span>(mcmc.output, b0 <span class="sc">+</span> b1 <span class="sc">*</span> <span class="dv">85</span>)</span>
<span id="cb222-2"><a href="bayesian-computation.html#cb222-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(avg.chirps<span class="fl">.85</span>)</span></code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   16.32   17.48   17.70   17.70   17.93   18.89</code></pre>
<div class="sourceCode" id="cb224"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb224-1"><a href="bayesian-computation.html#cb224-1" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span>(avg.chirps<span class="fl">.85</span>, <span class="at">probs =</span> <span class="fu">c</span>(.<span class="dv">025</span>, <span class="fl">0.975</span>))</span></code></pre></div>
<pre><code>##     2.5%    97.5% 
## 17.00726 18.39120</code></pre>
<p>We could use the <code>density</code> function to get a quick idea of the shape of the distribution:</p>
<div class="sourceCode" id="cb226"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb226-1"><a href="bayesian-computation.html#cb226-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">density</span>(avg.chirps<span class="fl">.85</span>))</span></code></pre></div>
<p><img src="03-BayesianIntro_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<p>Thus, we might say that the posterior mean for the average number of chirps at 85 F is 17.7, and a central 95% credible interval is (17.01, 18.39).</p>
<p>Finally, we can use the posterior samples to estimate the uncertainty in a future observation. When we use a posterior distribution to estimate the distribution of a future observation, we refer to it as a posterior predictive distribution. The posterior predictive distribution must also include the error around the regression line. We can estimate the posterior predictive distribution as follows. Suppose we denote sample <span class="math inline">\(i\)</span> from the posterior as <span class="math inline">\(\beta_{0, i}\)</span>, <span class="math inline">\(\beta_{1, i}\)</span>, and <span class="math inline">\(\sigma_i\)</span>. Then for each posterior sample we will generate a new hypothetical observation <span class="math inline">\(y_i^\star\)</span> by sampling from a Gaussian distribution with mean equal to $<em>{0,i} + </em>{1,i} x $ and standard deviation <span class="math inline">\(\sigma_i\)</span>, where <span class="math inline">\(x = 85\)</span>. The distribution of the <span class="math inline">\(y_i^*\)</span>’s then gives the posterior predictive distribution that we seek.</p>
<div class="sourceCode" id="cb227"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb227-1"><a href="bayesian-computation.html#cb227-1" aria-hidden="true" tabindex="-1"></a>n.sims <span class="ot">&lt;-</span> <span class="fu">nrow</span>(mcmc.output)</span>
<span id="cb227-2"><a href="bayesian-computation.html#cb227-2" aria-hidden="true" tabindex="-1"></a>new.errors <span class="ot">&lt;-</span> <span class="fu">with</span>(mcmc.output, <span class="fu">rnorm</span>(n.sims, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> sigma))</span>
<span id="cb227-3"><a href="bayesian-computation.html#cb227-3" aria-hidden="true" tabindex="-1"></a>new.chirps<span class="fl">.85</span> <span class="ot">&lt;-</span> <span class="fu">with</span>(mcmc.output, b0 <span class="sc">+</span> b1 <span class="sc">*</span> <span class="dv">85</span>) <span class="sc">+</span> new.errors</span>
<span id="cb227-4"><a href="bayesian-computation.html#cb227-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">density</span>(new.chirps<span class="fl">.85</span>))</span></code></pre></div>
<p><img src="03-BayesianIntro_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<div class="sourceCode" id="cb228"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb228-1"><a href="bayesian-computation.html#cb228-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(new.chirps<span class="fl">.85</span>)</span></code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   12.93   16.98   17.70   17.70   18.42   22.47</code></pre>
<div class="sourceCode" id="cb230"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb230-1"><a href="bayesian-computation.html#cb230-1" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span>(new.chirps<span class="fl">.85</span>, <span class="at">probs =</span> <span class="fu">c</span>(.<span class="dv">025</span>, <span class="fl">0.975</span>))</span></code></pre></div>
<pre><code>##     2.5%    97.5% 
## 15.59601 19.93024</code></pre>
<p>Thus, the posterior predictive distribution has a central 95% credible interval of (15.6, 19.93).</p>
<p>Although it hasn’t caused any difficulty here, the slope and intercept are strongly negatively correlated in the posterior. We can visualize this posterior correlation:</p>
<div class="sourceCode" id="cb232"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb232-1"><a href="bayesian-computation.html#cb232-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(hexbin)</span></code></pre></div>
<pre><code>## Warning: package &#39;hexbin&#39; was built under R version 4.1.1</code></pre>
<div class="sourceCode" id="cb234"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb234-1"><a href="bayesian-computation.html#cb234-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(RColorBrewer)</span>
<span id="cb234-2"><a href="bayesian-computation.html#cb234-2" aria-hidden="true" tabindex="-1"></a>rf <span class="ot">&lt;-</span> <span class="fu">colorRampPalette</span>(<span class="fu">rev</span>(<span class="fu">brewer.pal</span>(<span class="dv">11</span>, <span class="st">&#39;Spectral&#39;</span>)))</span>
<span id="cb234-3"><a href="bayesian-computation.html#cb234-3" aria-hidden="true" tabindex="-1"></a><span class="fu">with</span>(jagsfit<span class="sc">$</span>BUGSoutput<span class="sc">$</span>sims.list, <span class="fu">hexbinplot</span>(b1 <span class="sc">~</span> b0, <span class="at">colramp =</span> rf))</span></code></pre></div>
<p><img src="03-BayesianIntro_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
<p>We can estimate the posterior correlation between the intercept and the slope by accessing the raw MCMC samples</p>
<div class="sourceCode" id="cb235"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb235-1"><a href="bayesian-computation.html#cb235-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(mcmc.output[, <span class="sc">-</span><span class="fu">c</span>(<span class="dv">3</span><span class="sc">:</span><span class="dv">4</span>)])</span></code></pre></div>
<pre><code>##              b0          b1         tau
## b0   1.00000000 -0.99676477  0.02869738
## b1  -0.99676477  1.00000000 -0.02663822
## tau  0.02869738 -0.02663822  1.00000000</code></pre>
<p>Thus we estimate that the intercept and slope have a posterior correlation of -0.997.</p>
<p>We could make life easier on ourselves by centering the predictor and trying again:</p>
<div class="sourceCode" id="cb237"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb237-1"><a href="bayesian-computation.html#cb237-1" aria-hidden="true" tabindex="-1"></a>cricket<span class="sc">$</span>temp.ctr <span class="ot">&lt;-</span> cricket<span class="sc">$</span>temperature <span class="sc">-</span> <span class="fu">mean</span>(cricket<span class="sc">$</span>temperature)</span></code></pre></div>
<div class="sourceCode" id="cb238"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb238-1"><a href="bayesian-computation.html#cb238-1" aria-hidden="true" tabindex="-1"></a>jags.data <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">y =</span> cricket<span class="sc">$</span>chirps, </span>
<span id="cb238-2"><a href="bayesian-computation.html#cb238-2" aria-hidden="true" tabindex="-1"></a>                  <span class="at">x =</span> cricket<span class="sc">$</span>temp.ctr,</span>
<span id="cb238-3"><a href="bayesian-computation.html#cb238-3" aria-hidden="true" tabindex="-1"></a>                  <span class="at">J =</span> <span class="fu">nrow</span>(cricket))</span>
<span id="cb238-4"><a href="bayesian-computation.html#cb238-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb238-5"><a href="bayesian-computation.html#cb238-5" aria-hidden="true" tabindex="-1"></a>jags.params <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;b0&quot;</span>, <span class="st">&quot;b1&quot;</span>, <span class="st">&quot;tau&quot;</span>, <span class="st">&quot;sigma&quot;</span>)</span>
<span id="cb238-6"><a href="bayesian-computation.html#cb238-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb238-7"><a href="bayesian-computation.html#cb238-7" aria-hidden="true" tabindex="-1"></a>jags.inits <span class="ot">&lt;-</span> <span class="cf">function</span>(){</span>
<span id="cb238-8"><a href="bayesian-computation.html#cb238-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">list</span>(<span class="st">&quot;b0&quot;</span> <span class="ot">=</span> <span class="fu">rnorm</span>(<span class="dv">1</span>), <span class="st">&quot;b1&quot;</span> <span class="ot">=</span> <span class="fu">rnorm</span>(<span class="dv">1</span>), <span class="st">&quot;tau&quot;</span> <span class="ot">=</span> <span class="fu">runif</span>(<span class="dv">1</span>))</span>
<span id="cb238-9"><a href="bayesian-computation.html#cb238-9" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb238-10"><a href="bayesian-computation.html#cb238-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb238-11"><a href="bayesian-computation.html#cb238-11" aria-hidden="true" tabindex="-1"></a>jagsfit <span class="ot">&lt;-</span> <span class="fu">jags</span>(<span class="at">data               =</span> jags.data, </span>
<span id="cb238-12"><a href="bayesian-computation.html#cb238-12" aria-hidden="true" tabindex="-1"></a>                <span class="at">inits              =</span> jags.inits, </span>
<span id="cb238-13"><a href="bayesian-computation.html#cb238-13" aria-hidden="true" tabindex="-1"></a>                <span class="at">parameters.to.save =</span> jags.params,</span>
<span id="cb238-14"><a href="bayesian-computation.html#cb238-14" aria-hidden="true" tabindex="-1"></a>                <span class="at">model.file         =</span> cricket.model,</span>
<span id="cb238-15"><a href="bayesian-computation.html#cb238-15" aria-hidden="true" tabindex="-1"></a>                <span class="at">n.chains           =</span> <span class="dv">3</span>,</span>
<span id="cb238-16"><a href="bayesian-computation.html#cb238-16" aria-hidden="true" tabindex="-1"></a>                <span class="at">n.iter             =</span> <span class="dv">5000</span>)</span></code></pre></div>
<pre><code>## Compiling model graph
##    Resolving undeclared variables
##    Allocating nodes
## Graph information:
##    Observed stochastic nodes: 15
##    Unobserved stochastic nodes: 3
##    Total graph size: 70
## 
## Initializing model</code></pre>
<div class="sourceCode" id="cb240"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb240-1"><a href="bayesian-computation.html#cb240-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(jagsfit)</span></code></pre></div>
<pre><code>## Inference for Bugs model at &quot;C:/Users/krgross/AppData/Local/Temp/Rtmp6pTrk2/model6681a1d1de8.txt&quot;, fit using jags,
##  3 chains, each with 5000 iterations (first 2500 discarded), n.thin = 2
##  n.sims = 3750 iterations saved
##          mu.vect sd.vect   2.5%    25%    50%    75%  97.5%  Rhat n.eff
## b0        16.650   0.273 16.106 16.481 16.646 16.818 17.203 1.001  3800
## b1         0.211   0.042  0.126  0.185  0.211  0.238  0.292 1.001  3800
## sigma      1.036   0.226  0.708  0.877  1.000  1.151  1.597 1.001  3800
## tau        1.054   0.414  0.392  0.755  1.000  1.300  1.993 1.001  3800
## deviance  42.900   2.804 39.777 40.829 42.148 44.125 50.205 1.001  3800
## 
## For each parameter, n.eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor (at convergence, Rhat=1).
## 
## DIC info (using the rule, pD = var(deviance)/2)
## pD = 3.9 and DIC = 46.8
## DIC is an estimate of expected predictive error (lower deviance is better).</code></pre>
<div class="sourceCode" id="cb242"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb242-1"><a href="bayesian-computation.html#cb242-1" aria-hidden="true" tabindex="-1"></a><span class="fu">traceplot</span>(jagsfit)</span></code></pre></div>
<p><img src="03-BayesianIntro_files/figure-html/unnamed-chunk-24-1.png" width="672" /><img src="03-BayesianIntro_files/figure-html/unnamed-chunk-24-2.png" width="672" /><img src="03-BayesianIntro_files/figure-html/unnamed-chunk-24-3.png" width="672" /><img src="03-BayesianIntro_files/figure-html/unnamed-chunk-24-4.png" width="672" /><img src="03-BayesianIntro_files/figure-html/unnamed-chunk-24-5.png" width="672" /></p>
<p>The posteriors for the intercept and slope are now uncorrelated:</p>
<div class="sourceCode" id="cb243"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb243-1"><a href="bayesian-computation.html#cb243-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(hexbin)</span>
<span id="cb243-2"><a href="bayesian-computation.html#cb243-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(RColorBrewer)</span>
<span id="cb243-3"><a href="bayesian-computation.html#cb243-3" aria-hidden="true" tabindex="-1"></a>rf <span class="ot">&lt;-</span> <span class="fu">colorRampPalette</span>(<span class="fu">rev</span>(<span class="fu">brewer.pal</span>(<span class="dv">11</span>, <span class="st">&#39;Spectral&#39;</span>)))</span>
<span id="cb243-4"><a href="bayesian-computation.html#cb243-4" aria-hidden="true" tabindex="-1"></a><span class="fu">with</span>(jagsfit<span class="sc">$</span>BUGSoutput<span class="sc">$</span>sims.list, <span class="fu">hexbinplot</span>(b1 <span class="sc">~</span> b0, <span class="at">colramp =</span> rf))</span></code></pre></div>
<p><img src="03-BayesianIntro_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<div class="sourceCode" id="cb244"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb244-1"><a href="bayesian-computation.html#cb244-1" aria-hidden="true" tabindex="-1"></a>mcmc.output <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(jagsfit<span class="sc">$</span>BUGSoutput<span class="sc">$</span>sims.list)</span>
<span id="cb244-2"><a href="bayesian-computation.html#cb244-2" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(mcmc.output[, <span class="sc">-</span><span class="fu">c</span>(<span class="dv">3</span><span class="sc">:</span><span class="dv">4</span>)])</span></code></pre></div>
<pre><code>##               b0          b1          tau
## b0  1.000000e+00 0.004046838 4.905969e-05
## b1  4.046838e-03 1.000000000 1.893835e-02
## tau 4.905969e-05 0.018938349 1.000000e+00</code></pre>
</div>
<div id="rstanarm" class="section level2" number="3.3">
<h2><span class="header-section-number">3.3</span> rstanarm</h2>
<p>The <code>rstanarm</code> package is a recent set of routines that seeks to provide a user-friendly front end to Bayesian analysis with Stan. Specifically, <code>rstanarm</code> provides functions for fitting standard statistical models that are meant to mimic the analogous fitting functions in R. For example, the basic routine for fitting linear models in R is <code>lm</code>; <code>rstanarm</code> provides a function <code>stan_lm</code> that strives to have the same functionality and interface as <code>lm</code>, albeit using Stan “under the hood” to generate Bayesian inference. (That said, the main workhorse function in <code>rstanarm</code> for model fitting is <code>stan_glm</code>, which attempts to mimic the native R function <code>glm</code> for fitting generalized linear models. Separately, the developers of <code>rstanarm</code> have taken the not unreasonable stance that generalized linear models should supplant general linear models as the analyst’s default approach to model fitting.)</p>
<p>To provide functionality that is similar to R’s native model-fitting routines, the functions in <code>rstanarm</code> make a number of operational decisions behind the scenes. Most notably, the model fitting routines in <code>rstanarm</code> will select default priors and default HMC parameters. While these defaults can always be modified by the analyst, the implementation of software that chooses priors by default is radical. First, the developers of <code>rstanarm</code> have their own particular view about what the role of the prior should be in data analysis. While their view is a considered one, by no means does it reflect a consensus that extends beyond the developers of the software. If you use <code>rstanarm</code>’s routines out of the box, you are accepting this view as your own if you do not specify the priors yourself. Second, as best I understand, the methods by which <code>rstanarm</code> chooses default priors still appear to be in some flux. That means that future versions of <code>rstanarm</code> may supply different default priors than those that are supplied today. As a result, the behavior of <code>rstanarm</code> today may differ from its behavior tomorrow, if you use the default priors.</p>
<p>All that said, here is how you might use <code>rstanarm</code> to fit the simple regression to the cricket data:</p>
<div class="sourceCode" id="cb246"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb246-1"><a href="bayesian-computation.html#cb246-1" aria-hidden="true" tabindex="-1"></a><span class="fu">require</span>(rstanarm)</span></code></pre></div>
<pre><code>## Loading required package: rstanarm</code></pre>
<pre><code>## Loading required package: Rcpp</code></pre>
<pre><code>## This is rstanarm version 2.21.1</code></pre>
<pre><code>## - See https://mc-stan.org/rstanarm/articles/priors for changes to default priors!</code></pre>
<pre><code>## - Default priors may change, so it&#39;s safest to specify priors, even if equivalent to the defaults.</code></pre>
<pre><code>## - For execution on a local, multicore CPU with excess RAM we recommend calling</code></pre>
<pre><code>##   options(mc.cores = parallel::detectCores())</code></pre>
<div class="sourceCode" id="cb254"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb254-1"><a href="bayesian-computation.html#cb254-1" aria-hidden="true" tabindex="-1"></a>stanarm.cricket.fit <span class="ot">&lt;-</span> <span class="fu">stan_glm</span>(chirps <span class="sc">~</span> temp.ctr, <span class="at">data =</span> cricket, <span class="at">family =</span> gaussian, <span class="at">seed =</span> <span class="dv">1</span>)</span></code></pre></div>
<pre><code>## 
## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 1).
## Chain 1: 
## Chain 1: Gradient evaluation took 0 seconds
## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
## Chain 1: Adjust your expectations accordingly!
## Chain 1: 
## Chain 1: 
## Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 1: 
## Chain 1:  Elapsed Time: 0.148 seconds (Warm-up)
## Chain 1:                0.214 seconds (Sampling)
## Chain 1:                0.362 seconds (Total)
## Chain 1: 
## 
## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 2).
## Chain 2: 
## Chain 2: Gradient evaluation took 0 seconds
## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
## Chain 2: Adjust your expectations accordingly!
## Chain 2: 
## Chain 2: 
## Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 2: 
## Chain 2:  Elapsed Time: 0.175 seconds (Warm-up)
## Chain 2:                0.113 seconds (Sampling)
## Chain 2:                0.288 seconds (Total)
## Chain 2: 
## 
## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 3).
## Chain 3: 
## Chain 3: Gradient evaluation took 0 seconds
## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
## Chain 3: Adjust your expectations accordingly!
## Chain 3: 
## Chain 3: 
## Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 3: 
## Chain 3:  Elapsed Time: 0.139 seconds (Warm-up)
## Chain 3:                0.129 seconds (Sampling)
## Chain 3:                0.268 seconds (Total)
## Chain 3: 
## 
## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 4).
## Chain 4: 
## Chain 4: Gradient evaluation took 0 seconds
## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
## Chain 4: Adjust your expectations accordingly!
## Chain 4: 
## Chain 4: 
## Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 4: 
## Chain 4:  Elapsed Time: 0.171 seconds (Warm-up)
## Chain 4:                0.125 seconds (Sampling)
## Chain 4:                0.296 seconds (Total)
## Chain 4:</code></pre>
<p>Note that <code>rstanarm</code> has made a variety of decisions about how many chains to run, how long to run them, etc. We can obtain a summary of the model fit by the <code>print</code> command:</p>
<div class="sourceCode" id="cb256"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb256-1"><a href="bayesian-computation.html#cb256-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(stanarm.cricket.fit, <span class="at">digits =</span> <span class="dv">3</span>)</span></code></pre></div>
<pre><code>## stan_glm
##  family:       gaussian [identity]
##  formula:      chirps ~ temp.ctr
##  observations: 15
##  predictors:   2
## ------
##             Median MAD_SD
## (Intercept) 16.648  0.257
## temp.ctr     0.210  0.041
## 
## Auxiliary parameter(s):
##       Median MAD_SD
## sigma 1.008  0.198 
## 
## ------
## * For help interpreting the printed output see ?print.stanreg
## * For info on the priors used see ?prior_summary.stanreg</code></pre>
<p>There are a few parts of this output that deserve comment. First, this summary reports the posterior median of the parameters instead of the posterior mean. Second, the authors of <code>rstanarm</code> have made the curious decision to replace the posterior standard deviation (itself the Bayesian counterpart to the frequentist’s standard error) with someting they call “MAD SD.” This takes a bit of explanation. The “MAD” part stands for median absolute deviation. It is the median of the absolute deviations of the posterior samples from the posterior median. In other words, if we have a generic parameter <span class="math inline">\(\theta\)</span> and label its posterior samples as <span class="math inline">\(\theta_1, \theta_2, \ldots, \theta_n\)</span>, then the MAD of <span class="math inline">\(\theta\)</span> is</p>
<p><span class="math display">\[
\mathrm{median}_i(| \theta_i - \mathrm{median}_i(\theta_i) |)
\]</span></p>
<p>According to the authors of <code>rstanarm</code>, “Because we are so used to working with standard deviations, when we compute the median absolute deviation, we then rescale it by multiplying by 1.483, which reproduces the standard deviation in the special case of the normal distribution. We call this the mad sd.” In other words, the MAD SD is a measure of posterior uncertainty that is meant to be comparable to the posterior standard deviation. (The authors of <code>rstanarm</code> clearly must think this is a more desirable estimate of the posterior uncertainty than the posterior standard deviation; though their reasoning here is not immediately clear to me.)</p>
<!-- See p 73 of Gelman "Regression and other stories" -->
<p>If we want to compute our own summary statistics, we can extract the MCMC samples from the <code>stam_glm</code> fit using the <code>as.matrix</code> command:</p>
<div class="sourceCode" id="cb258"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb258-1"><a href="bayesian-computation.html#cb258-1" aria-hidden="true" tabindex="-1"></a>mcmc.sims <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(stanarm.cricket.fit)</span>
<span id="cb258-2"><a href="bayesian-computation.html#cb258-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mcmc.sims)</span></code></pre></div>
<pre><code>##   (Intercept)       temp.ctr           sigma       
##  Min.   :15.65   Min.   :0.02782   Min.   :0.5582  
##  1st Qu.:16.48   1st Qu.:0.18191   1st Qu.:0.8869  
##  Median :16.65   Median :0.21023   Median :1.0079  
##  Mean   :16.65   Mean   :0.20955   Mean   :1.0457  
##  3rd Qu.:16.83   3rd Qu.:0.23740   3rd Qu.:1.1627  
##  Max.   :17.68   Max.   :0.36177   Max.   :2.3400</code></pre>
<p>We might, for example, then use this output to find the posterior standard deviation of each of the parameters, or to find central 95% credible intervals:</p>
<div class="sourceCode" id="cb260"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb260-1"><a href="bayesian-computation.html#cb260-1" aria-hidden="true" tabindex="-1"></a><span class="fu">apply</span>(mcmc.sims, <span class="dv">2</span>, sd)</span></code></pre></div>
<pre><code>## (Intercept)    temp.ctr       sigma 
##  0.27003507  0.04262539  0.22262375</code></pre>
<div class="sourceCode" id="cb262"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb262-1"><a href="bayesian-computation.html#cb262-1" aria-hidden="true" tabindex="-1"></a><span class="fu">apply</span>(mcmc.sims, <span class="dv">2</span>, <span class="cf">function</span>(x) <span class="fu">quantile</span>(x, <span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>)))</span></code></pre></div>
<pre><code>##        parameters
##         (Intercept)  temp.ctr     sigma
##   2.5%     16.10111 0.1240071 0.7171401
##   97.5%    17.17942 0.2906848 1.5816217</code></pre>
<p>Compare these values to the posterior standard deviations and 95% central credible intervals reported in the JAGS fit.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="beyond-the-mle-confidence-regions-and-hypothesis-tests-using-the-likelihood-function.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="smooth-regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
