<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Bayesian computation | Computing companion for BMA / ST 590, Fall 2021</title>
  <meta name="description" content="Computing companion for BMA / ST 590, Statistical Modeling in Ecology, NCSU, Fall 2021." />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Bayesian computation | Computing companion for BMA / ST 590, Fall 2021" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Computing companion for BMA / ST 590, Statistical Modeling in Ecology, NCSU, Fall 2021." />
  <meta name="github-repo" content="krgross/bma590-course-notes" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Bayesian computation | Computing companion for BMA / ST 590, Fall 2021" />
  
  <meta name="twitter:description" content="Computing companion for BMA / ST 590, Statistical Modeling in Ecology, NCSU, Fall 2021." />
  

<meta name="author" content="Kevin Gross" />


<meta name="date" content="2021-09-13" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="beyond-the-mle-confidence-regions-and-hypothesis-tests-using-the-likelihood-function.html"/>

<script src="libs/header-attrs-2.9/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html"><i class="fa fa-check"></i><b>1</b> Maximum likelihood estimation</a>
<ul>
<li class="chapter" data-level="1.1" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#a-very-simple-example-with-a-single-observation"><i class="fa fa-check"></i><b>1.1</b> A very simple example with a single observation</a></li>
<li class="chapter" data-level="1.2" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#horse-kick-data"><i class="fa fa-check"></i><b>1.2</b> Horse-kick data</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#calculate-and-plot-the-log-likelihood-function"><i class="fa fa-check"></i><b>1.2.1</b> Calculate and plot the log-likelihood function</a></li>
<li class="chapter" data-level="1.2.2" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#find-the-mle-numerically-using-optimize"><i class="fa fa-check"></i><b>1.2.2</b> Find the MLE numerically using ‘optimize’</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#myxomatosis-data"><i class="fa fa-check"></i><b>1.3</b> Myxomatosis data</a></li>
<li class="chapter" data-level="1.4" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#tadpole-data"><i class="fa fa-check"></i><b>1.4</b> Tadpole data</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="beyond-the-mle-confidence-regions-and-hypothesis-tests-using-the-likelihood-function.html"><a href="beyond-the-mle-confidence-regions-and-hypothesis-tests-using-the-likelihood-function.html"><i class="fa fa-check"></i><b>2</b> Beyond the MLE: Confidence regions and hypothesis tests using the likelihood function</a>
<ul>
<li class="chapter" data-level="2.1" data-path="beyond-the-mle-confidence-regions-and-hypothesis-tests-using-the-likelihood-function.html"><a href="beyond-the-mle-confidence-regions-and-hypothesis-tests-using-the-likelihood-function.html#confidence-intervals-for-single-parameters"><i class="fa fa-check"></i><b>2.1</b> Confidence intervals for single parameters</a></li>
<li class="chapter" data-level="2.2" data-path="beyond-the-mle-confidence-regions-and-hypothesis-tests-using-the-likelihood-function.html"><a href="beyond-the-mle-confidence-regions-and-hypothesis-tests-using-the-likelihood-function.html#two-param-mle"><i class="fa fa-check"></i><b>2.2</b> Confidence regions, profile likelihoods, and associated univariate intervals</a></li>
<li class="chapter" data-level="2.3" data-path="beyond-the-mle-confidence-regions-and-hypothesis-tests-using-the-likelihood-function.html"><a href="beyond-the-mle-confidence-regions-and-hypothesis-tests-using-the-likelihood-function.html#locally-quadratic-approximations-to-confidence-intervals-and-regions"><i class="fa fa-check"></i><b>2.3</b> Locally quadratic approximations to confidence intervals and regions</a></li>
<li class="chapter" data-level="2.4" data-path="beyond-the-mle-confidence-regions-and-hypothesis-tests-using-the-likelihood-function.html"><a href="beyond-the-mle-confidence-regions-and-hypothesis-tests-using-the-likelihood-function.html#comparing-models-likelihood-ratio-test-and-aic"><i class="fa fa-check"></i><b>2.4</b> Comparing models: Likelihood ratio test and AIC</a></li>
<li class="chapter" data-level="2.5" data-path="beyond-the-mle-confidence-regions-and-hypothesis-tests-using-the-likelihood-function.html"><a href="beyond-the-mle-confidence-regions-and-hypothesis-tests-using-the-likelihood-function.html#transformable-constraints"><i class="fa fa-check"></i><b>2.5</b> Transformable constraints</a></li>
<li class="chapter" data-level="2.6" data-path="beyond-the-mle-confidence-regions-and-hypothesis-tests-using-the-likelihood-function.html"><a href="beyond-the-mle-confidence-regions-and-hypothesis-tests-using-the-likelihood-function.html#the-negative-binomial-distriution-revisited"><i class="fa fa-check"></i><b>2.6</b> The negative binomial distriution, revisited</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="bayesian-computation.html"><a href="bayesian-computation.html"><i class="fa fa-check"></i><b>3</b> Bayesian computation</a>
<ul>
<li class="chapter" data-level="3.1" data-path="bayesian-computation.html"><a href="bayesian-computation.html#computations-with-conjugate-priors"><i class="fa fa-check"></i><b>3.1</b> Computations with conjugate priors</a></li>
<li class="chapter" data-level="3.2" data-path="bayesian-computation.html"><a href="bayesian-computation.html#jags-in-r"><i class="fa fa-check"></i><b>3.2</b> JAGS in R</a></li>
<li class="chapter" data-level="3.3" data-path="bayesian-computation.html"><a href="bayesian-computation.html#rstanarm"><i class="fa fa-check"></i><b>3.3</b> rstanarm</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Computing companion for BMA / ST 590, Fall 2021</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="bayesian-computation" class="section level1" number="3">
<h1><span class="header-section-number">Chapter 3</span> Bayesian computation</h1>
<p>This chapter of the computing companion will focus solely on the computing aspects of Bayesian computation in R. See the course notes or relevant sections of Bolker for the underlying theory.</p>
<p>The landscape of computing tools available to fit Bayesian models is fluid. Here, we will look at three tools currently available: <code>R2jags</code>, which is based on the JAGS (Just Another Gibbs Sampler) platform, <code>rstan</code>, which is based on the computer program Stan (itself based on Hamiltonian Monte Carlo, or HMC), and the recent <code>rstanarm</code>, which seeks to put much of the computational details in the background. (The “arm” portion of the name <code>rstanarm</code> is an acronym for applied regression modeling.)</p>
<p>Throughout, we will be working with two data sets: the horse kick data (again), and a data set that details how the rate at which a cricket chirps depends on the air temperature. The horse kick data are useful in this context because a Gamma distribution is a conjugate prior for Poisson data. Thus, if we use a Gamma prior, then we know the posterior exactly. Therefore, we can compare the approximations provided by stochastic sampling schemes to the known posterior. The cricket data set will be used as an example of a simple linear regression, even though the data hint that the actual relationship between temperature and the rate of chirping is nonlinear.</p>
<div id="computations-with-conjugate-priors" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Computations with conjugate priors</h2>
<p>Suppose that we observe an iid random sample <span class="math inline">\(X_1, \ldots, X_n\)</span> from a Poisson distribution with unknown parameter <span class="math inline">\(\lambda\)</span>. (This is the setting for the horse-kick data.) If we place a Gamma prior with shape parameter <span class="math inline">\(a\)</span> and rate parameter <span class="math inline">\(r\)</span> on <span class="math inline">\(\lambda\)</span>, then the posterior distribution is also Gamma with shape parameter <span class="math inline">\(a + \sum_n X_n\)</span> and rate parameter <span class="math inline">\(r + n\)</span>. In other words,
<span class="math display">\[\begin{align*}
\lambda &amp; \sim \mbox{Gamma}(a, r) \\
X_1, \ldots, X_n &amp; \sim \mbox{Pois}(\lambda) \\
\lambda | X_1, \ldots, X_n &amp; \sim \mbox{Gamma}(a + \sum_n X_n, r + n) \\
\end{align*}\]</span></p>
<p>In the horse kick data, <span class="math inline">\(\sum_n x_n = 196\)</span> and <span class="math inline">\(n = 280\)</span>. Suppose we start with the vague Gamma prior <span class="math inline">\(a=.01\)</span>, <span class="math inline">\(r = .01\)</span> on <span class="math inline">\(\lambda\)</span>. This prior has mean <span class="math inline">\(a/r = 1\)</span> and variance <span class="math inline">\(a/r^2 = 100\)</span>. The posterior distribution for <span class="math inline">\(\lambda\)</span> is then a Gamma with shape parameter <span class="math inline">\(a = 196.01\)</span> and rate parameter <span class="math inline">\(280.01\)</span>. We can plot it:</p>
<div class="sourceCode" id="cb171"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb171-1"><a href="bayesian-computation.html#cb171-1" aria-hidden="true" tabindex="-1"></a>horse <span class="ot">&lt;-</span> <span class="fu">read.table</span>(<span class="st">&quot;data/horse.txt&quot;</span>, </span>
<span id="cb171-2"><a href="bayesian-computation.html#cb171-2" aria-hidden="true" tabindex="-1"></a>                    <span class="at">header =</span> <span class="cn">TRUE</span>,</span>
<span id="cb171-3"><a href="bayesian-computation.html#cb171-3" aria-hidden="true" tabindex="-1"></a>                    <span class="at">stringsAsFactors =</span> <span class="cn">TRUE</span>)</span>
<span id="cb171-4"><a href="bayesian-computation.html#cb171-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb171-5"><a href="bayesian-computation.html#cb171-5" aria-hidden="true" tabindex="-1"></a>l.vals <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">2</span>, <span class="at">length =</span> <span class="dv">200</span>)</span>
<span id="cb171-6"><a href="bayesian-computation.html#cb171-6" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(l.vals, <span class="fu">dgamma</span>(l.vals, <span class="at">shape =</span> <span class="fl">196.01</span>, <span class="at">rate =</span> <span class="fl">280.01</span>), <span class="at">type =</span> <span class="st">&quot;l&quot;</span>, </span>
<span id="cb171-7"><a href="bayesian-computation.html#cb171-7" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="fu">expression</span>(lambda), <span class="at">ylab =</span> <span class="st">&quot;&quot;</span>)</span>
<span id="cb171-8"><a href="bayesian-computation.html#cb171-8" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(l.vals, <span class="fu">dgamma</span>(l.vals, <span class="at">shape =</span> .<span class="dv">01</span>, <span class="at">rate =</span> .<span class="dv">01</span>), <span class="at">lty =</span> <span class="st">&quot;dashed&quot;</span>)</span>
<span id="cb171-9"><a href="bayesian-computation.html#cb171-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb171-10"><a href="bayesian-computation.html#cb171-10" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fl">0.7</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span>
<span id="cb171-11"><a href="bayesian-computation.html#cb171-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb171-12"><a href="bayesian-computation.html#cb171-12" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topleft&quot;</span>, <span class="at">leg =</span> <span class="fu">c</span>(<span class="st">&quot;prior&quot;</span>, <span class="st">&quot;posterior&quot;</span>), </span>
<span id="cb171-13"><a href="bayesian-computation.html#cb171-13" aria-hidden="true" tabindex="-1"></a>       <span class="at">lty =</span> <span class="fu">c</span>(<span class="st">&quot;dashed&quot;</span>, <span class="st">&quot;solid&quot;</span>))</span></code></pre></div>
<p><img src="03-BayesianComputation_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p>The red line shows the MLE, which is displaced slightly from the posterior mode.</p>
<p>As a point estimate, we might consider any of the following. The posterior mean can be found exactly as <span class="math inline">\(a/r\)</span> = 0.70001. Alternatively, we might consider the posterior median</p>
<div class="sourceCode" id="cb172"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb172-1"><a href="bayesian-computation.html#cb172-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qgamma</span>(<span class="fl">0.5</span>, <span class="at">shape =</span> <span class="fl">196.01</span>, <span class="at">rate =</span> <span class="fl">280.01</span>)</span></code></pre></div>
<pre><code>## [1] 0.6988206</code></pre>
<p>Finally, we might conisder the posterior mode:</p>
<div class="sourceCode" id="cb174"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb174-1"><a href="bayesian-computation.html#cb174-1" aria-hidden="true" tabindex="-1"></a><span class="fu">optimize</span>(<span class="at">f =</span> <span class="cf">function</span>(x) <span class="fu">dgamma</span>(x, <span class="at">shape =</span> <span class="fl">196.01</span>, <span class="at">rate =</span> <span class="fl">280.01</span>), <span class="at">interval =</span> <span class="fu">c</span>(<span class="fl">0.5</span>, <span class="dv">1</span>), <span class="at">maximum =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## $maximum
## [1] 0.6964383
## 
## $objective
## [1] 7.995941</code></pre>
<p>To find a 95% confidence interval, we might consider the central 95% interval:</p>
<div class="sourceCode" id="cb176"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb176-1"><a href="bayesian-computation.html#cb176-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qgamma</span>(<span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>), <span class="at">shape =</span> <span class="fl">196.01</span>, <span class="at">rate =</span> <span class="fl">280.01</span>)</span></code></pre></div>
<pre><code>## [1] 0.6054387 0.8013454</code></pre>
<p>A 95% highest posterior density (HPD) interval takes a bit more work:</p>
<div class="sourceCode" id="cb178"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb178-1"><a href="bayesian-computation.html#cb178-1" aria-hidden="true" tabindex="-1"></a>diff.in.pdf <span class="ot">&lt;-</span> <span class="cf">function</span>(x){</span>
<span id="cb178-2"><a href="bayesian-computation.html#cb178-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb178-3"><a href="bayesian-computation.html#cb178-3" aria-hidden="true" tabindex="-1"></a>  upper <span class="ot">&lt;-</span> <span class="fu">qgamma</span>(<span class="at">p =</span> x, <span class="at">shape =</span> <span class="fl">196.01</span>, <span class="at">rate =</span> <span class="fl">280.01</span>)</span>
<span id="cb178-4"><a href="bayesian-computation.html#cb178-4" aria-hidden="true" tabindex="-1"></a>  lower <span class="ot">&lt;-</span> <span class="fu">qgamma</span>(<span class="at">p =</span> x <span class="sc">-</span> .<span class="dv">95</span>, <span class="at">shape =</span> <span class="fl">196.01</span>, <span class="at">rate =</span> <span class="fl">280.01</span>)</span>
<span id="cb178-5"><a href="bayesian-computation.html#cb178-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb178-6"><a href="bayesian-computation.html#cb178-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dgamma</span>(upper, <span class="at">shape =</span> <span class="fl">196.01</span>, <span class="at">rate =</span> <span class="fl">280.01</span>) <span class="sc">-</span> <span class="fu">dgamma</span>(lower, <span class="at">shape =</span> <span class="fl">196.01</span>, <span class="at">rate =</span> <span class="fl">280.01</span>)</span>
<span id="cb178-7"><a href="bayesian-computation.html#cb178-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb178-8"><a href="bayesian-computation.html#cb178-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb178-9"><a href="bayesian-computation.html#cb178-9" aria-hidden="true" tabindex="-1"></a>(upper.qtile <span class="ot">&lt;-</span> <span class="fu">uniroot</span>(diff.in.pdf, <span class="at">interval =</span> <span class="fu">c</span>(<span class="fl">0.95</span>, <span class="dv">1</span>))<span class="sc">$</span>root)</span></code></pre></div>
<pre><code>## [1] 0.9722176</code></pre>
<div class="sourceCode" id="cb180"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb180-1"><a href="bayesian-computation.html#cb180-1" aria-hidden="true" tabindex="-1"></a>(hpd.ci <span class="ot">&lt;-</span> <span class="fu">qgamma</span>(<span class="at">p =</span> <span class="fu">c</span>(upper.qtile <span class="sc">-</span> .<span class="dv">95</span>, upper.qtile), <span class="at">shape =</span> <span class="fl">196.01</span>, <span class="at">rate =</span> <span class="fl">280.01</span>))</span></code></pre></div>
<pre><code>## [1] 0.6031732 0.7988576</code></pre>
<p>We might also ask questions like: What is the posterior probability that <span class="math inline">\(\lambda &gt; 2/3\)</span>? These caluclations are straightforward in a Bayesian context, and they make full sense.</p>
<div class="sourceCode" id="cb182"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb182-1"><a href="bayesian-computation.html#cb182-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pgamma</span>(<span class="dv">2</span><span class="sc">/</span><span class="dv">3</span>, <span class="at">shape =</span> <span class="fl">196.01</span>, <span class="at">rate =</span> <span class="fl">280.01</span>, <span class="at">lower.tail =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<pre><code>## [1] 0.7434032</code></pre>
<p>Thus we would say that there is a 0.743 posterior probability that <span class="math inline">\(\lambda &gt; 2/3\)</span>.</p>
<p>As an illustration, note that if we had begun with a more informative prior — say, a gamma distribution with shape parameter <span class="math inline">\(a = 50\)</span> and rate parameter = <span class="math inline">\(100\)</span> — then the posterior would have been more of a compromise between the prior and the information in the data:</p>
<div class="sourceCode" id="cb184"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb184-1"><a href="bayesian-computation.html#cb184-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(l.vals, <span class="fu">dgamma</span>(l.vals, <span class="at">shape =</span> <span class="dv">196</span> <span class="sc">+</span> <span class="dv">50</span>, <span class="at">rate =</span> <span class="dv">100</span> <span class="sc">+</span> <span class="dv">280</span>), <span class="at">type =</span> <span class="st">&quot;l&quot;</span>, </span>
<span id="cb184-2"><a href="bayesian-computation.html#cb184-2" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="fu">expression</span>(lambda), <span class="at">ylab =</span> <span class="st">&quot;&quot;</span>)</span>
<span id="cb184-3"><a href="bayesian-computation.html#cb184-3" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(l.vals, <span class="fu">dgamma</span>(l.vals, <span class="at">shape =</span> <span class="dv">50</span>, <span class="at">rate =</span> <span class="dv">100</span>), <span class="at">lty =</span> <span class="st">&quot;dashed&quot;</span>)</span>
<span id="cb184-4"><a href="bayesian-computation.html#cb184-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb184-5"><a href="bayesian-computation.html#cb184-5" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fl">0.7</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span>
<span id="cb184-6"><a href="bayesian-computation.html#cb184-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb184-7"><a href="bayesian-computation.html#cb184-7" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topleft&quot;</span>, <span class="at">leg =</span> <span class="fu">c</span>(<span class="st">&quot;prior&quot;</span>, <span class="st">&quot;posterior&quot;</span>), </span>
<span id="cb184-8"><a href="bayesian-computation.html#cb184-8" aria-hidden="true" tabindex="-1"></a>       <span class="at">lty =</span> <span class="fu">c</span>(<span class="st">&quot;dashed&quot;</span>, <span class="st">&quot;solid&quot;</span>))</span></code></pre></div>
<p><img src="03-BayesianComputation_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
</div>
<div id="jags-in-r" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> JAGS in R</h2>
<p>All of the computational tools that we will examine in this section involve some form of stochastic sampling from the posterior. This computing companion will largely use the default settings, though in real practice the analyst will often have to do considerable work adjusting the settings to obtain a satisfactory approximation.</p>
<p>We’ll use JAGS through R, using the library <code>r2jags</code>. Here is JAGS code to approximate the posterior to <span class="math inline">\(\lambda\)</span> for the horse kick data, using the vague prior.</p>
<div class="sourceCode" id="cb185"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb185-1"><a href="bayesian-computation.html#cb185-1" aria-hidden="true" tabindex="-1"></a><span class="fu">require</span>(R2jags)</span></code></pre></div>
<pre><code>## Loading required package: R2jags</code></pre>
<pre><code>## Warning: package &#39;R2jags&#39; was built under R version 4.1.1</code></pre>
<pre><code>## Loading required package: rjags</code></pre>
<pre><code>## Warning: package &#39;rjags&#39; was built under R version 4.1.1</code></pre>
<pre><code>## Loading required package: coda</code></pre>
<pre><code>## Linked to JAGS 4.3.0</code></pre>
<pre><code>## Loaded modules: basemod,bugs</code></pre>
<pre><code>## 
## Attaching package: &#39;R2jags&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:coda&#39;:
## 
##     traceplot</code></pre>
<div class="sourceCode" id="cb195"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb195-1"><a href="bayesian-computation.html#cb195-1" aria-hidden="true" tabindex="-1"></a>horse.model <span class="ot">&lt;-</span> <span class="cf">function</span>() {</span>
<span id="cb195-2"><a href="bayesian-computation.html#cb195-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb195-3"><a href="bayesian-computation.html#cb195-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>J) {             <span class="co"># J = 280, number of data points</span></span>
<span id="cb195-4"><a href="bayesian-computation.html#cb195-4" aria-hidden="true" tabindex="-1"></a>    y[j] <span class="sc">~</span> <span class="fu">dpois</span> (lambda)      <span class="co"># data model:  the likelihood      </span></span>
<span id="cb195-5"><a href="bayesian-computation.html#cb195-5" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb195-6"><a href="bayesian-computation.html#cb195-6" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb195-7"><a href="bayesian-computation.html#cb195-7" aria-hidden="true" tabindex="-1"></a>  lambda <span class="sc">~</span> <span class="fu">dgamma</span> (<span class="fl">0.01</span>, <span class="fl">0.01</span>) <span class="co"># prior </span></span>
<span id="cb195-8"><a href="bayesian-computation.html#cb195-8" aria-hidden="true" tabindex="-1"></a>                               <span class="co"># note that BUGS / JAGS parameterizes </span></span>
<span id="cb195-9"><a href="bayesian-computation.html#cb195-9" aria-hidden="true" tabindex="-1"></a>                               <span class="co"># gamma by shape, rate</span></span>
<span id="cb195-10"><a href="bayesian-computation.html#cb195-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb195-11"><a href="bayesian-computation.html#cb195-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb195-12"><a href="bayesian-computation.html#cb195-12" aria-hidden="true" tabindex="-1"></a>jags.data <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">y =</span> horse<span class="sc">$</span>deaths, <span class="at">J =</span> <span class="fu">length</span>(horse<span class="sc">$</span>deaths))</span>
<span id="cb195-13"><a href="bayesian-computation.html#cb195-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb195-14"><a href="bayesian-computation.html#cb195-14" aria-hidden="true" tabindex="-1"></a>jags.params <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;lambda&quot;</span>)</span>
<span id="cb195-15"><a href="bayesian-computation.html#cb195-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb195-16"><a href="bayesian-computation.html#cb195-16" aria-hidden="true" tabindex="-1"></a>jags.inits <span class="ot">&lt;-</span> <span class="cf">function</span>(){</span>
<span id="cb195-17"><a href="bayesian-computation.html#cb195-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">list</span>(<span class="st">&quot;lambda&quot;</span> <span class="ot">=</span> <span class="fu">rgamma</span>(<span class="fl">0.01</span>, <span class="fl">0.01</span>))</span>
<span id="cb195-18"><a href="bayesian-computation.html#cb195-18" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb195-19"><a href="bayesian-computation.html#cb195-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb195-20"><a href="bayesian-computation.html#cb195-20" aria-hidden="true" tabindex="-1"></a>jagsfit <span class="ot">&lt;-</span> <span class="fu">jags</span>(<span class="at">data               =</span> jags.data, </span>
<span id="cb195-21"><a href="bayesian-computation.html#cb195-21" aria-hidden="true" tabindex="-1"></a>                <span class="at">inits              =</span> jags.inits, </span>
<span id="cb195-22"><a href="bayesian-computation.html#cb195-22" aria-hidden="true" tabindex="-1"></a>                <span class="at">parameters.to.save =</span> jags.params,</span>
<span id="cb195-23"><a href="bayesian-computation.html#cb195-23" aria-hidden="true" tabindex="-1"></a>                <span class="at">model.file         =</span> horse.model,</span>
<span id="cb195-24"><a href="bayesian-computation.html#cb195-24" aria-hidden="true" tabindex="-1"></a>                <span class="at">n.chains           =</span> <span class="dv">3</span>,</span>
<span id="cb195-25"><a href="bayesian-computation.html#cb195-25" aria-hidden="true" tabindex="-1"></a>                <span class="at">n.iter             =</span> <span class="dv">5000</span>)</span></code></pre></div>
<pre><code>## module glm loaded</code></pre>
<pre><code>## Compiling model graph
##    Resolving undeclared variables
##    Allocating nodes
## Graph information:
##    Observed stochastic nodes: 280
##    Unobserved stochastic nodes: 1
##    Total graph size: 283
## 
## Initializing model</code></pre>
<p>Let’s take a look at some summary statistics of the fit</p>
<div class="sourceCode" id="cb198"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb198-1"><a href="bayesian-computation.html#cb198-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(jagsfit)</span></code></pre></div>
<pre><code>## Inference for Bugs model at &quot;C:/Users/krgross/AppData/Local/Temp/RtmpqCr2sA/model104cc016b3b.txt&quot;, fit using jags,
##  3 chains, each with 5000 iterations (first 2500 discarded), n.thin = 2
##  n.sims = 3750 iterations saved
##          mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
## lambda     0.701    0.05   0.607   0.668   0.699   0.735   0.800 1.003   810
## deviance 629.293    1.40 628.310 628.408 628.757 629.625 633.275 1.001  3800
## 
## For each parameter, n.eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor (at convergence, Rhat=1).
## 
## DIC info (using the rule, pD = var(deviance)/2)
## pD = 1.0 and DIC = 630.3
## DIC is an estimate of expected predictive error (lower deviance is better).</code></pre>
<p>The Rhat values suggest that our chains have converged, as we might hope for such a simple model. We can generate a trace plot using <code>traceplot</code> to inspect convergence visually, but beware that visual assessment of convergence is prone to error</p>
<p>We can also use the <code>lattice</code> package to construct smoothed estimates of the posterior density:</p>
<div class="sourceCode" id="cb200"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb200-1"><a href="bayesian-computation.html#cb200-1" aria-hidden="true" tabindex="-1"></a><span class="fu">require</span>(lattice)</span></code></pre></div>
<pre><code>## Loading required package: lattice</code></pre>
<div class="sourceCode" id="cb202"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb202-1"><a href="bayesian-computation.html#cb202-1" aria-hidden="true" tabindex="-1"></a>jagsfit.mcmc <span class="ot">&lt;-</span> <span class="fu">as.mcmc</span>(jagsfit)</span>
<span id="cb202-2"><a href="bayesian-computation.html#cb202-2" aria-hidden="true" tabindex="-1"></a><span class="fu">densityplot</span>(jagsfit.mcmc)</span></code></pre></div>
<p><img src="03-BayesianComputation_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>For a more involved example, let’s take a look at the simple regression fit to the cricket data. First, we’ll make a plot of the data and fit a SLR model by least squares.</p>
<div class="sourceCode" id="cb203"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb203-1"><a href="bayesian-computation.html#cb203-1" aria-hidden="true" tabindex="-1"></a>cricket <span class="ot">&lt;-</span> <span class="fu">read.table</span>(<span class="st">&quot;data/cricket.txt&quot;</span>, <span class="at">header =</span> <span class="cn">TRUE</span>)</span>
<span id="cb203-2"><a href="bayesian-computation.html#cb203-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-3"><a href="bayesian-computation.html#cb203-3" aria-hidden="true" tabindex="-1"></a>cricket.slr <span class="ot">&lt;-</span> <span class="fu">lm</span>(chirps <span class="sc">~</span> temperature, <span class="at">data =</span> cricket)</span>
<span id="cb203-4"><a href="bayesian-computation.html#cb203-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(cricket.slr)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = chirps ~ temperature, data = cricket)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.56009 -0.57930  0.03129  0.59020  1.53259 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -0.30914    3.10858  -0.099 0.922299    
## temperature  0.21193    0.03871   5.475 0.000107 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9715 on 13 degrees of freedom
## Multiple R-squared:  0.6975, Adjusted R-squared:  0.6742 
## F-statistic: 29.97 on 1 and 13 DF,  p-value: 0.0001067</code></pre>
<div class="sourceCode" id="cb205"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb205-1"><a href="bayesian-computation.html#cb205-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(chirps <span class="sc">~</span> temperature, <span class="at">data =</span> cricket)</span>
<span id="cb205-2"><a href="bayesian-computation.html#cb205-2" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(cricket.slr)</span></code></pre></div>
<p><img src="03-BayesianComputation_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>Now we’ll fit the same model in JAGS, using vague priors for all model parameters</p>
<div class="sourceCode" id="cb206"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb206-1"><a href="bayesian-computation.html#cb206-1" aria-hidden="true" tabindex="-1"></a>cricket.model <span class="ot">&lt;-</span> <span class="cf">function</span>() {</span>
<span id="cb206-2"><a href="bayesian-computation.html#cb206-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb206-3"><a href="bayesian-computation.html#cb206-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>J) {             <span class="co"># J = number of data points</span></span>
<span id="cb206-4"><a href="bayesian-computation.html#cb206-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb206-5"><a href="bayesian-computation.html#cb206-5" aria-hidden="true" tabindex="-1"></a>    y[j] <span class="sc">~</span> <span class="fu">dnorm</span> (mu[j], tau)  <span class="co"># data model:  the likelihood </span></span>
<span id="cb206-6"><a href="bayesian-computation.html#cb206-6" aria-hidden="true" tabindex="-1"></a>                               <span class="co"># note that BUGS / JAGS uses precision</span></span>
<span id="cb206-7"><a href="bayesian-computation.html#cb206-7" aria-hidden="true" tabindex="-1"></a>                               <span class="co"># instead of variance</span></span>
<span id="cb206-8"><a href="bayesian-computation.html#cb206-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb206-9"><a href="bayesian-computation.html#cb206-9" aria-hidden="true" tabindex="-1"></a>    mu[j] <span class="ot">&lt;-</span> b0 <span class="sc">+</span> b1 <span class="sc">*</span> x[j]    <span class="co"># compute the mean for each observation</span></span>
<span id="cb206-10"><a href="bayesian-computation.html#cb206-10" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb206-11"><a href="bayesian-computation.html#cb206-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb206-12"><a href="bayesian-computation.html#cb206-12" aria-hidden="true" tabindex="-1"></a>  b0 <span class="sc">~</span> <span class="fu">dnorm</span> (<span class="fl">0.0</span>, <span class="fl">1E-6</span>)       <span class="co"># prior for intercept</span></span>
<span id="cb206-13"><a href="bayesian-computation.html#cb206-13" aria-hidden="true" tabindex="-1"></a>  b1 <span class="sc">~</span> <span class="fu">dnorm</span> (<span class="fl">0.0</span>, <span class="fl">1E-6</span>)       <span class="co"># prior for slope</span></span>
<span id="cb206-14"><a href="bayesian-computation.html#cb206-14" aria-hidden="true" tabindex="-1"></a>  tau <span class="sc">~</span> <span class="fu">dgamma</span> (<span class="fl">0.01</span>, <span class="fl">0.01</span>)    <span class="co"># prior for tau</span></span>
<span id="cb206-15"><a href="bayesian-computation.html#cb206-15" aria-hidden="true" tabindex="-1"></a>                               <span class="co"># note that BUGS / JAGS parameterizes </span></span>
<span id="cb206-16"><a href="bayesian-computation.html#cb206-16" aria-hidden="true" tabindex="-1"></a>                               <span class="co"># gamma by shape, rate</span></span>
<span id="cb206-17"><a href="bayesian-computation.html#cb206-17" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb206-18"><a href="bayesian-computation.html#cb206-18" aria-hidden="true" tabindex="-1"></a>  sigma <span class="ot">&lt;-</span> <span class="fu">pow</span>(tau, <span class="sc">-</span><span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>)      <span class="co"># the SD of the residaul errors</span></span>
<span id="cb206-19"><a href="bayesian-computation.html#cb206-19" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb206-20"><a href="bayesian-computation.html#cb206-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb206-21"><a href="bayesian-computation.html#cb206-21" aria-hidden="true" tabindex="-1"></a>jags.data <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">y =</span> cricket<span class="sc">$</span>chirps, </span>
<span id="cb206-22"><a href="bayesian-computation.html#cb206-22" aria-hidden="true" tabindex="-1"></a>                  <span class="at">x =</span> cricket<span class="sc">$</span>temperature,</span>
<span id="cb206-23"><a href="bayesian-computation.html#cb206-23" aria-hidden="true" tabindex="-1"></a>                  <span class="at">J =</span> <span class="fu">nrow</span>(cricket))</span>
<span id="cb206-24"><a href="bayesian-computation.html#cb206-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb206-25"><a href="bayesian-computation.html#cb206-25" aria-hidden="true" tabindex="-1"></a>jags.params <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;b0&quot;</span>, <span class="st">&quot;b1&quot;</span>, <span class="st">&quot;tau&quot;</span>, <span class="st">&quot;sigma&quot;</span>)</span>
<span id="cb206-26"><a href="bayesian-computation.html#cb206-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb206-27"><a href="bayesian-computation.html#cb206-27" aria-hidden="true" tabindex="-1"></a>jags.inits <span class="ot">&lt;-</span> <span class="cf">function</span>(){</span>
<span id="cb206-28"><a href="bayesian-computation.html#cb206-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">list</span>(<span class="st">&quot;b0&quot;</span> <span class="ot">=</span> <span class="fu">rnorm</span>(<span class="dv">1</span>), <span class="st">&quot;b1&quot;</span> <span class="ot">=</span> <span class="fu">rnorm</span>(<span class="dv">1</span>), <span class="st">&quot;tau&quot;</span> <span class="ot">=</span> <span class="fu">runif</span>(<span class="dv">1</span>))</span>
<span id="cb206-29"><a href="bayesian-computation.html#cb206-29" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb206-30"><a href="bayesian-computation.html#cb206-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb206-31"><a href="bayesian-computation.html#cb206-31" aria-hidden="true" tabindex="-1"></a>jagsfit <span class="ot">&lt;-</span> <span class="fu">jags</span>(<span class="at">data               =</span> jags.data, </span>
<span id="cb206-32"><a href="bayesian-computation.html#cb206-32" aria-hidden="true" tabindex="-1"></a>                <span class="at">inits              =</span> jags.inits, </span>
<span id="cb206-33"><a href="bayesian-computation.html#cb206-33" aria-hidden="true" tabindex="-1"></a>                <span class="at">parameters.to.save =</span> jags.params,</span>
<span id="cb206-34"><a href="bayesian-computation.html#cb206-34" aria-hidden="true" tabindex="-1"></a>                <span class="at">model.file         =</span> cricket.model,</span>
<span id="cb206-35"><a href="bayesian-computation.html#cb206-35" aria-hidden="true" tabindex="-1"></a>                <span class="at">n.chains           =</span> <span class="dv">3</span>,</span>
<span id="cb206-36"><a href="bayesian-computation.html#cb206-36" aria-hidden="true" tabindex="-1"></a>                <span class="at">n.iter             =</span> <span class="dv">5000</span>)</span></code></pre></div>
<pre><code>## Compiling model graph
##    Resolving undeclared variables
##    Allocating nodes
## Graph information:
##    Observed stochastic nodes: 15
##    Unobserved stochastic nodes: 3
##    Total graph size: 70
## 
## Initializing model</code></pre>
<div class="sourceCode" id="cb208"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb208-1"><a href="bayesian-computation.html#cb208-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(jagsfit)</span></code></pre></div>
<pre><code>## Inference for Bugs model at &quot;C:/Users/krgross/AppData/Local/Temp/RtmpqCr2sA/model104c66fc5517.txt&quot;, fit using jags,
##  3 chains, each with 5000 iterations (first 2500 discarded), n.thin = 2
##  n.sims = 3750 iterations saved
##          mu.vect sd.vect   2.5%    25%    50%    75%  97.5%  Rhat n.eff
## b0        -0.258   3.449 -6.935 -2.501 -0.261  1.918  6.483 1.001  3800
## b1         0.211   0.043  0.127  0.184  0.212  0.239  0.295 1.001  3800
## sigma      1.036   0.223  0.700  0.881  0.999  1.153  1.582 1.001  3000
## tau        1.052   0.411  0.399  0.752  1.002  1.288  2.042 1.001  3000
## deviance  42.928   2.812 39.793 40.933 42.197 44.111 50.587 1.001  3800
## 
## For each parameter, n.eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor (at convergence, Rhat=1).
## 
## DIC info (using the rule, pD = var(deviance)/2)
## pD = 4.0 and DIC = 46.9
## DIC is an estimate of expected predictive error (lower deviance is better).</code></pre>
<div class="sourceCode" id="cb210"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb210-1"><a href="bayesian-computation.html#cb210-1" aria-hidden="true" tabindex="-1"></a><span class="fu">traceplot</span>(jagsfit)</span></code></pre></div>
<p><img src="03-BayesianComputation_files/figure-html/unnamed-chunk-13-1.png" width="672" /><img src="03-BayesianComputation_files/figure-html/unnamed-chunk-13-2.png" width="672" /><img src="03-BayesianComputation_files/figure-html/unnamed-chunk-13-3.png" width="672" /><img src="03-BayesianComputation_files/figure-html/unnamed-chunk-13-4.png" width="672" /><img src="03-BayesianComputation_files/figure-html/unnamed-chunk-13-5.png" width="672" /></p>
<p>The traces for the intercept aren’t great, but we haven’t centered the predictor either. In the usual way, the slope and intercept are strongly negatively correlated in the posterior. We can visualize this posterior correlation:</p>
<div class="sourceCode" id="cb211"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb211-1"><a href="bayesian-computation.html#cb211-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(hexbin)</span></code></pre></div>
<pre><code>## Warning: package &#39;hexbin&#39; was built under R version 4.1.1</code></pre>
<div class="sourceCode" id="cb213"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb213-1"><a href="bayesian-computation.html#cb213-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(RColorBrewer)</span>
<span id="cb213-2"><a href="bayesian-computation.html#cb213-2" aria-hidden="true" tabindex="-1"></a>rf <span class="ot">&lt;-</span> <span class="fu">colorRampPalette</span>(<span class="fu">rev</span>(<span class="fu">brewer.pal</span>(<span class="dv">11</span>, <span class="st">&#39;Spectral&#39;</span>)))</span>
<span id="cb213-3"><a href="bayesian-computation.html#cb213-3" aria-hidden="true" tabindex="-1"></a><span class="fu">with</span>(jagsfit<span class="sc">$</span>BUGSoutput<span class="sc">$</span>sims.list, <span class="fu">hexbinplot</span>(b1 <span class="sc">~</span> b0, <span class="at">colramp =</span> rf))</span></code></pre></div>
<p><img src="03-BayesianComputation_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>If we want to estimate the posterior correlation of the intercept and the slope, we can do so by accessing the MCMC samples. For an rjags object, the samples are stored in <code>BUGSoutput$sims.list</code>.</p>
<div class="sourceCode" id="cb214"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb214-1"><a href="bayesian-computation.html#cb214-1" aria-hidden="true" tabindex="-1"></a><span class="fu">with</span>(jagsfit<span class="sc">$</span>BUGSoutput<span class="sc">$</span>sims.list, <span class="fu">cor</span>(b0, b1))</span></code></pre></div>
<pre><code>##            [,1]
## [1,] -0.9967823</code></pre>
<p>Thus we estimate that the intercept and slope have a posterior correlation of -0.997.</p>
<p>We could make life easier on ourselves by centering the predictor and trying again:</p>
<div class="sourceCode" id="cb216"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb216-1"><a href="bayesian-computation.html#cb216-1" aria-hidden="true" tabindex="-1"></a>cricket<span class="sc">$</span>temp.ctr <span class="ot">&lt;-</span> cricket<span class="sc">$</span>temperature <span class="sc">-</span> <span class="fu">mean</span>(cricket<span class="sc">$</span>temperature)</span>
<span id="cb216-2"><a href="bayesian-computation.html#cb216-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb216-3"><a href="bayesian-computation.html#cb216-3" aria-hidden="true" tabindex="-1"></a>jags.data <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">y =</span> cricket<span class="sc">$</span>chirps, </span>
<span id="cb216-4"><a href="bayesian-computation.html#cb216-4" aria-hidden="true" tabindex="-1"></a>                  <span class="at">x =</span> cricket<span class="sc">$</span>temp.ctr,</span>
<span id="cb216-5"><a href="bayesian-computation.html#cb216-5" aria-hidden="true" tabindex="-1"></a>                  <span class="at">J =</span> <span class="fu">nrow</span>(cricket))</span>
<span id="cb216-6"><a href="bayesian-computation.html#cb216-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb216-7"><a href="bayesian-computation.html#cb216-7" aria-hidden="true" tabindex="-1"></a>jags.params <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;b0&quot;</span>, <span class="st">&quot;b1&quot;</span>, <span class="st">&quot;tau&quot;</span>, <span class="st">&quot;sigma&quot;</span>)</span>
<span id="cb216-8"><a href="bayesian-computation.html#cb216-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb216-9"><a href="bayesian-computation.html#cb216-9" aria-hidden="true" tabindex="-1"></a>jags.inits <span class="ot">&lt;-</span> <span class="cf">function</span>(){</span>
<span id="cb216-10"><a href="bayesian-computation.html#cb216-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">list</span>(<span class="st">&quot;b0&quot;</span> <span class="ot">=</span> <span class="fu">rnorm</span>(<span class="dv">1</span>), <span class="st">&quot;b1&quot;</span> <span class="ot">=</span> <span class="fu">rnorm</span>(<span class="dv">1</span>), <span class="st">&quot;tau&quot;</span> <span class="ot">=</span> <span class="fu">runif</span>(<span class="dv">1</span>))</span>
<span id="cb216-11"><a href="bayesian-computation.html#cb216-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb216-12"><a href="bayesian-computation.html#cb216-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb216-13"><a href="bayesian-computation.html#cb216-13" aria-hidden="true" tabindex="-1"></a>jagsfit <span class="ot">&lt;-</span> <span class="fu">jags</span>(<span class="at">data               =</span> jags.data, </span>
<span id="cb216-14"><a href="bayesian-computation.html#cb216-14" aria-hidden="true" tabindex="-1"></a>                <span class="at">inits              =</span> jags.inits, </span>
<span id="cb216-15"><a href="bayesian-computation.html#cb216-15" aria-hidden="true" tabindex="-1"></a>                <span class="at">parameters.to.save =</span> jags.params,</span>
<span id="cb216-16"><a href="bayesian-computation.html#cb216-16" aria-hidden="true" tabindex="-1"></a>                <span class="at">model.file         =</span> cricket.model,</span>
<span id="cb216-17"><a href="bayesian-computation.html#cb216-17" aria-hidden="true" tabindex="-1"></a>                <span class="at">n.chains           =</span> <span class="dv">3</span>,</span>
<span id="cb216-18"><a href="bayesian-computation.html#cb216-18" aria-hidden="true" tabindex="-1"></a>                <span class="at">n.iter             =</span> <span class="dv">5000</span>)</span></code></pre></div>
<pre><code>## Compiling model graph
##    Resolving undeclared variables
##    Allocating nodes
## Graph information:
##    Observed stochastic nodes: 15
##    Unobserved stochastic nodes: 3
##    Total graph size: 70
## 
## Initializing model</code></pre>
<div class="sourceCode" id="cb218"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb218-1"><a href="bayesian-computation.html#cb218-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(jagsfit)</span></code></pre></div>
<pre><code>## Inference for Bugs model at &quot;C:/Users/krgross/AppData/Local/Temp/RtmpqCr2sA/model104c3f023e41.txt&quot;, fit using jags,
##  3 chains, each with 5000 iterations (first 2500 discarded), n.thin = 2
##  n.sims = 3750 iterations saved
##          mu.vect sd.vect   2.5%    25%    50%    75%  97.5%  Rhat n.eff
## b0        16.653   0.276 16.100 16.482 16.648 16.831 17.209 1.001  3800
## b1         0.211   0.042  0.128  0.185  0.212  0.238  0.297 1.001  3800
## sigma      1.031   0.217  0.708  0.876  0.998  1.151  1.540 1.001  2600
## tau        1.059   0.411  0.422  0.755  1.005  1.304  1.997 1.001  2600
## deviance  42.895   2.678 39.802 40.934 42.181 44.133 49.873 1.001  3800
## 
## For each parameter, n.eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor (at convergence, Rhat=1).
## 
## DIC info (using the rule, pD = var(deviance)/2)
## pD = 3.6 and DIC = 46.5
## DIC is an estimate of expected predictive error (lower deviance is better).</code></pre>
<div class="sourceCode" id="cb220"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb220-1"><a href="bayesian-computation.html#cb220-1" aria-hidden="true" tabindex="-1"></a><span class="fu">traceplot</span>(jagsfit)</span></code></pre></div>
<p><img src="03-BayesianComputation_files/figure-html/unnamed-chunk-16-1.png" width="672" /><img src="03-BayesianComputation_files/figure-html/unnamed-chunk-16-2.png" width="672" /><img src="03-BayesianComputation_files/figure-html/unnamed-chunk-16-3.png" width="672" /><img src="03-BayesianComputation_files/figure-html/unnamed-chunk-16-4.png" width="672" /><img src="03-BayesianComputation_files/figure-html/unnamed-chunk-16-5.png" width="672" /></p>
<p>The posteriors for the intercept and slope are now uncorrelated:</p>
<div class="sourceCode" id="cb221"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb221-1"><a href="bayesian-computation.html#cb221-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(hexbin)</span>
<span id="cb221-2"><a href="bayesian-computation.html#cb221-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(RColorBrewer)</span>
<span id="cb221-3"><a href="bayesian-computation.html#cb221-3" aria-hidden="true" tabindex="-1"></a>rf <span class="ot">&lt;-</span> <span class="fu">colorRampPalette</span>(<span class="fu">rev</span>(<span class="fu">brewer.pal</span>(<span class="dv">11</span>, <span class="st">&#39;Spectral&#39;</span>)))</span>
<span id="cb221-4"><a href="bayesian-computation.html#cb221-4" aria-hidden="true" tabindex="-1"></a><span class="fu">with</span>(jagsfit<span class="sc">$</span>BUGSoutput<span class="sc">$</span>sims.list, <span class="fu">hexbinplot</span>(b1 <span class="sc">~</span> b0, <span class="at">colramp =</span> rf))</span></code></pre></div>
<p><img src="03-BayesianComputation_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<div class="sourceCode" id="cb222"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb222-1"><a href="bayesian-computation.html#cb222-1" aria-hidden="true" tabindex="-1"></a><span class="fu">with</span>(jagsfit<span class="sc">$</span>BUGSoutput<span class="sc">$</span>sims.list, <span class="fu">cor</span>(b0, b1))</span></code></pre></div>
<pre><code>##            [,1]
## [1,] 0.02335981</code></pre>
</div>
<div id="rstanarm" class="section level2" number="3.3">
<h2><span class="header-section-number">3.3</span> rstanarm</h2>
<p>The <code>rstanarm</code> package is a recent set of routines that seeks to provide a user-friendly front end to Bayesian analysis with Stan. Specifically, <code>rstanarm</code> provides functions for fitting standard statistical models that are meant to mimic the analogous fitting functions in R. For example, the basic routine for fitting linear models in R is <code>lm</code>; <code>rstanarm</code> provides a function <code>stan_lm</code> that strives to have the same functionality and interface as <code>lm</code>, albeit using Stan “under the hood” to generate Bayesian inference. (That said, the main workhorse function in <code>rstanarm</code> for model fitting is <code>stan_glm</code>, which attempts to mimic the native R function <code>glm</code> for fitting generalized linear models. Separately, the developers of <code>rstanarm</code> have taken the not unreasonable stance that generalized linear models should supplant general linear models as the analyst’s default approach to model fitting.)</p>
<p>To provide functionality that is similar to R’s native model-fitting routines, the functions in <code>rstanarm</code> make a number of operational decisions behind the scenes. Most notably, the model fitting routines in <code>rstanarm</code> will select default priors and default HMC parameters. While these defaults can always be modified by the analyst, the implementation of software that chooses priors by default is radical. First, the developers of <code>rstanarm</code> have their own particular view about what the role of the prior should be in data analysis. While their view is a considered one, by no means does it reflect a consensus that extends beyond the developers of the software. If you use <code>rstanarm</code>’s routines out of the box, you are accepting this view as your own if you do not specify the priors yourself. Second, as best I understand, the methods by which <code>rstanarm</code> chooses default priors still appear to be in some flux. That means that future versions of <code>rstanarm</code> may supply different default priors than those that are supplied today. As a result, the behavior of <code>rstanarm</code> today may differ from its behavior tomorrow, if you use the default priors.</p>
<p>All that said, here is how you might use <code>rstanarm</code> most simply to fit the two working examples in this chapter. We’ll begin by fitting the horse-kick data:</p>
<div class="sourceCode" id="cb224"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb224-1"><a href="bayesian-computation.html#cb224-1" aria-hidden="true" tabindex="-1"></a><span class="fu">require</span>(rstanarm)</span></code></pre></div>
<pre><code>## Loading required package: rstanarm</code></pre>
<pre><code>## Loading required package: Rcpp</code></pre>
<pre><code>## This is rstanarm version 2.21.1</code></pre>
<pre><code>## - See https://mc-stan.org/rstanarm/articles/priors for changes to default priors!</code></pre>
<pre><code>## - Default priors may change, so it&#39;s safest to specify priors, even if equivalent to the defaults.</code></pre>
<pre><code>## - For execution on a local, multicore CPU with excess RAM we recommend calling</code></pre>
<pre><code>##   options(mc.cores = parallel::detectCores())</code></pre>
<div class="sourceCode" id="cb232"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb232-1"><a href="bayesian-computation.html#cb232-1" aria-hidden="true" tabindex="-1"></a>stanarm.horse.fit <span class="ot">&lt;-</span> <span class="fu">stan_glm</span>(deaths <span class="sc">~</span> <span class="dv">1</span>, <span class="at">data =</span> horse, <span class="at">family =</span> poisson, <span class="at">seed =</span> <span class="dv">1</span>)</span></code></pre></div>
<pre><code>## 
## SAMPLING FOR MODEL &#39;count&#39; NOW (CHAIN 1).
## Chain 1: 
## Chain 1: Gradient evaluation took 0 seconds
## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
## Chain 1: Adjust your expectations accordingly!
## Chain 1: 
## Chain 1: 
## Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 1: 
## Chain 1:  Elapsed Time: 0.238 seconds (Warm-up)
## Chain 1:                0.228 seconds (Sampling)
## Chain 1:                0.466 seconds (Total)
## Chain 1: 
## 
## SAMPLING FOR MODEL &#39;count&#39; NOW (CHAIN 2).
## Chain 2: 
## Chain 2: Gradient evaluation took 0 seconds
## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
## Chain 2: Adjust your expectations accordingly!
## Chain 2: 
## Chain 2: 
## Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 2: 
## Chain 2:  Elapsed Time: 0.221 seconds (Warm-up)
## Chain 2:                0.259 seconds (Sampling)
## Chain 2:                0.48 seconds (Total)
## Chain 2: 
## 
## SAMPLING FOR MODEL &#39;count&#39; NOW (CHAIN 3).
## Chain 3: 
## Chain 3: Gradient evaluation took 0 seconds
## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
## Chain 3: Adjust your expectations accordingly!
## Chain 3: 
## Chain 3: 
## Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 3: 
## Chain 3:  Elapsed Time: 0.233 seconds (Warm-up)
## Chain 3:                0.258 seconds (Sampling)
## Chain 3:                0.491 seconds (Total)
## Chain 3: 
## 
## SAMPLING FOR MODEL &#39;count&#39; NOW (CHAIN 4).
## Chain 4: 
## Chain 4: Gradient evaluation took 0 seconds
## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
## Chain 4: Adjust your expectations accordingly!
## Chain 4: 
## Chain 4: 
## Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 4: 
## Chain 4:  Elapsed Time: 0.283 seconds (Warm-up)
## Chain 4:                0.277 seconds (Sampling)
## Chain 4:                0.56 seconds (Total)
## Chain 4:</code></pre>
<p>The model formula (“deaths ~ 1”) requires a bit of explanation. Essentially, we are fitting a regression model that only includes an intercept. In R, the way to fit a model with only an intercept is to include a “1” on the right-hand side of the model formula. The call to <code>stan_glm</code> is meant to mimic the call Here we have supplied the random number seed for the HMC sampling. Let’s take a look:</p>
<div class="sourceCode" id="cb234"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb234-1"><a href="bayesian-computation.html#cb234-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(stanarm.horse.fit, <span class="at">digits =</span> <span class="dv">3</span>)</span></code></pre></div>
<pre><code>## stan_glm
##  family:       poisson [log]
##  formula:      deaths ~ 1
##  observations: 280
##  predictors:   1
## ------
##             Median MAD_SD
## (Intercept) -0.355  0.073
## 
## ------
## * For help interpreting the printed output see ?print.stanreg
## * For info on the priors used see ?prior_summary.stanreg</code></pre>
<p>The parameter labeled (Intercept) is <span class="math inline">\(\log(\lambda)\)</span>.</p>
<p>Now we’ll fit the simple regression to the cricket data:</p>
<div class="sourceCode" id="cb236"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb236-1"><a href="bayesian-computation.html#cb236-1" aria-hidden="true" tabindex="-1"></a>stanarm.cricket.fit <span class="ot">&lt;-</span> <span class="fu">stan_glm</span>(chirps <span class="sc">~</span> temp.ctr, <span class="at">data =</span> cricket, <span class="at">family =</span> gaussian, <span class="at">seed =</span> <span class="dv">1</span>)</span></code></pre></div>
<pre><code>## 
## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 1).
## Chain 1: 
## Chain 1: Gradient evaluation took 0 seconds
## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
## Chain 1: Adjust your expectations accordingly!
## Chain 1: 
## Chain 1: 
## Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 1: 
## Chain 1:  Elapsed Time: 0.08 seconds (Warm-up)
## Chain 1:                0.091 seconds (Sampling)
## Chain 1:                0.171 seconds (Total)
## Chain 1: 
## 
## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 2).
## Chain 2: 
## Chain 2: Gradient evaluation took 0 seconds
## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
## Chain 2: Adjust your expectations accordingly!
## Chain 2: 
## Chain 2: 
## Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 2: 
## Chain 2:  Elapsed Time: 0.081 seconds (Warm-up)
## Chain 2:                0.063 seconds (Sampling)
## Chain 2:                0.144 seconds (Total)
## Chain 2: 
## 
## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 3).
## Chain 3: 
## Chain 3: Gradient evaluation took 0 seconds
## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
## Chain 3: Adjust your expectations accordingly!
## Chain 3: 
## Chain 3: 
## Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 3: 
## Chain 3:  Elapsed Time: 0.062 seconds (Warm-up)
## Chain 3:                0.064 seconds (Sampling)
## Chain 3:                0.126 seconds (Total)
## Chain 3: 
## 
## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 4).
## Chain 4: 
## Chain 4: Gradient evaluation took 0 seconds
## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
## Chain 4: Adjust your expectations accordingly!
## Chain 4: 
## Chain 4: 
## Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 4: 
## Chain 4:  Elapsed Time: 0.071 seconds (Warm-up)
## Chain 4:                0.058 seconds (Sampling)
## Chain 4:                0.129 seconds (Total)
## Chain 4:</code></pre>
<div class="sourceCode" id="cb238"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb238-1"><a href="bayesian-computation.html#cb238-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(stanarm.cricket.fit, <span class="at">digits =</span> <span class="dv">3</span>)</span></code></pre></div>
<pre><code>## stan_glm
##  family:       gaussian [identity]
##  formula:      chirps ~ temp.ctr
##  observations: 15
##  predictors:   2
## ------
##             Median MAD_SD
## (Intercept) 16.648  0.257
## temp.ctr     0.210  0.041
## 
## Auxiliary parameter(s):
##       Median MAD_SD
## sigma 1.008  0.198 
## 
## ------
## * For help interpreting the printed output see ?print.stanreg
## * For info on the priors used see ?prior_summary.stanreg</code></pre>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="beyond-the-mle-confidence-regions-and-hypothesis-tests-using-the-likelihood-function.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
