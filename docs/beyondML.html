<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 2 Beyond the MLE: Confidence regions and hypothesis tests using the likelihood function | Applied statistical analysis of non-normal and/or correlated data</title>
  <meta name="description" content="This is a proto-textbook for BMA / ST 590, Statistical Modeling in Ecology." />
  <meta name="generator" content="bookdown 0.43 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 2 Beyond the MLE: Confidence regions and hypothesis tests using the likelihood function | Applied statistical analysis of non-normal and/or correlated data" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is a proto-textbook for BMA / ST 590, Statistical Modeling in Ecology." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 Beyond the MLE: Confidence regions and hypothesis tests using the likelihood function | Applied statistical analysis of non-normal and/or correlated data" />
  
  <meta name="twitter:description" content="This is a proto-textbook for BMA / ST 590, Statistical Modeling in Ecology." />
  

<meta name="author" content="Kevin Gross" />


<meta name="date" content="2025-10-23" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="bayesian-computation.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<link href="libs/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.11.0/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.2.1/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.1/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-2.11.1/plotly-latest.min.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Maximum likelihood estimation</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#mathematical-basics"><i class="fa fa-check"></i><b>1.1</b> Mathematical basics</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#horse"><i class="fa fa-check"></i><b>1.2</b> Horse-kick data</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="index.html"><a href="index.html#calculate-and-plot-the-log-likelihood-function"><i class="fa fa-check"></i><b>1.2.1</b> Calculate and plot the log-likelihood function</a></li>
<li class="chapter" data-level="1.2.2" data-path="index.html"><a href="index.html#find-the-mle-numerically-using-optimize"><i class="fa fa-check"></i><b>1.2.2</b> Find the MLE numerically using ‘optimize’</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#pulse-rate-data"><i class="fa fa-check"></i><b>1.3</b> Pulse rate data</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#tadpole-data"><i class="fa fa-check"></i><b>1.4</b> Tadpole data</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#transformable-constraints"><i class="fa fa-check"></i><b>1.5</b> Transformable constraints</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="beyondML.html"><a href="beyondML.html"><i class="fa fa-check"></i><b>2</b> Beyond the MLE: Confidence regions and hypothesis tests using the likelihood function</a>
<ul>
<li class="chapter" data-level="2.1" data-path="beyondML.html"><a href="beyondML.html#confidence-intervals-for-single-parameters"><i class="fa fa-check"></i><b>2.1</b> Confidence intervals for single parameters</a></li>
<li class="chapter" data-level="2.2" data-path="beyondML.html"><a href="beyondML.html#two-param-mle"><i class="fa fa-check"></i><b>2.2</b> Confidence regions, profile likelihoods, and associated univariate intervals</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="beyondML.html"><a href="beyondML.html#profile-likelihoods"><i class="fa fa-check"></i><b>2.2.1</b> Profile likelihoods</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="beyondML.html"><a href="beyondML.html#quadapprox"><i class="fa fa-check"></i><b>2.3</b> Quadratic approximations to confidence intervals and regions</a></li>
<li class="chapter" data-level="2.4" data-path="beyondML.html"><a href="beyondML.html#comparing-models-likelihood-ratio-test-and-aic"><i class="fa fa-check"></i><b>2.4</b> Comparing models: Likelihood ratio test and AIC</a></li>
<li class="chapter" data-level="2.5" data-path="beyondML.html"><a href="beyondML.html#the-negative-binomial-distriution-revisited"><i class="fa fa-check"></i><b>2.5</b> The negative binomial distriution, revisited</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="bayesian-computation.html"><a href="bayesian-computation.html"><i class="fa fa-check"></i><b>3</b> Bayesian computation</a>
<ul>
<li class="chapter" data-level="3.1" data-path="bayesian-computation.html"><a href="bayesian-computation.html#computations-with-conjugate-priors"><i class="fa fa-check"></i><b>3.1</b> Computations with conjugate priors</a></li>
<li class="chapter" data-level="3.2" data-path="bayesian-computation.html"><a href="bayesian-computation.html#mcmc-and-stochastic-approximations-of-the-posterior"><i class="fa fa-check"></i><b>3.2</b> MCMC and stochastic approximations of the posterior</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="bayesian-computation.html"><a href="bayesian-computation.html#the-horse-kick-data-once-more"><i class="fa fa-check"></i><b>3.2.1</b> The horse-kick data, once more</a></li>
<li class="chapter" data-level="3.2.2" data-path="bayesian-computation.html"><a href="bayesian-computation.html#a-simple-regression-example"><i class="fa fa-check"></i><b>3.2.2</b> A simple regression example</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="bayesian-computation.html"><a href="bayesian-computation.html#rstanarm"><i class="fa fa-check"></i><b>3.3</b> rstanarm</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="smoothing-and-gams.html"><a href="smoothing-and-gams.html"><i class="fa fa-check"></i><b>4</b> Smoothing and GAMs</a>
<ul>
<li class="chapter" data-level="4.1" data-path="smoothing-and-gams.html"><a href="smoothing-and-gams.html#loess-smoothers"><i class="fa fa-check"></i><b>4.1</b> Loess smoothers</a></li>
<li class="chapter" data-level="4.2" data-path="smoothing-and-gams.html"><a href="smoothing-and-gams.html#splines"><i class="fa fa-check"></i><b>4.2</b> Splines</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="smoothing-and-gams.html"><a href="smoothing-and-gams.html#regression-splines"><i class="fa fa-check"></i><b>4.2.1</b> Regression splines</a></li>
<li class="chapter" data-level="4.2.2" data-path="smoothing-and-gams.html"><a href="smoothing-and-gams.html#natural-splines"><i class="fa fa-check"></i><b>4.2.2</b> Natural splines</a></li>
<li class="chapter" data-level="4.2.3" data-path="smoothing-and-gams.html"><a href="smoothing-and-gams.html#smoothing-splines"><i class="fa fa-check"></i><b>4.2.3</b> Smoothing splines</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="smoothing-and-gams.html"><a href="smoothing-and-gams.html#GAMs"><i class="fa fa-check"></i><b>4.3</b> Generalized additive models (GAMs)</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="generalized-least-squares.html"><a href="generalized-least-squares.html"><i class="fa fa-check"></i><b>5</b> Generalized Least Squares</a>
<ul>
<li class="chapter" data-level="5.1" data-path="generalized-least-squares.html"><a href="generalized-least-squares.html#heterogeneous-variance"><i class="fa fa-check"></i><b>5.1</b> Heterogeneous variance</a></li>
<li class="chapter" data-level="5.2" data-path="generalized-least-squares.html"><a href="generalized-least-squares.html#temporal-serial-correlation"><i class="fa fa-check"></i><b>5.2</b> Temporal (serial) correlation</a></li>
<li class="chapter" data-level="5.3" data-path="generalized-least-squares.html"><a href="generalized-least-squares.html#spatial-data"><i class="fa fa-check"></i><b>5.3</b> Spatial data</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="hierarchical-mixed-models.html"><a href="hierarchical-mixed-models.html"><i class="fa fa-check"></i><b>6</b> Hierarchical (mixed) models</a>
<ul>
<li class="chapter" data-level="6.1" data-path="hierarchical-mixed-models.html"><a href="hierarchical-mixed-models.html#one-factor-layout-dyestuff-data"><i class="fa fa-check"></i><b>6.1</b> One-factor layout: Dyestuff data</a></li>
<li class="chapter" data-level="6.2" data-path="hierarchical-mixed-models.html"><a href="hierarchical-mixed-models.html#bayesian-analysis"><i class="fa fa-check"></i><b>6.2</b> Bayesian analysis</a></li>
<li class="chapter" data-level="6.3" data-path="hierarchical-mixed-models.html"><a href="hierarchical-mixed-models.html#negative-within-group-correlations"><i class="fa fa-check"></i><b>6.3</b> Negative within-group correlations</a></li>
<li class="chapter" data-level="6.4" data-path="hierarchical-mixed-models.html"><a href="hierarchical-mixed-models.html#random-coefficient-models-rikz-data"><i class="fa fa-check"></i><b>6.4</b> Random coefficient models: RIKZ data</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="hierarchical-mixed-models.html"><a href="hierarchical-mixed-models.html#analysis-without-beach-level-covariate"><i class="fa fa-check"></i><b>6.4.1</b> Analysis without beach-level covariate</a></li>
<li class="chapter" data-level="6.4.2" data-path="hierarchical-mixed-models.html"><a href="hierarchical-mixed-models.html#adding-a-beach-level-covariate"><i class="fa fa-check"></i><b>6.4.2</b> Adding a beach-level covariate</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="hierarchical-mixed-models.html"><a href="hierarchical-mixed-models.html#nested-and-crossed-random-effects"><i class="fa fa-check"></i><b>6.5</b> Nested and crossed random effects</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="hierarchical-mixed-models.html"><a href="hierarchical-mixed-models.html#nested-random-effects"><i class="fa fa-check"></i><b>6.5.1</b> Nested random effects</a></li>
<li class="chapter" data-level="6.5.2" data-path="hierarchical-mixed-models.html"><a href="hierarchical-mixed-models.html#crossed-random-effects"><i class="fa fa-check"></i><b>6.5.2</b> Crossed random effects</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html"><i class="fa fa-check"></i><b>7</b> Generalized linear models</a>
<ul>
<li class="chapter" data-level="7.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#glms-the-big-picture"><i class="fa fa-check"></i><b>7.1</b> GLMs: The big picture</a></li>
<li class="chapter" data-level="7.2" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#poisson-regression"><i class="fa fa-check"></i><b>7.2</b> Poisson regression</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#horse-kick-data-revisited"><i class="fa fa-check"></i><b>7.2.1</b> Horse-kick data revisited</a></li>
<li class="chapter" data-level="7.2.2" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#elephant-matings"><i class="fa fa-check"></i><b>7.2.2</b> Elephant matings</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#binary-responses"><i class="fa fa-check"></i><b>7.3</b> Binary responses</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#individual-binary-responses-tb-in-boar"><i class="fa fa-check"></i><b>7.3.1</b> Individual binary responses: TB in boar</a></li>
<li class="chapter" data-level="7.3.2" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#grouped-binary-data-tb-in-red-deer"><i class="fa fa-check"></i><b>7.3.2</b> Grouped binary data: TB in red deer</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#zero-adjusted-models-for-count-data"><i class="fa fa-check"></i><b>7.4</b> Zero-adjusted models for count data</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#zero-truncated-models"><i class="fa fa-check"></i><b>7.4.1</b> Zero-truncated models</a></li>
<li class="chapter" data-level="7.4.2" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#zero-inflated-models"><i class="fa fa-check"></i><b>7.4.2</b> Zero-inflated models</a></li>
<li class="chapter" data-level="7.4.3" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#zero-altered-or-hurdle-models"><i class="fa fa-check"></i><b>7.4.3</b> Zero-altered, or “hurdle”, models</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#generalized-additive-models-gams"><i class="fa fa-check"></i><b>7.5</b> Generalized additive models (GAMs)</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="generalized-linear-mixed-models.html"><a href="generalized-linear-mixed-models.html"><i class="fa fa-check"></i><b>8</b> Generalized linear mixed models</a>
<ul>
<li class="chapter" data-level="8.1" data-path="generalized-linear-mixed-models.html"><a href="generalized-linear-mixed-models.html#example-1-industrial-melanism-data"><i class="fa fa-check"></i><b>8.1</b> Example 1: Industrial melanism data</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="generalized-linear-mixed-models.html"><a href="generalized-linear-mixed-models.html#gees"><i class="fa fa-check"></i><b>8.1.1</b> GEEs</a></li>
<li class="chapter" data-level="8.1.2" data-path="generalized-linear-mixed-models.html"><a href="generalized-linear-mixed-models.html#glmms"><i class="fa fa-check"></i><b>8.1.2</b> GLMMs</a></li>
<li class="chapter" data-level="8.1.3" data-path="generalized-linear-mixed-models.html"><a href="generalized-linear-mixed-models.html#bayesian-fit"><i class="fa fa-check"></i><b>8.1.3</b> Bayesian fit</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="generalized-linear-mixed-models.html"><a href="generalized-linear-mixed-models.html#example-2-ticks-on-red-grouse"><i class="fa fa-check"></i><b>8.2</b> Example 2: Ticks on red grouse</a></li>
<li class="chapter" data-level="8.3" data-path="generalized-linear-mixed-models.html"><a href="generalized-linear-mixed-models.html#GAMMs"><i class="fa fa-check"></i><b>8.3</b> GAMMs</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="bibliography.html"><a href="bibliography.html"><i class="fa fa-check"></i>Bibliography</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Applied statistical analysis of non-normal and/or correlated data</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="beyondML" class="section level1 hasAnchor" number="2">
<h1><span class="header-section-number">Chapter 2</span> Beyond the MLE: Confidence regions and hypothesis tests using the likelihood function<a href="beyondML.html#beyondML" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Likelihood can be used for more than simply isolating the MLE. The likelihood can also be used to generate confidence intervals for single parameters, or confidence regions for several parameters. We’ll start by using the horse-kick data to see how to generate a confidence interval for a single parameter, and then move on to considering models with more than one parameter.</p>
<div id="confidence-intervals-for-single-parameters" class="section level2 hasAnchor" number="2.1">
<h2><span class="header-section-number">2.1</span> Confidence intervals for single parameters<a href="beyondML.html#confidence-intervals-for-single-parameters" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Likelihood regions for parameters can be found using upper contour sets of the log-likelihood function (or, equivalently, using lower contour sets of the negative log-likelihood function). An upper contour set consists of all values of the parameter(s) at which the log-likelihood is no less than a certain value. Even though this definition seems a bit wordy, the intuition is straightforward: if the log-likelihood measures the goodness of fit, then we just want to select the parameter values that correspond to a fit that is at least as good as a certain threshold.</p>
<p>We’ll start by constructing a confidence interval for <span class="math inline">\(\lambda\)</span> with the horse-kick data.</p>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="beyondML.html#cb67-1" tabindex="-1"></a>horse <span class="ot">&lt;-</span> <span class="fu">read.table</span>(<span class="st">&quot;data/horse.txt&quot;</span>, <span class="at">header =</span> <span class="cn">TRUE</span>)</span>
<span id="cb67-2"><a href="beyondML.html#cb67-2" tabindex="-1"></a></span>
<span id="cb67-3"><a href="beyondML.html#cb67-3" tabindex="-1"></a>horse.neg.ll <span class="ot">&lt;-</span> <span class="cf">function</span>(my.lambda) {</span>
<span id="cb67-4"><a href="beyondML.html#cb67-4" tabindex="-1"></a>  ll.vals <span class="ot">&lt;-</span> <span class="fu">dpois</span>(<span class="at">x =</span> horse<span class="sc">$</span>deaths, <span class="at">lambda =</span> my.lambda, <span class="at">log =</span> <span class="cn">TRUE</span>)</span>
<span id="cb67-5"><a href="beyondML.html#cb67-5" tabindex="-1"></a>  <span class="sc">-</span><span class="dv">1</span> <span class="sc">*</span> <span class="fu">sum</span>(ll.vals) </span>
<span id="cb67-6"><a href="beyondML.html#cb67-6" tabindex="-1"></a>}</span>
<span id="cb67-7"><a href="beyondML.html#cb67-7" tabindex="-1"></a></span>
<span id="cb67-8"><a href="beyondML.html#cb67-8" tabindex="-1"></a><span class="co"># create a vector of lambda values using the &#39;seq&#39;uence command</span></span>
<span id="cb67-9"><a href="beyondML.html#cb67-9" tabindex="-1"></a>lambda.vals <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="fl">0.5</span>, <span class="at">to =</span> <span class="fl">1.0</span>, <span class="at">by =</span> <span class="fl">0.01</span>)</span>
<span id="cb67-10"><a href="beyondML.html#cb67-10" tabindex="-1"></a></span>
<span id="cb67-11"><a href="beyondML.html#cb67-11" tabindex="-1"></a><span class="co"># create an empty vector to store the values of the log-likelihood</span></span>
<span id="cb67-12"><a href="beyondML.html#cb67-12" tabindex="-1"></a>ll.vals <span class="ot">&lt;-</span> <span class="fu">double</span>(<span class="at">length =</span> <span class="fu">length</span>(lambda.vals))</span>
<span id="cb67-13"><a href="beyondML.html#cb67-13" tabindex="-1"></a></span>
<span id="cb67-14"><a href="beyondML.html#cb67-14" tabindex="-1"></a><span class="co"># use a loop to find the log-likelihood for each value in lambda.vals</span></span>
<span id="cb67-15"><a href="beyondML.html#cb67-15" tabindex="-1"></a><span class="cf">for</span> (i.lambda <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(lambda.vals)) {</span>
<span id="cb67-16"><a href="beyondML.html#cb67-16" tabindex="-1"></a>  ll.vals[i.lambda] <span class="ot">&lt;-</span> <span class="fu">horse.neg.ll</span>(lambda.vals[i.lambda])</span>
<span id="cb67-17"><a href="beyondML.html#cb67-17" tabindex="-1"></a>}</span>
<span id="cb67-18"><a href="beyondML.html#cb67-18" tabindex="-1"></a></span>
<span id="cb67-19"><a href="beyondML.html#cb67-19" tabindex="-1"></a><span class="fu">plot</span>(ll.vals <span class="sc">~</span> lambda.vals, <span class="at">xlab =</span> <span class="st">&quot;lambda&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;negative log likelihood&quot;</span>, <span class="at">type =</span> <span class="st">&quot;l&quot;</span>)</span></code></pre></div>
<p><img src="02-LikelihoodConfideceRegions_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p>To find an asymptotic confidence interval for <span class="math inline">\(\lambda\)</span> with confidence level <span class="math inline">\(100 \times (1-\alpha)\%\)</span>, we want to find all the values of <span class="math inline">\(\lambda\)</span> for which the negative log-likelihood is no greater than <span class="math inline">\(\frac{1}{2}\chi^2_1(1-\alpha)\)</span> larger than the negative log-likelihood at the MLE.<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a> By <span class="math inline">\(\chi^2_1(1-\alpha)\)</span>, we mean <span class="math inline">\(1-\alpha\)</span> quantile of a <span class="math inline">\(\chi^2_1\)</span> distribution, which can be found with the function <code>qchisq</code> in R. The code below uses the function <code>uniroot</code> to find the upper and lower bounds of a 95% CI for <span class="math inline">\(\lambda\)</span>.</p>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb68-1"><a href="beyondML.html#cb68-1" tabindex="-1"></a>cutoff.ll <span class="ot">&lt;-</span> <span class="fu">horse.neg.ll</span>(<span class="fl">0.7</span>) <span class="sc">+</span> <span class="fu">qchisq</span>(<span class="fl">0.95</span>, <span class="at">df =</span> <span class="dv">1</span>) <span class="sc">/</span> <span class="dv">2</span></span>
<span id="cb68-2"><a href="beyondML.html#cb68-2" tabindex="-1"></a></span>
<span id="cb68-3"><a href="beyondML.html#cb68-3" tabindex="-1"></a><span class="co"># recreate the plot and add a line</span></span>
<span id="cb68-4"><a href="beyondML.html#cb68-4" tabindex="-1"></a><span class="fu">plot</span>(ll.vals <span class="sc">~</span> lambda.vals, <span class="at">xlab =</span> <span class="st">&quot;lambda&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;negative log likelihood&quot;</span>, <span class="at">type =</span> <span class="st">&quot;l&quot;</span>)</span>
<span id="cb68-5"><a href="beyondML.html#cb68-5" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> cutoff.ll, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>, <span class="at">lty =</span> <span class="st">&quot;dashed&quot;</span>)</span></code></pre></div>
<p><img src="02-LikelihoodConfideceRegions_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="beyondML.html#cb69-1" tabindex="-1"></a><span class="co"># use uniroot to find the confidence bounds precisely</span></span>
<span id="cb69-2"><a href="beyondML.html#cb69-2" tabindex="-1"></a></span>
<span id="cb69-3"><a href="beyondML.html#cb69-3" tabindex="-1"></a>my.function <span class="ot">&lt;-</span> <span class="cf">function</span>(my.lambda){</span>
<span id="cb69-4"><a href="beyondML.html#cb69-4" tabindex="-1"></a>  </span>
<span id="cb69-5"><a href="beyondML.html#cb69-5" tabindex="-1"></a>  <span class="fu">horse.neg.ll</span>(<span class="fl">0.7</span>) <span class="sc">+</span> <span class="fu">qchisq</span>(<span class="fl">0.95</span>, <span class="at">df =</span> <span class="dv">1</span>) <span class="sc">/</span> <span class="dv">2</span> <span class="sc">-</span> <span class="fu">horse.neg.ll</span>(my.lambda)  </span>
<span id="cb69-6"><a href="beyondML.html#cb69-6" tabindex="-1"></a>}</span>
<span id="cb69-7"><a href="beyondML.html#cb69-7" tabindex="-1"></a></span>
<span id="cb69-8"><a href="beyondML.html#cb69-8" tabindex="-1"></a>(lower <span class="ot">&lt;-</span> <span class="fu">uniroot</span>(<span class="at">f =</span> my.function, <span class="at">interval =</span> <span class="fu">c</span>(<span class="fl">0.6</span>, <span class="fl">0.7</span>)))</span></code></pre></div>
<pre><code>## $root
## [1] 0.6065198
## 
## $f.root
## [1] -3.556854e-05
## 
## $iter
## [1] 4
## 
## $init.it
## [1] NA
## 
## $estim.prec
## [1] 6.103516e-05</code></pre>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="beyondML.html#cb71-1" tabindex="-1"></a>(upper <span class="ot">&lt;-</span> <span class="fu">uniroot</span>(<span class="at">f =</span> my.function, <span class="at">interval =</span> <span class="fu">c</span>(<span class="fl">0.7</span>, <span class="fl">0.9</span>)))</span></code></pre></div>
<pre><code>## $root
## [1] 0.8026265
## 
## $f.root
## [1] -0.0001007316
## 
## $iter
## [1] 6
## 
## $init.it
## [1] NA
## 
## $estim.prec
## [1] 6.103516e-05</code></pre>
<p>As an alternative programming style, we could have defined the objective function on the fly without bothering to create <code>my.function</code>.</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="beyondML.html#cb73-1" tabindex="-1"></a>(lower <span class="ot">&lt;-</span> <span class="fu">uniroot</span>(<span class="at">f =</span> <span class="cf">function</span>(x) <span class="fu">horse.neg.ll</span>(<span class="fl">0.7</span>) <span class="sc">+</span> <span class="fu">qchisq</span>(<span class="fl">0.95</span>, <span class="at">df =</span> <span class="dv">1</span>) <span class="sc">/</span> <span class="dv">2</span> <span class="sc">-</span> <span class="fu">horse.neg.ll</span>(x) ,</span>
<span id="cb73-2"><a href="beyondML.html#cb73-2" tabindex="-1"></a>                 <span class="at">interval =</span> <span class="fu">c</span>(<span class="fl">0.6</span>, <span class="fl">0.7</span>)))</span></code></pre></div>
<pre><code>## $root
## [1] 0.6065198
## 
## $f.root
## [1] -3.556854e-05
## 
## $iter
## [1] 4
## 
## $init.it
## [1] NA
## 
## $estim.prec
## [1] 6.103516e-05</code></pre>
<p>Let’s recreate the plot and add vertical lines to indicate the confidence interval.</p>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="beyondML.html#cb75-1" tabindex="-1"></a><span class="fu">plot</span>(ll.vals <span class="sc">~</span> lambda.vals, <span class="at">xlab =</span> <span class="st">&quot;lambda&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;negative log likelihood&quot;</span>, <span class="at">type =</span> <span class="st">&quot;l&quot;</span>)</span>
<span id="cb75-2"><a href="beyondML.html#cb75-2" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> cutoff.ll, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>, <span class="at">lty =</span> <span class="st">&quot;dashed&quot;</span>)</span>
<span id="cb75-3"><a href="beyondML.html#cb75-3" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fu">c</span>(lower<span class="sc">$</span>root, upper<span class="sc">$</span>root), <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="02-LikelihoodConfideceRegions_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="beyondML.html#cb76-1" tabindex="-1"></a><span class="co"># clean up the workspace</span></span>
<span id="cb76-2"><a href="beyondML.html#cb76-2" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list =</span> <span class="fu">ls</span>())</span></code></pre></div>
<p>Thus, the 95% CI for <span class="math inline">\(\lambda\)</span> is <span class="math inline">\((0.607, 0.803)\)</span>.</p>
<p>There are two important caveats about the CIs constructed from the likelihood function in this way. First, the coverage is asymptotic, which means that the actual coverage is only guaranteed to match the nominal coverage (e.g., the 95% value) in the limit as the volume of data grows large. As Bolker (p. 194) notes, though, analysts use these asymptotic CIs “very freely”. Secondly, the CI is only valid if the MLE lies in the interior of its range of allowable values. Said the other way, the CI isn’t valid if the MLE lies at the edge of the parameter’s allowable values. We’ll have to worry about this most when constructing likelihood-based CIs for variances. To foreshadow, in mixed models we sometimes encounter a variance whose MLE is 0 — its smallest allowable value. In those case, we’ll have to modify the method detailed here to get a valid CI.</p>
<hr />
<p><span style="color: gray;"> Here’s a bit of the theory behind the result above for generating asymptotic CIs from the likelihood function. This is only a sketch of the theory (as it doesn’t justify the key step); for a more complete explanation, <span class="citation">Bolker (<a href="#ref-bolker2008">2008</a>)</span> suggests consulting <span class="citation">Kendall and Stuart (<a href="#ref-kendall1979">1979</a>)</span>.</span></p>
<p><span style="color: gray;"> Consider a model with <span class="math inline">\(k\)</span> parameters, and write those parameters generically as <span class="math inline">\(\theta_1, \theta_2, \ldots, \theta_k\)</span>. Write the likelihood as <span class="math inline">\(\mathcal{L}(\theta_1,\ldots,\theta_k)\)</span>, and write the MLEs as <span class="math inline">\(\hat{\theta_1}\)</span>, etc., in the usual way. Now consider a subset of <span class="math inline">\(r \leq k\)</span> of the parameters — and we might as well write these as the first <span class="math inline">\(r\)</span> parameters, <span class="math inline">\(\theta_1, \ldots, \theta_r\)</span> — and fix these at any particular value, and proceed to maximize the likelihood with respect to the remaining parameters. Write the values of the remaining parameters that maximize the likelihood as <span class="math inline">\(\tilde{\theta}_{r+1}, \ldots, \tilde{\theta}_k\)</span>. (It’s common to call these values the restricted MLEs, because they maximize the likelihood restricted to the values <span class="math inline">\(\theta_1, \ldots, \theta_r\)</span>, but in using this terminology we should not confuse these with REML estimates, which are yet to come and are a separate thing.) In other words,
<span class="math display">\[
\tilde{\theta}_{r+1}, \ldots, \tilde{\theta}_k = \mathop{\mathrm{arg\,max}}_{\theta_{r+1},\ldots,\theta_{k}} \mathcal{L}(\theta_1, \ldots, \theta_r, \theta_{r+1},\ldots, \theta_k).
\]</span>
Now (and this is the key step that we’ll just assert here) it can be shown that, asymptotically (e.g., in the limit as <span class="math inline">\(n\)</span> becomes large)
<span class="math display">\[
2 \ln \dfrac{\mathcal{L}(\hat{\theta}_1,\ldots,\hat{\theta}_k)}{\mathcal{L}(\theta_1, \ldots, \theta_r, \tilde{\theta}_{r+1},\ldots, \tilde{\theta}_k)} \sim \chi^2_r.
\]</span>
From here, it’s simple algebra to re-express the above in terms of the negative log likelihood to yield
<span class="math display">\[
2 \times \left[-\ell(\theta_1, \ldots, \theta_r, \tilde{\theta}_{r+1},\ldots, \tilde{\theta}_k) - (-\ell(\hat{\theta}_1,\ldots,\hat{\theta}_k)) \right] \sim \chi^2_r
\]</span>
from which the needed result follows.</span></p>
<hr />
</div>
<div id="two-param-mle" class="section level2 hasAnchor" number="2.2">
<h2><span class="header-section-number">2.2</span> Confidence regions, profile likelihoods, and associated univariate intervals<a href="beyondML.html#two-param-mle" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>With a 2-parameter model, we can plot a confidence region directly. First some housekeeping to get started:</p>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="beyondML.html#cb77-1" tabindex="-1"></a><span class="fu">library</span>(emdbook)</span>
<span id="cb77-2"><a href="beyondML.html#cb77-2" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;ReedfrogFuncresp&quot;</span>)</span>
<span id="cb77-3"><a href="beyondML.html#cb77-3" tabindex="-1"></a></span>
<span id="cb77-4"><a href="beyondML.html#cb77-4" tabindex="-1"></a><span class="co"># rename something shorter</span></span>
<span id="cb77-5"><a href="beyondML.html#cb77-5" tabindex="-1"></a></span>
<span id="cb77-6"><a href="beyondML.html#cb77-6" tabindex="-1"></a>frog <span class="ot">&lt;-</span> ReedfrogFuncresp</span>
<span id="cb77-7"><a href="beyondML.html#cb77-7" tabindex="-1"></a><span class="fu">rm</span>(ReedfrogFuncresp)</span>
<span id="cb77-8"><a href="beyondML.html#cb77-8" tabindex="-1"></a></span>
<span id="cb77-9"><a href="beyondML.html#cb77-9" tabindex="-1"></a>frog.neg.ll <span class="ot">&lt;-</span> <span class="cf">function</span>(params){</span>
<span id="cb77-10"><a href="beyondML.html#cb77-10" tabindex="-1"></a>  </span>
<span id="cb77-11"><a href="beyondML.html#cb77-11" tabindex="-1"></a>  a <span class="ot">&lt;-</span> params[<span class="dv">1</span>]</span>
<span id="cb77-12"><a href="beyondML.html#cb77-12" tabindex="-1"></a>  h <span class="ot">&lt;-</span> params[<span class="dv">2</span>]</span>
<span id="cb77-13"><a href="beyondML.html#cb77-13" tabindex="-1"></a>  </span>
<span id="cb77-14"><a href="beyondML.html#cb77-14" tabindex="-1"></a>  prob.vals <span class="ot">&lt;-</span> a <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> a <span class="sc">*</span> h <span class="sc">*</span> frog<span class="sc">$</span>Initial)</span>
<span id="cb77-15"><a href="beyondML.html#cb77-15" tabindex="-1"></a>  </span>
<span id="cb77-16"><a href="beyondML.html#cb77-16" tabindex="-1"></a>  ll.vals <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(frog<span class="sc">$</span>Killed, <span class="at">size =</span> frog<span class="sc">$</span>Initial, <span class="at">prob =</span> prob.vals, <span class="at">log =</span> <span class="cn">TRUE</span>)</span>
<span id="cb77-17"><a href="beyondML.html#cb77-17" tabindex="-1"></a>  <span class="sc">-</span><span class="dv">1</span> <span class="sc">*</span> <span class="fu">sum</span>(ll.vals)</span>
<span id="cb77-18"><a href="beyondML.html#cb77-18" tabindex="-1"></a>}</span>
<span id="cb77-19"><a href="beyondML.html#cb77-19" tabindex="-1"></a></span>
<span id="cb77-20"><a href="beyondML.html#cb77-20" tabindex="-1"></a>(frog.mle <span class="ot">&lt;-</span> <span class="fu">optim</span>(<span class="at">par =</span> <span class="fu">c</span>(<span class="fl">0.5</span>, <span class="dv">1</span><span class="sc">/</span><span class="dv">60</span>),</span>
<span id="cb77-21"><a href="beyondML.html#cb77-21" tabindex="-1"></a>                   <span class="at">fn  =</span> frog.neg.ll))</span></code></pre></div>
<pre><code>## Warning in dbinom(frog$Killed, size = frog$Initial, prob = prob.vals, log =
## TRUE): NaNs produced</code></pre>
<pre><code>## $par
## [1] 0.52585566 0.01660104
## 
## $value
## [1] 46.72136
## 
## $counts
## function gradient 
##       61       NA 
## 
## $convergence
## [1] 0
## 
## $message
## NULL</code></pre>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb80-1"><a href="beyondML.html#cb80-1" tabindex="-1"></a>a.mle <span class="ot">&lt;-</span> frog.mle<span class="sc">$</span>par[<span class="dv">1</span>]</span>
<span id="cb80-2"><a href="beyondML.html#cb80-2" tabindex="-1"></a>h.mle <span class="ot">&lt;-</span> frog.mle<span class="sc">$</span>par[<span class="dv">2</span>]</span>
<span id="cb80-3"><a href="beyondML.html#cb80-3" tabindex="-1"></a></span>
<span id="cb80-4"><a href="beyondML.html#cb80-4" tabindex="-1"></a><span class="co"># plot negative likelihood contours</span></span>
<span id="cb80-5"><a href="beyondML.html#cb80-5" tabindex="-1"></a></span>
<span id="cb80-6"><a href="beyondML.html#cb80-6" tabindex="-1"></a>a.vals <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="fl">0.3</span>, <span class="at">to =</span> <span class="fl">0.75</span>, <span class="at">by =</span> <span class="fl">0.01</span>)</span>
<span id="cb80-7"><a href="beyondML.html#cb80-7" tabindex="-1"></a>h.vals <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="fl">0.001</span>, <span class="at">to =</span> <span class="fl">0.03</span>, <span class="at">by =</span> <span class="fl">0.001</span>)</span>
<span id="cb80-8"><a href="beyondML.html#cb80-8" tabindex="-1"></a></span>
<span id="cb80-9"><a href="beyondML.html#cb80-9" tabindex="-1"></a>ll.vals <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="at">nrow =</span> <span class="fu">length</span>(a.vals), <span class="at">ncol =</span> <span class="fu">length</span>(h.vals))</span>
<span id="cb80-10"><a href="beyondML.html#cb80-10" tabindex="-1"></a></span>
<span id="cb80-11"><a href="beyondML.html#cb80-11" tabindex="-1"></a><span class="cf">for</span> (i.a <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(a.vals)) {</span>
<span id="cb80-12"><a href="beyondML.html#cb80-12" tabindex="-1"></a>  <span class="cf">for</span>(i.h <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(h.vals)) {</span>
<span id="cb80-13"><a href="beyondML.html#cb80-13" tabindex="-1"></a>    ll.vals[i.a, i.h] <span class="ot">&lt;-</span> <span class="fu">frog.neg.ll</span>(<span class="fu">c</span>(a.vals[i.a], h.vals[i.h]))</span>
<span id="cb80-14"><a href="beyondML.html#cb80-14" tabindex="-1"></a>  }</span>
<span id="cb80-15"><a href="beyondML.html#cb80-15" tabindex="-1"></a>}</span>
<span id="cb80-16"><a href="beyondML.html#cb80-16" tabindex="-1"></a></span>
<span id="cb80-17"><a href="beyondML.html#cb80-17" tabindex="-1"></a><span class="fu">contour</span>(<span class="at">x =</span> a.vals, <span class="at">y =</span> h.vals, <span class="at">z =</span> ll.vals, <span class="at">nlevels =</span> <span class="dv">100</span>,</span>
<span id="cb80-18"><a href="beyondML.html#cb80-18" tabindex="-1"></a>        <span class="at">xlab =</span> <span class="st">&quot;a&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;h&quot;</span>)</span>
<span id="cb80-19"><a href="beyondML.html#cb80-19" tabindex="-1"></a></span>
<span id="cb80-20"><a href="beyondML.html#cb80-20" tabindex="-1"></a><span class="fu">points</span>(<span class="at">x =</span> a.mle, <span class="at">y =</span> h.mle, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>, <span class="at">pch =</span> <span class="dv">16</span>)</span></code></pre></div>
<p><img src="02-LikelihoodConfideceRegions_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>Equipped with the contour plot, graphing the appropriate confidence region is straightforward.</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="beyondML.html#cb81-1" tabindex="-1"></a>cut.off <span class="ot">&lt;-</span> <span class="fu">frog.neg.ll</span>(<span class="fu">c</span>(a.mle, h.mle)) <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">/</span> <span class="dv">2</span>) <span class="sc">*</span> <span class="fu">qchisq</span>(.<span class="dv">95</span>, <span class="at">df =</span> <span class="dv">2</span>)</span>
<span id="cb81-2"><a href="beyondML.html#cb81-2" tabindex="-1"></a></span>
<span id="cb81-3"><a href="beyondML.html#cb81-3" tabindex="-1"></a><span class="co"># recreate the plot and add a line for the 95% confidence region</span></span>
<span id="cb81-4"><a href="beyondML.html#cb81-4" tabindex="-1"></a><span class="fu">contour</span>(<span class="at">x =</span> a.vals, <span class="at">y =</span> h.vals, <span class="at">z =</span> ll.vals, <span class="at">nlevels =</span> <span class="dv">100</span>,</span>
<span id="cb81-5"><a href="beyondML.html#cb81-5" tabindex="-1"></a>        <span class="at">xlab =</span> <span class="st">&quot;a&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;h&quot;</span>)</span>
<span id="cb81-6"><a href="beyondML.html#cb81-6" tabindex="-1"></a></span>
<span id="cb81-7"><a href="beyondML.html#cb81-7" tabindex="-1"></a><span class="fu">points</span>(<span class="at">x =</span> a.mle, <span class="at">y =</span> h.mle, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span>
<span id="cb81-8"><a href="beyondML.html#cb81-8" tabindex="-1"></a><span class="fu">contour</span>(<span class="at">x =</span> a.vals, <span class="at">y =</span> h.vals, <span class="at">z =</span> ll.vals, </span>
<span id="cb81-9"><a href="beyondML.html#cb81-9" tabindex="-1"></a>        <span class="at">levels =</span> cut.off,</span>
<span id="cb81-10"><a href="beyondML.html#cb81-10" tabindex="-1"></a>        <span class="at">add =</span> <span class="cn">TRUE</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="02-LikelihoodConfideceRegions_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<div id="profile-likelihoods" class="section level3 hasAnchor" number="2.2.1">
<h3><span class="header-section-number">2.2.1</span> Profile likelihoods<a href="beyondML.html#profile-likelihoods" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>There are several drawbacks to confidence regions. First, while a two-dimensional confidence region can be readily visualized, it is hard to summarize or describe. Second, and more importantly, most models have more than two parameters. In these models, a confidence region would have more than 2 dimensions, and thus would be impractical to visualize. Thus it is helpful, or even essential, to be able to generate univariate confidence intervals for single parameters from high-dimensional likelihoods.</p>
<p>There are two common approaches for generating univariate confidence intervals from a high-dimensional likelihood surface. The first method is called <em>slicing</em>. As the name perhaps suggests, a slice likelihood function is computed by allowing one or more parameter(s) of interest to vary while holding the other parameter(s) fixed at their MLEs. The slice likelihood then tells us about how the quality of the fit changes as we vary our parameter(s) of interest.</p>
<p>In notation, write our parameter(s) of interest as <span class="math inline">\(\theta\)</span> and write the other parameter(s) in the model as <span class="math inline">\(\phi\)</span>. (Here, we’ll let both <span class="math inline">\(\theta\)</span> and <span class="math inline">\(\phi\)</span> denote either single parameters or vectors of several parameters, as the situation requires. Doing this allows us to cut down on the notation.) Write the full likelihood function as <span class="math inline">\(\mathcal{L}(\theta, \phi)\)</span>. The slice likelihood for <span class="math inline">\(\theta\)</span>, which we might write as <span class="math inline">\(\mathcal{L}_s(\theta)\)</span>, is
<span class="math display">\[\begin{equation}
\mathcal{L}_s(\theta) = \mathcal{L}(\theta, \hat{\phi})
\end{equation}\]</span>
where <span class="math inline">\(\hat{\phi}\)</span> is the MLE of <span class="math inline">\(\phi\)</span>.</p>
<p>The advantage to the slice likelihood is that it is easy to compute. To write a slice-likelihood function for <span class="math inline">\(a\)</span> in the tadpole data, all we need is</p>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb82-1"><a href="beyondML.html#cb82-1" tabindex="-1"></a>slice.ll <span class="ot">&lt;-</span> <span class="cf">function</span>(a) <span class="fu">frog.neg.ll</span>(<span class="fu">c</span>(a, h.mle))</span></code></pre></div>
<p>Now we can plot the slice likelihood for different values of <span class="math inline">\(a\)</span>.</p>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="beyondML.html#cb83-1" tabindex="-1"></a>a.values <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="fl">0.3</span>, <span class="at">to =</span> <span class="fl">0.8</span>, <span class="at">by =</span> <span class="fl">0.01</span>)</span>
<span id="cb83-2"><a href="beyondML.html#cb83-2" tabindex="-1"></a>a.slice <span class="ot">&lt;-</span> <span class="fu">double</span>(<span class="at">length =</span> <span class="fu">length</span>(a.values))</span>
<span id="cb83-3"><a href="beyondML.html#cb83-3" tabindex="-1"></a></span>
<span id="cb83-4"><a href="beyondML.html#cb83-4" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(a.values)) a.slice[i] <span class="ot">&lt;-</span> <span class="fu">slice.ll</span>(a.values[i])</span>
<span id="cb83-5"><a href="beyondML.html#cb83-5" tabindex="-1"></a></span>
<span id="cb83-6"><a href="beyondML.html#cb83-6" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x =</span> a.values, <span class="at">y =</span> a.slice, <span class="at">xlab =</span> <span class="st">&quot;a&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;negative slice log-likelihood&quot;</span>, <span class="at">type =</span> <span class="st">&quot;l&quot;</span>)</span></code></pre></div>
<p><img src="02-LikelihoodConfideceRegions_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>The downside to a slice likelihood is that as we vary our parameter(s) of interest, we might be able to improve the fit by allowing the other parameters in the model to adjust. A <em>profile</em> likelihood tells us how the fit changes as we vary our parameter(s) of interest, while allowing the other parameters in the model to adjust. In other words, the profile likelihood tells us about the best fit available for a particular value of our parameter(s) of interest (which isn’t necessarily found by keeping the other model parameters fixed at their MLEs, as the slice likelihood does). Computing a profile likelihood takes a little more work, but it generally provides a more accurate understanding of how our parameter(s) of interest affects the fit.</p>
<p>Continuing with our notation above, the profile likelihood for <span class="math inline">\(\theta\)</span>, which we might write as <span class="math inline">\(\mathcal{L}_p(\theta)\)</span>, is
<span class="math display">\[\begin{equation}
\mathcal{L}_p(\theta) = \max_{\phi} \, \mathcal{L}(\theta, \phi).
\end{equation}\]</span></p>
<p>The code below calculates the (negative) profile log-likelihood for <span class="math inline">\(a\)</span> in the tadpole data.</p>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb84-1"><a href="beyondML.html#cb84-1" tabindex="-1"></a>profile.ll <span class="ot">&lt;-</span> <span class="cf">function</span>(my.a) {</span>
<span id="cb84-2"><a href="beyondML.html#cb84-2" tabindex="-1"></a>  </span>
<span id="cb84-3"><a href="beyondML.html#cb84-3" tabindex="-1"></a>  <span class="co"># Calculate the minimum log likelihood value for a given value of a, the attack rate</span></span>
<span id="cb84-4"><a href="beyondML.html#cb84-4" tabindex="-1"></a>  </span>
<span id="cb84-5"><a href="beyondML.html#cb84-5" tabindex="-1"></a>  my.ll <span class="ot">&lt;-</span> <span class="cf">function</span>(h) <span class="fu">frog.neg.ll</span>(<span class="fu">c</span>(my.a, h))</span>
<span id="cb84-6"><a href="beyondML.html#cb84-6" tabindex="-1"></a>  my.profile <span class="ot">&lt;-</span> <span class="fu">optimize</span>(<span class="at">f =</span> my.ll, <span class="at">interval =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.03</span>), <span class="at">maximum =</span> <span class="cn">FALSE</span>)</span>
<span id="cb84-7"><a href="beyondML.html#cb84-7" tabindex="-1"></a>  </span>
<span id="cb84-8"><a href="beyondML.html#cb84-8" tabindex="-1"></a>  my.profile<span class="sc">$</span>objective</span>
<span id="cb84-9"><a href="beyondML.html#cb84-9" tabindex="-1"></a>}</span>
<span id="cb84-10"><a href="beyondML.html#cb84-10" tabindex="-1"></a></span>
<span id="cb84-11"><a href="beyondML.html#cb84-11" tabindex="-1"></a><span class="co"># plot the profile likelihood vs. a</span></span>
<span id="cb84-12"><a href="beyondML.html#cb84-12" tabindex="-1"></a></span>
<span id="cb84-13"><a href="beyondML.html#cb84-13" tabindex="-1"></a>a.profile <span class="ot">&lt;-</span> <span class="fu">double</span>(<span class="at">length =</span> <span class="fu">length</span>(a.values))</span>
<span id="cb84-14"><a href="beyondML.html#cb84-14" tabindex="-1"></a></span>
<span id="cb84-15"><a href="beyondML.html#cb84-15" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(a.values)) a.profile[i] <span class="ot">&lt;-</span> <span class="fu">profile.ll</span>(a.values[i])</span>
<span id="cb84-16"><a href="beyondML.html#cb84-16" tabindex="-1"></a></span>
<span id="cb84-17"><a href="beyondML.html#cb84-17" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x =</span> a.values, <span class="at">y =</span> a.profile, <span class="at">xlab =</span> <span class="st">&quot;a&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;profile negative log-likelihood&quot;</span>, <span class="at">type =</span> <span class="st">&quot;l&quot;</span>)</span></code></pre></div>
<p><img src="02-LikelihoodConfideceRegions_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>Notice that the profile likelihood is shallower than the slice likelihood.</p>
<p>We can find a confidence region for <span class="math inline">\(\theta\)</span> using the upper contour sets of the profile likelihood, in just the same way as we did with the full likelihood. The code below computes a profile-based confidence interval for the attack rate <span class="math inline">\(a\)</span> in the tadpole data.</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="beyondML.html#cb85-1" tabindex="-1"></a><span class="co"># Now follow the same steps as before to find the profile 95% CI</span></span>
<span id="cb85-2"><a href="beyondML.html#cb85-2" tabindex="-1"></a></span>
<span id="cb85-3"><a href="beyondML.html#cb85-3" tabindex="-1"></a>cut.off <span class="ot">&lt;-</span> <span class="fu">profile.ll</span>(a.mle) <span class="sc">+</span> <span class="fu">qchisq</span>(<span class="fl">0.95</span>, <span class="at">df =</span> <span class="dv">1</span>) <span class="sc">/</span> <span class="dv">2</span></span>
<span id="cb85-4"><a href="beyondML.html#cb85-4" tabindex="-1"></a></span>
<span id="cb85-5"><a href="beyondML.html#cb85-5" tabindex="-1"></a>(lower <span class="ot">&lt;-</span> <span class="fu">uniroot</span>(<span class="at">f =</span> <span class="cf">function</span>(x) cut.off <span class="sc">-</span> <span class="fu">profile.ll</span>(x) ,</span>
<span id="cb85-6"><a href="beyondML.html#cb85-6" tabindex="-1"></a>                  <span class="at">interval =</span> <span class="fu">c</span>(<span class="fl">0.3</span>, a.mle)))</span></code></pre></div>
<pre><code>## $root
## [1] 0.4024268
## 
## $f.root
## [1] -0.0001303772
## 
## $iter
## [1] 6
## 
## $init.it
## [1] NA
## 
## $estim.prec
## [1] 6.103516e-05</code></pre>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb87-1"><a href="beyondML.html#cb87-1" tabindex="-1"></a>(upper <span class="ot">&lt;-</span> <span class="fu">uniroot</span>(<span class="at">f =</span> <span class="cf">function</span>(x) cut.off <span class="sc">-</span> <span class="fu">profile.ll</span>(x) ,</span>
<span id="cb87-2"><a href="beyondML.html#cb87-2" tabindex="-1"></a>                  <span class="at">interval =</span> <span class="fu">c</span>(a.mle, <span class="fl">0.8</span>)))</span></code></pre></div>
<pre><code>## $root
## [1] 0.6824678
## 
## $f.root
## [1] -9.763258e-06
## 
## $iter
## [1] 6
## 
## $init.it
## [1] NA
## 
## $estim.prec
## [1] 6.103516e-05</code></pre>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb89-1"><a href="beyondML.html#cb89-1" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x =</span> a.values, <span class="at">y =</span> a.profile, <span class="at">xlab =</span> <span class="st">&quot;a&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;negative log-likelihood&quot;</span>, <span class="at">type =</span> <span class="st">&quot;l&quot;</span>)</span>
<span id="cb89-2"><a href="beyondML.html#cb89-2" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fu">c</span>(lower<span class="sc">$</span>root, upper<span class="sc">$</span>root), <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>)</span>
<span id="cb89-3"><a href="beyondML.html#cb89-3" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> cut.off, <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="at">lty =</span> <span class="st">&quot;dashed&quot;</span>)</span></code></pre></div>
<p><img src="02-LikelihoodConfideceRegions_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>So, the 95% profile CI for <span class="math inline">\(a\)</span> is (0.402, 0.682).</p>
</div>
</div>
<div id="quadapprox" class="section level2 hasAnchor" number="2.3">
<h2><span class="header-section-number">2.3</span> Quadratic approximations to confidence intervals and regions<a href="beyondML.html#quadapprox" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Likelihood profiling provides a straightforward way to summarize a high-dimensional confidence region by univariate confidence intervals. However, these profile intervals can still involve quite a bit of computation. Further, they are not able to capture possible correlations among parameter estimates, which are revealed in (two-dimensional) confidence regions. (Recall the shape of the joint confidence region for the parameters <span class="math inline">\(a\)</span> and <span class="math inline">\(h\)</span> in the tadpole data.) Locally quadratic approximations provide a way to approximate the (already approximate) univariate confidence intervals and bivariate confidence regions using only information about the curvature of the likelihood surface at the MLE.</p>
<hr />
<p><span style="color: gray;"> There’s some remarkable theory behind the idea of approximating a log-likelihood with a quadratic function. Asymptotically, (that is, as the number of data points grows large), the sampling distribution of an MLE approaches a Gaussian distribution (with the usual caveat that the MLE can’t be on the edge of the allowable parameter space). But the log-likelihood of the parameters in a Gaussian distribution is exactly quadratic. Therefore, as the number of data points grows large, the log-likelihood function of any model will come to resemble a quadratic function in the neighborhood of the MLE.</span></p>
<hr />
<p>We’ll first start by revisiting the horse-kick data again. Of course, with the more precise <span class="math inline">\(\chi^2\)</span> based confidence interval in hand, there is no reason to seek an approximation. But doing so allows us to illustrate the calculations involved, and to see how well the approximation fares in this case.</p>
<p>First some housekeeping to read the data into memory, etc.</p>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb90-1"><a href="beyondML.html#cb90-1" tabindex="-1"></a><span class="co"># clean up</span></span>
<span id="cb90-2"><a href="beyondML.html#cb90-2" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list =</span> <span class="fu">ls</span>())</span>
<span id="cb90-3"><a href="beyondML.html#cb90-3" tabindex="-1"></a></span>
<span id="cb90-4"><a href="beyondML.html#cb90-4" tabindex="-1"></a><span class="co"># read in the data</span></span>
<span id="cb90-5"><a href="beyondML.html#cb90-5" tabindex="-1"></a></span>
<span id="cb90-6"><a href="beyondML.html#cb90-6" tabindex="-1"></a>horse <span class="ot">&lt;-</span> <span class="fu">read.table</span>(<span class="st">&quot;data/horse.txt&quot;</span>, <span class="at">header =</span> <span class="cn">TRUE</span>)</span>
<span id="cb90-7"><a href="beyondML.html#cb90-7" tabindex="-1"></a></span>
<span id="cb90-8"><a href="beyondML.html#cb90-8" tabindex="-1"></a>horse.neg.ll <span class="ot">&lt;-</span> <span class="cf">function</span>(my.lambda) {</span>
<span id="cb90-9"><a href="beyondML.html#cb90-9" tabindex="-1"></a>  ll.vals <span class="ot">&lt;-</span> <span class="fu">dpois</span>(<span class="at">x =</span> horse<span class="sc">$</span>deaths, <span class="at">lambda =</span> my.lambda, <span class="at">log =</span> <span class="cn">TRUE</span>)</span>
<span id="cb90-10"><a href="beyondML.html#cb90-10" tabindex="-1"></a>  <span class="sc">-</span><span class="dv">1</span> <span class="sc">*</span> <span class="fu">sum</span>(ll.vals) </span>
<span id="cb90-11"><a href="beyondML.html#cb90-11" tabindex="-1"></a>}</span>
<span id="cb90-12"><a href="beyondML.html#cb90-12" tabindex="-1"></a></span>
<span id="cb90-13"><a href="beyondML.html#cb90-13" tabindex="-1"></a><span class="co"># use uniroot to find the confidence bounds precisely</span></span>
<span id="cb90-14"><a href="beyondML.html#cb90-14" tabindex="-1"></a></span>
<span id="cb90-15"><a href="beyondML.html#cb90-15" tabindex="-1"></a>my.function <span class="ot">&lt;-</span> <span class="cf">function</span>(my.lambda){</span>
<span id="cb90-16"><a href="beyondML.html#cb90-16" tabindex="-1"></a>  </span>
<span id="cb90-17"><a href="beyondML.html#cb90-17" tabindex="-1"></a>  <span class="fu">horse.neg.ll</span>(<span class="fl">0.7</span>) <span class="sc">+</span> <span class="fu">qchisq</span>(<span class="fl">0.95</span>, <span class="at">df =</span> <span class="dv">1</span>) <span class="sc">/</span> <span class="dv">2</span> <span class="sc">-</span> <span class="fu">horse.neg.ll</span>(my.lambda)  </span>
<span id="cb90-18"><a href="beyondML.html#cb90-18" tabindex="-1"></a>}</span>
<span id="cb90-19"><a href="beyondML.html#cb90-19" tabindex="-1"></a></span>
<span id="cb90-20"><a href="beyondML.html#cb90-20" tabindex="-1"></a>lower <span class="ot">&lt;-</span> <span class="fu">uniroot</span>(<span class="at">f =</span> my.function, <span class="at">interval =</span> <span class="fu">c</span>(<span class="fl">0.6</span>, <span class="fl">0.7</span>))</span>
<span id="cb90-21"><a href="beyondML.html#cb90-21" tabindex="-1"></a>upper <span class="ot">&lt;-</span> <span class="fu">uniroot</span>(<span class="at">f =</span> my.function, <span class="at">interval =</span> <span class="fu">c</span>(<span class="fl">0.7</span>, <span class="fl">0.9</span>))</span></code></pre></div>
<p>To proceed with the approximation, we need to calculate the second derivative of the log-likelihood at the MLE. We’ll rely on the <code>hessian</code> routine in the <code>numDeriv</code> package to calculate this second derivative for us. However, it’s worth noting that we can approximate the second derivative numerically by the method of finite differences. This method only requires to additional evaluations of the likelihood function!</p>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb91-1"><a href="beyondML.html#cb91-1" tabindex="-1"></a><span class="do">## this function finds the second derivative at the MLE by finite differences</span></span>
<span id="cb91-2"><a href="beyondML.html#cb91-2" tabindex="-1"></a></span>
<span id="cb91-3"><a href="beyondML.html#cb91-3" tabindex="-1"></a>second.deriv <span class="ot">&lt;-</span> <span class="cf">function</span>(delta.l) {</span>
<span id="cb91-4"><a href="beyondML.html#cb91-4" tabindex="-1"></a>  </span>
<span id="cb91-5"><a href="beyondML.html#cb91-5" tabindex="-1"></a>  (<span class="fu">horse.neg.ll</span>(<span class="fl">0.7</span> <span class="sc">+</span> delta.l) <span class="sc">-</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fu">horse.neg.ll</span>(<span class="fl">0.7</span>) <span class="sc">+</span> <span class="fu">horse.neg.ll</span>(<span class="fl">0.7</span> <span class="sc">-</span> delta.l)) <span class="sc">/</span> delta.l <span class="sc">^</span> <span class="dv">2</span></span>
<span id="cb91-6"><a href="beyondML.html#cb91-6" tabindex="-1"></a>}</span>
<span id="cb91-7"><a href="beyondML.html#cb91-7" tabindex="-1"></a></span>
<span id="cb91-8"><a href="beyondML.html#cb91-8" tabindex="-1"></a>(horse.D2 <span class="ot">&lt;-</span> <span class="fu">second.deriv</span>(<span class="fl">1e-04</span>))</span></code></pre></div>
<pre><code>## [1] 400</code></pre>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb93-1"><a href="beyondML.html#cb93-1" tabindex="-1"></a><span class="co"># see how the answer changes if we change delta</span></span>
<span id="cb93-2"><a href="beyondML.html#cb93-2" tabindex="-1"></a><span class="fu">second.deriv</span>(<span class="fl">1e-05</span>)</span></code></pre></div>
<pre><code>## [1] 400.0003</code></pre>
<p>Let’s compare this answer to the answer obtained by <code>numDeriv::hessian</code>.</p>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb95-1"><a href="beyondML.html#cb95-1" tabindex="-1"></a>numDeriv<span class="sc">::</span><span class="fu">hessian</span>(<span class="at">func =</span> horse.neg.ll, <span class="at">x =</span> <span class="fl">0.7</span>)</span></code></pre></div>
<pre><code>##      [,1]
## [1,]  400</code></pre>
<p>The approximate standard error of <span class="math inline">\(\hat{\lambda}\)</span> is the square root of the inverse of the second derivative of the likelihood function.</p>
<div class="sourceCode" id="cb97"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb97-1"><a href="beyondML.html#cb97-1" tabindex="-1"></a>(lambda.se <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="dv">1</span> <span class="sc">/</span> horse.D2))</span></code></pre></div>
<pre><code>## [1] 0.05</code></pre>
<p>Now we can approximate the 95% confidence interval by using critical values from a standard normal distribution.</p>
<div class="sourceCode" id="cb99"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb99-1"><a href="beyondML.html#cb99-1" tabindex="-1"></a>(lower.approx <span class="ot">&lt;-</span> <span class="fl">0.7</span> <span class="sc">-</span> <span class="fu">qnorm</span>(.<span class="dv">975</span>) <span class="sc">*</span> lambda.se)</span></code></pre></div>
<pre><code>## [1] 0.6020018</code></pre>
<div class="sourceCode" id="cb101"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb101-1"><a href="beyondML.html#cb101-1" tabindex="-1"></a>(upper.approx <span class="ot">&lt;-</span> <span class="fl">0.7</span> <span class="sc">+</span> <span class="fu">qnorm</span>(.<span class="dv">975</span>) <span class="sc">*</span> lambda.se)</span></code></pre></div>
<pre><code>## [1] 0.7979982</code></pre>
<p>Compare the approximation to the “exact” values</p>
<div class="sourceCode" id="cb103"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb103-1"><a href="beyondML.html#cb103-1" tabindex="-1"></a>lower<span class="sc">$</span>root</span></code></pre></div>
<pre><code>## [1] 0.6065198</code></pre>
<div class="sourceCode" id="cb105"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb105-1"><a href="beyondML.html#cb105-1" tabindex="-1"></a>upper<span class="sc">$</span>root</span></code></pre></div>
<pre><code>## [1] 0.8026265</code></pre>
<p>Make a plot</p>
<div class="sourceCode" id="cb107"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb107-1"><a href="beyondML.html#cb107-1" tabindex="-1"></a><span class="co"># create a vector of lambda values using the &#39;seq&#39;uence command</span></span>
<span id="cb107-2"><a href="beyondML.html#cb107-2" tabindex="-1"></a>lambda.vals <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="fl">0.5</span>, <span class="at">to =</span> <span class="fl">1.0</span>, <span class="at">by =</span> <span class="fl">0.01</span>)</span>
<span id="cb107-3"><a href="beyondML.html#cb107-3" tabindex="-1"></a></span>
<span id="cb107-4"><a href="beyondML.html#cb107-4" tabindex="-1"></a><span class="co"># create an empty vector to store the values of the log-likelihood</span></span>
<span id="cb107-5"><a href="beyondML.html#cb107-5" tabindex="-1"></a>ll.vals <span class="ot">&lt;-</span> <span class="fu">double</span>(<span class="at">length =</span> <span class="fu">length</span>(lambda.vals))</span>
<span id="cb107-6"><a href="beyondML.html#cb107-6" tabindex="-1"></a></span>
<span id="cb107-7"><a href="beyondML.html#cb107-7" tabindex="-1"></a><span class="co"># use a loop to find the log-likelihood for each value in lambda.vals</span></span>
<span id="cb107-8"><a href="beyondML.html#cb107-8" tabindex="-1"></a><span class="cf">for</span> (i.lambda <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(lambda.vals)) {</span>
<span id="cb107-9"><a href="beyondML.html#cb107-9" tabindex="-1"></a>  ll.vals[i.lambda] <span class="ot">&lt;-</span> <span class="fu">horse.neg.ll</span>(lambda.vals[i.lambda])</span>
<span id="cb107-10"><a href="beyondML.html#cb107-10" tabindex="-1"></a>}</span>
<span id="cb107-11"><a href="beyondML.html#cb107-11" tabindex="-1"></a></span>
<span id="cb107-12"><a href="beyondML.html#cb107-12" tabindex="-1"></a><span class="fu">plot</span>(ll.vals <span class="sc">~</span> lambda.vals, <span class="at">xlab =</span> <span class="st">&quot;lambda&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;negative log likelihood&quot;</span>, <span class="at">type =</span> <span class="st">&quot;l&quot;</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span>
<span id="cb107-13"><a href="beyondML.html#cb107-13" tabindex="-1"></a></span>
<span id="cb107-14"><a href="beyondML.html#cb107-14" tabindex="-1"></a>approx.ll <span class="ot">&lt;-</span> <span class="cf">function</span>(lambda) <span class="fu">horse.neg.ll</span>(<span class="fl">0.7</span>) <span class="sc">+</span> (<span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>) <span class="sc">*</span> (lambda <span class="sc">-</span> <span class="fl">0.7</span>)<span class="sc">^</span><span class="dv">2</span> <span class="sc">*</span> horse.D2</span>
<span id="cb107-15"><a href="beyondML.html#cb107-15" tabindex="-1"></a></span>
<span id="cb107-16"><a href="beyondML.html#cb107-16" tabindex="-1"></a><span class="fu">curve</span>(approx.ll, <span class="at">from =</span> <span class="fu">min</span>(lambda.vals), <span class="at">to =</span> <span class="fu">max</span>(lambda.vals), <span class="at">add =</span> <span class="cn">TRUE</span>, <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>)</span>
<span id="cb107-17"><a href="beyondML.html#cb107-17" tabindex="-1"></a></span>
<span id="cb107-18"><a href="beyondML.html#cb107-18" tabindex="-1"></a><span class="do">###################################</span></span>
<span id="cb107-19"><a href="beyondML.html#cb107-19" tabindex="-1"></a><span class="do">## Now find the confidence interval, and plot it</span></span>
<span id="cb107-20"><a href="beyondML.html#cb107-20" tabindex="-1"></a><span class="do">####################################</span></span>
<span id="cb107-21"><a href="beyondML.html#cb107-21" tabindex="-1"></a></span>
<span id="cb107-22"><a href="beyondML.html#cb107-22" tabindex="-1"></a>cutoff.ll <span class="ot">&lt;-</span> <span class="fu">horse.neg.ll</span>(<span class="fl">0.7</span>) <span class="sc">+</span> <span class="fu">qchisq</span>(<span class="fl">0.95</span>, <span class="at">df =</span> <span class="dv">1</span>) <span class="sc">/</span> <span class="dv">2</span></span>
<span id="cb107-23"><a href="beyondML.html#cb107-23" tabindex="-1"></a></span>
<span id="cb107-24"><a href="beyondML.html#cb107-24" tabindex="-1"></a><span class="co"># add a line to the plot</span></span>
<span id="cb107-25"><a href="beyondML.html#cb107-25" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> cutoff.ll, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>, <span class="at">lty =</span> <span class="st">&quot;dashed&quot;</span>)</span>
<span id="cb107-26"><a href="beyondML.html#cb107-26" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fu">c</span>(lower<span class="sc">$</span>root, upper<span class="sc">$</span>root), <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span>
<span id="cb107-27"><a href="beyondML.html#cb107-27" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fu">c</span>(lower.approx, upper.approx), <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>)</span>
<span id="cb107-28"><a href="beyondML.html#cb107-28" tabindex="-1"></a></span>
<span id="cb107-29"><a href="beyondML.html#cb107-29" tabindex="-1"></a><span class="fu">legend</span>(<span class="at">x =</span> <span class="fl">0.65</span>, <span class="at">y =</span> <span class="dv">326</span>, </span>
<span id="cb107-30"><a href="beyondML.html#cb107-30" tabindex="-1"></a>       <span class="at">leg =</span> <span class="fu">c</span>(<span class="st">&quot;exact&quot;</span>, <span class="st">&quot;approximate&quot;</span>), </span>
<span id="cb107-31"><a href="beyondML.html#cb107-31" tabindex="-1"></a>       <span class="at">pch =</span> <span class="dv">16</span>, </span>
<span id="cb107-32"><a href="beyondML.html#cb107-32" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;blue&quot;</span>),</span>
<span id="cb107-33"><a href="beyondML.html#cb107-33" tabindex="-1"></a>       <span class="at">bty =</span> <span class="st">&quot;n&quot;</span>)</span></code></pre></div>
<p><img src="02-LikelihoodConfideceRegions_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb108-1"><a href="beyondML.html#cb108-1" tabindex="-1"></a><span class="co"># clean up</span></span>
<span id="cb108-2"><a href="beyondML.html#cb108-2" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list =</span> <span class="fu">ls</span>())</span></code></pre></div>
<p>Notice that the full <span class="math inline">\(\chi^2\)</span>-based confidence intervals capture the asymmetry in the information about <span class="math inline">\(\lambda\)</span>. The intervals based on the quadratic approximation are symmetric.</p>
<p>Now, use the quadratic approximation to find standard errors for <span class="math inline">\(\hat{a}\)</span> and <span class="math inline">\(\hat{h}\)</span> in the tadpole predation data.</p>
<p>The first part is preparatory work from old classes.</p>
<div class="sourceCode" id="cb109"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb109-1"><a href="beyondML.html#cb109-1" tabindex="-1"></a><span class="fu">library</span>(emdbook)</span>
<span id="cb109-2"><a href="beyondML.html#cb109-2" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;ReedfrogFuncresp&quot;</span>)</span>
<span id="cb109-3"><a href="beyondML.html#cb109-3" tabindex="-1"></a></span>
<span id="cb109-4"><a href="beyondML.html#cb109-4" tabindex="-1"></a><span class="co"># rename something shorter</span></span>
<span id="cb109-5"><a href="beyondML.html#cb109-5" tabindex="-1"></a></span>
<span id="cb109-6"><a href="beyondML.html#cb109-6" tabindex="-1"></a>frog <span class="ot">&lt;-</span> ReedfrogFuncresp</span>
<span id="cb109-7"><a href="beyondML.html#cb109-7" tabindex="-1"></a><span class="fu">rm</span>(ReedfrogFuncresp)</span>
<span id="cb109-8"><a href="beyondML.html#cb109-8" tabindex="-1"></a></span>
<span id="cb109-9"><a href="beyondML.html#cb109-9" tabindex="-1"></a>frog.neg.ll <span class="ot">&lt;-</span> <span class="cf">function</span>(params){</span>
<span id="cb109-10"><a href="beyondML.html#cb109-10" tabindex="-1"></a>  </span>
<span id="cb109-11"><a href="beyondML.html#cb109-11" tabindex="-1"></a>  a <span class="ot">&lt;-</span> params[<span class="dv">1</span>]</span>
<span id="cb109-12"><a href="beyondML.html#cb109-12" tabindex="-1"></a>  h <span class="ot">&lt;-</span> params[<span class="dv">2</span>]</span>
<span id="cb109-13"><a href="beyondML.html#cb109-13" tabindex="-1"></a>  </span>
<span id="cb109-14"><a href="beyondML.html#cb109-14" tabindex="-1"></a>  prob.vals <span class="ot">&lt;-</span> a <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> a <span class="sc">*</span> h <span class="sc">*</span> frog<span class="sc">$</span>Initial)</span>
<span id="cb109-15"><a href="beyondML.html#cb109-15" tabindex="-1"></a>  </span>
<span id="cb109-16"><a href="beyondML.html#cb109-16" tabindex="-1"></a>  ll.vals <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(frog<span class="sc">$</span>Killed, <span class="at">size =</span> frog<span class="sc">$</span>Initial, <span class="at">prob =</span> prob.vals, <span class="at">log =</span> <span class="cn">TRUE</span>)</span>
<span id="cb109-17"><a href="beyondML.html#cb109-17" tabindex="-1"></a>  <span class="sc">-</span><span class="dv">1</span> <span class="sc">*</span> <span class="fu">sum</span>(ll.vals)</span>
<span id="cb109-18"><a href="beyondML.html#cb109-18" tabindex="-1"></a>}</span>
<span id="cb109-19"><a href="beyondML.html#cb109-19" tabindex="-1"></a></span>
<span id="cb109-20"><a href="beyondML.html#cb109-20" tabindex="-1"></a>frog.mle <span class="ot">&lt;-</span> <span class="fu">optim</span>(<span class="at">par =</span> <span class="fu">c</span>(<span class="fl">0.5</span>, <span class="dv">1</span><span class="sc">/</span><span class="dv">60</span>),</span>
<span id="cb109-21"><a href="beyondML.html#cb109-21" tabindex="-1"></a>                  <span class="at">fn  =</span> frog.neg.ll)</span></code></pre></div>
<pre><code>## Warning in dbinom(frog$Killed, size = frog$Initial, prob = prob.vals, log =
## TRUE): NaNs produced</code></pre>
<div class="sourceCode" id="cb111"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb111-1"><a href="beyondML.html#cb111-1" tabindex="-1"></a>(a.mle <span class="ot">&lt;-</span> frog.mle<span class="sc">$</span>par[<span class="dv">1</span>])</span></code></pre></div>
<pre><code>## [1] 0.5258557</code></pre>
<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb113-1"><a href="beyondML.html#cb113-1" tabindex="-1"></a>(h.mle <span class="ot">&lt;-</span> frog.mle<span class="sc">$</span>par[<span class="dv">2</span>])</span></code></pre></div>
<pre><code>## [1] 0.01660104</code></pre>
<p>Now find the hessian:</p>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb115-1"><a href="beyondML.html#cb115-1" tabindex="-1"></a>(D2 <span class="ot">&lt;-</span> numDeriv<span class="sc">::</span><span class="fu">hessian</span>(<span class="at">func =</span> frog.neg.ll, <span class="at">x =</span> <span class="fu">c</span>(a.mle, h.mle)))</span></code></pre></div>
<pre><code>##            [,1]       [,2]
## [1,]   616.5606  -7394.263
## [2,] -7394.2628 130640.685</code></pre>
<p>The matrix inverse of the hessian is the variance-covariance matrix of the parameters. Note that R uses the function <code>solve</code> to find the inverse of a matrix.</p>
<div class="sourceCode" id="cb117"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb117-1"><a href="beyondML.html#cb117-1" tabindex="-1"></a><span class="co"># invert to get var-cov matrix</span></span>
<span id="cb117-2"><a href="beyondML.html#cb117-2" tabindex="-1"></a>(var.matrix <span class="ot">&lt;-</span> <span class="fu">solve</span>(D2))</span></code></pre></div>
<pre><code>##              [,1]         [,2]
## [1,] 0.0050493492 2.857932e-04
## [2,] 0.0002857932 2.383048e-05</code></pre>
<p>We can use the handy <code>cov2cor</code> function to convert the variance matrix into a correlation matrix:</p>
<div class="sourceCode" id="cb119"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb119-1"><a href="beyondML.html#cb119-1" tabindex="-1"></a><span class="fu">cov2cor</span>(var.matrix)</span></code></pre></div>
<pre><code>##           [,1]      [,2]
## [1,] 1.0000000 0.8238872
## [2,] 0.8238872 1.0000000</code></pre>
<p>Note the large correlation between <span class="math inline">\(\hat{a}\)</span> and <span class="math inline">\(\hat{h}\)</span>.</p>
<p>There are a few paths that we can take from here. It turns out that probability contours of a bivariate normal distribution are ellipses. So, we can use the <code>ellipse::ellipse</code> function to find (say) an approximate 95% confidence region for <span class="math inline">\((a,h)\)</span>. (There is some clever math behind this computation, but that math is beside the point here, so we’ll just use the available tools in <code>R</code>).</p>
<pre><code>## Loading required package: ellipse</code></pre>
<pre><code>## 
## Attaching package: &#39;ellipse&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:graphics&#39;:
## 
##     pairs</code></pre>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb124-1"><a href="beyondML.html#cb124-1" tabindex="-1"></a>approx<span class="fl">.95</span> <span class="ot">&lt;-</span> ellipse<span class="sc">::</span><span class="fu">ellipse</span>(var.matrix, <span class="at">center =</span> <span class="fu">c</span>(a.mle, h.mle), <span class="at">level =</span> <span class="fl">0.95</span>, <span class="at">npoints =</span> <span class="dv">200</span>)</span></code></pre></div>
<p>Now we’ll recreate our contour plot of the negative log likelihood, show the exact 95% confidence region, and overlay the approximate 95% confidence ellipse.</p>
<div class="sourceCode" id="cb125"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb125-1"><a href="beyondML.html#cb125-1" tabindex="-1"></a><span class="co"># plot negative likelihood contours</span></span>
<span id="cb125-2"><a href="beyondML.html#cb125-2" tabindex="-1"></a></span>
<span id="cb125-3"><a href="beyondML.html#cb125-3" tabindex="-1"></a>a.vals <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="fl">0.3</span>, <span class="at">to =</span> <span class="fl">0.75</span>, <span class="at">by =</span> <span class="fl">0.01</span>)</span>
<span id="cb125-4"><a href="beyondML.html#cb125-4" tabindex="-1"></a>h.vals <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="fl">0.001</span>, <span class="at">to =</span> <span class="fl">0.03</span>, <span class="at">by =</span> <span class="fl">0.001</span>)</span>
<span id="cb125-5"><a href="beyondML.html#cb125-5" tabindex="-1"></a></span>
<span id="cb125-6"><a href="beyondML.html#cb125-6" tabindex="-1"></a>ll.vals <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="at">nrow =</span> <span class="fu">length</span>(a.vals), <span class="at">ncol =</span> <span class="fu">length</span>(h.vals))</span>
<span id="cb125-7"><a href="beyondML.html#cb125-7" tabindex="-1"></a></span>
<span id="cb125-8"><a href="beyondML.html#cb125-8" tabindex="-1"></a><span class="cf">for</span> (i.a <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(a.vals)) {</span>
<span id="cb125-9"><a href="beyondML.html#cb125-9" tabindex="-1"></a>  <span class="cf">for</span>(i.h <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(h.vals)) {</span>
<span id="cb125-10"><a href="beyondML.html#cb125-10" tabindex="-1"></a>    ll.vals[i.a, i.h] <span class="ot">&lt;-</span> <span class="fu">frog.neg.ll</span>(<span class="fu">c</span>(a.vals[i.a], h.vals[i.h]))</span>
<span id="cb125-11"><a href="beyondML.html#cb125-11" tabindex="-1"></a>  }</span>
<span id="cb125-12"><a href="beyondML.html#cb125-12" tabindex="-1"></a>}</span>
<span id="cb125-13"><a href="beyondML.html#cb125-13" tabindex="-1"></a></span>
<span id="cb125-14"><a href="beyondML.html#cb125-14" tabindex="-1"></a><span class="fu">contour</span>(<span class="at">x =</span> a.vals, <span class="at">y =</span> h.vals, <span class="at">z =</span> ll.vals, <span class="at">nlevels =</span> <span class="dv">100</span>,</span>
<span id="cb125-15"><a href="beyondML.html#cb125-15" tabindex="-1"></a>        <span class="at">xlab =</span> <span class="st">&quot;a&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;h&quot;</span>)</span>
<span id="cb125-16"><a href="beyondML.html#cb125-16" tabindex="-1"></a></span>
<span id="cb125-17"><a href="beyondML.html#cb125-17" tabindex="-1"></a><span class="fu">points</span>(<span class="at">x =</span> a.mle, <span class="at">y =</span> h.mle, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>, <span class="at">pch =</span> <span class="dv">16</span>)</span>
<span id="cb125-18"><a href="beyondML.html#cb125-18" tabindex="-1"></a></span>
<span id="cb125-19"><a href="beyondML.html#cb125-19" tabindex="-1"></a>cut.off <span class="ot">&lt;-</span> <span class="fu">frog.neg.ll</span>(<span class="fu">c</span>(a.mle, h.mle)) <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">/</span> <span class="dv">2</span>) <span class="sc">*</span> <span class="fu">qchisq</span>(.<span class="dv">95</span>, <span class="at">df =</span> <span class="dv">2</span>)</span>
<span id="cb125-20"><a href="beyondML.html#cb125-20" tabindex="-1"></a></span>
<span id="cb125-21"><a href="beyondML.html#cb125-21" tabindex="-1"></a><span class="fu">contour</span>(<span class="at">x =</span> a.vals, <span class="at">y =</span> h.vals, <span class="at">z =</span> ll.vals, </span>
<span id="cb125-22"><a href="beyondML.html#cb125-22" tabindex="-1"></a>        <span class="at">levels =</span> cut.off,</span>
<span id="cb125-23"><a href="beyondML.html#cb125-23" tabindex="-1"></a>        <span class="at">add =</span> <span class="cn">TRUE</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb125-24"><a href="beyondML.html#cb125-24" tabindex="-1"></a></span>
<span id="cb125-25"><a href="beyondML.html#cb125-25" tabindex="-1"></a><span class="co"># add the approximate confidence ellipse</span></span>
<span id="cb125-26"><a href="beyondML.html#cb125-26" tabindex="-1"></a></span>
<span id="cb125-27"><a href="beyondML.html#cb125-27" tabindex="-1"></a><span class="fu">lines</span>(approx<span class="fl">.95</span>, <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="02-LikelihoodConfideceRegions_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<p>Compare this with Fig. 6.13 in Bolker.</p>
<p>We can also use the curvature to compute approximate standard errors for both parameters, as simply the square roots of the diagaonal elements of the variance-covariance matrix.</p>
<div class="sourceCode" id="cb126"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb126-1"><a href="beyondML.html#cb126-1" tabindex="-1"></a>(a.se <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(var.matrix[<span class="dv">1</span>, <span class="dv">1</span>]))</span></code></pre></div>
<pre><code>## [1] 0.07105877</code></pre>
<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb128-1"><a href="beyondML.html#cb128-1" tabindex="-1"></a>(h.se <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(var.matrix[<span class="dv">2</span>, <span class="dv">2</span>]))</span></code></pre></div>
<pre><code>## [1] 0.004881647</code></pre>
<p>Let’s use the (approximate) standard error of <span class="math inline">\(\hat{a}\)</span> to calculate an (approximate) 95% confidence interval:</p>
<div class="sourceCode" id="cb130"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb130-1"><a href="beyondML.html#cb130-1" tabindex="-1"></a>(ci.approx <span class="ot">&lt;-</span> a.mle <span class="sc">+</span> <span class="fu">qnorm</span>(<span class="fu">c</span>(<span class="fl">0.025</span>, .<span class="dv">975</span>)) <span class="sc">*</span> a.se)</span></code></pre></div>
<pre><code>## [1] 0.3865830 0.6651283</code></pre>
<p>Recall that the 95% confidence interval we calculated by the profile likelihood was <span class="math inline">\((0.402, 0.682)\)</span>. So the quadratic approximation has gotten the width of the interval more or less correct, but it has fared less well at capturing the asymmetry of the interval.</p>
</div>
<div id="comparing-models-likelihood-ratio-test-and-aic" class="section level2 hasAnchor" number="2.4">
<h2><span class="header-section-number">2.4</span> Comparing models: Likelihood ratio test and AIC<a href="beyondML.html#comparing-models-likelihood-ratio-test-and-aic" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Obtaining a parsimonious statistical description of data often requires arbitrating between competing model fits. Likelihood provides two tools for comparing models: likelihood ratio tests (LRTs) and information criteria. Of the latter, the best known information criterion is due to Akaike, and takes the name AIC. (Akaike didn’t name AIC after himself; he used AIC to refer to “An information criterion”. In his honor, the acronym is now largely taken to stand for “Akaike’s information criterion”.)</p>
<p>LRTs and information criteria have complementary strengths and weaknesses. LRTs are direct, head-to-head comparisons of nested models. By “nested”, we mean that one model can be obtained as a special case of the other. The “reduced”, or less flexible (and thus more parsimonious) model plays the role of the null hypothesis, and the “full”, or more flexible (and thus less parsimonious) model plays the role of the alternative hypothesis. The LRT then formally evaluates whether the improvement in fit offered by the full model is statistically significant, that is, greater than what we would expect merely by chance.</p>
<p>On the other hand, information criteria provide a penalized goodness-of-fit measure that can be used to compare many models at once. Information criteria produce a ranking of model fits, and thus a best-fitting model. The downside to information criteria is that there are no hard and fast guidelines to determine when one model provides a significantly better fit than another. The properties of information criteria are also less well understood than the properties of LRTs.</p>
<p>To illustrate both, we will use the study of cone production by fir trees studied in <span class="math inline">\(\S\)</span> 6.6 of Bolker. These data are originally from work by Dodd and Silvertown. The data are much richer than we will examine here. Like Bolker, we will focus on whether the relationship between tree size (as measured by diameter at breast height, or dbh) and the number of cones produces differs between populations that “have experienced wave-like die-offs” and those that have not.</p>
<p>First some preparatory work to import and assemble the data:</p>
<div class="sourceCode" id="cb132"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb132-1"><a href="beyondML.html#cb132-1" tabindex="-1"></a><span class="fu">require</span>(emdbook)</span>
<span id="cb132-2"><a href="beyondML.html#cb132-2" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;FirDBHFec&quot;</span>)</span>
<span id="cb132-3"><a href="beyondML.html#cb132-3" tabindex="-1"></a></span>
<span id="cb132-4"><a href="beyondML.html#cb132-4" tabindex="-1"></a><span class="co"># give the data a simpler name</span></span>
<span id="cb132-5"><a href="beyondML.html#cb132-5" tabindex="-1"></a></span>
<span id="cb132-6"><a href="beyondML.html#cb132-6" tabindex="-1"></a>fir <span class="ot">&lt;-</span> FirDBHFec</span>
<span id="cb132-7"><a href="beyondML.html#cb132-7" tabindex="-1"></a><span class="fu">rm</span>(FirDBHFec)</span>
<span id="cb132-8"><a href="beyondML.html#cb132-8" tabindex="-1"></a></span>
<span id="cb132-9"><a href="beyondML.html#cb132-9" tabindex="-1"></a>fir <span class="ot">&lt;-</span> fir[, <span class="fu">c</span>(<span class="st">&quot;WAVE_NON&quot;</span>, <span class="st">&quot;DBH&quot;</span>, <span class="st">&quot;TOTCONES&quot;</span>)]  <span class="co"># select just the variables we want</span></span>
<span id="cb132-10"><a href="beyondML.html#cb132-10" tabindex="-1"></a></span>
<span id="cb132-11"><a href="beyondML.html#cb132-11" tabindex="-1"></a><span class="fu">summary</span>(fir)</span></code></pre></div>
<pre><code>##  WAVE_NON      DBH            TOTCONES    
##  n:166    Min.   : 3.200   Min.   :  0.0  
##  w:205    1st Qu.: 6.400   1st Qu.: 14.0  
##           Median : 7.600   Median : 36.0  
##           Mean   : 8.169   Mean   : 49.9  
##           3rd Qu.: 9.700   3rd Qu.: 66.0  
##           Max.   :17.400   Max.   :297.0  
##           NA&#39;s   :26       NA&#39;s   :114</code></pre>
<div class="sourceCode" id="cb134"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb134-1"><a href="beyondML.html#cb134-1" tabindex="-1"></a><span class="fu">names</span>(fir) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;wave&quot;</span>, <span class="st">&quot;dbh&quot;</span>, <span class="st">&quot;cones&quot;</span>)  <span class="co"># rename the variables</span></span>
<span id="cb134-2"><a href="beyondML.html#cb134-2" tabindex="-1"></a></span>
<span id="cb134-3"><a href="beyondML.html#cb134-3" tabindex="-1"></a><span class="co"># get rid of the incomplete records</span></span>
<span id="cb134-4"><a href="beyondML.html#cb134-4" tabindex="-1"></a></span>
<span id="cb134-5"><a href="beyondML.html#cb134-5" tabindex="-1"></a>fir <span class="ot">&lt;-</span> <span class="fu">na.omit</span>(fir)</span>
<span id="cb134-6"><a href="beyondML.html#cb134-6" tabindex="-1"></a></span>
<span id="cb134-7"><a href="beyondML.html#cb134-7" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb134-8"><a href="beyondML.html#cb134-8" tabindex="-1"></a></span>
<span id="cb134-9"><a href="beyondML.html#cb134-9" tabindex="-1"></a><span class="fu">plot</span>(cones <span class="sc">~</span> dbh, <span class="at">data =</span> fir, <span class="at">type =</span> <span class="st">&quot;n&quot;</span>, <span class="at">main =</span> <span class="st">&quot;wave&quot;</span>)</span>
<span id="cb134-10"><a href="beyondML.html#cb134-10" tabindex="-1"></a><span class="fu">points</span>(cones <span class="sc">~</span> dbh, <span class="at">data =</span> <span class="fu">subset</span>(fir, wave <span class="sc">==</span> <span class="st">&quot;w&quot;</span>))</span>
<span id="cb134-11"><a href="beyondML.html#cb134-11" tabindex="-1"></a></span>
<span id="cb134-12"><a href="beyondML.html#cb134-12" tabindex="-1"></a><span class="fu">plot</span>(cones <span class="sc">~</span> dbh, <span class="at">data =</span> fir, <span class="at">type =</span> <span class="st">&quot;n&quot;</span>, <span class="at">main =</span> <span class="st">&quot;non-wave&quot;</span>)</span>
<span id="cb134-13"><a href="beyondML.html#cb134-13" tabindex="-1"></a><span class="fu">points</span>(cones <span class="sc">~</span> dbh, <span class="at">data =</span> <span class="fu">subset</span>(fir, wave <span class="sc">==</span> <span class="st">&quot;n&quot;</span>))</span></code></pre></div>
<p><img src="02-LikelihoodConfideceRegions_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<div class="sourceCode" id="cb135"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb135-1"><a href="beyondML.html#cb135-1" tabindex="-1"></a><span class="co"># any non-integral responses?</span></span>
<span id="cb135-2"><a href="beyondML.html#cb135-2" tabindex="-1"></a></span>
<span id="cb135-3"><a href="beyondML.html#cb135-3" tabindex="-1"></a><span class="fu">with</span>(fir, <span class="fu">table</span>(cones <span class="sc">==</span> <span class="fu">round</span>(cones)))  <span class="co"># illustrate the use of &#39;with&#39;</span></span></code></pre></div>
<pre><code>## 
## FALSE  TRUE 
##     6   236</code></pre>
<div class="sourceCode" id="cb137"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb137-1"><a href="beyondML.html#cb137-1" tabindex="-1"></a><span class="co"># round the non-integral values</span></span>
<span id="cb137-2"><a href="beyondML.html#cb137-2" tabindex="-1"></a>fir<span class="sc">$</span>cones <span class="ot">&lt;-</span> <span class="fu">round</span>(fir<span class="sc">$</span>cones)</span>
<span id="cb137-3"><a href="beyondML.html#cb137-3" tabindex="-1"></a></span>
<span id="cb137-4"><a href="beyondML.html#cb137-4" tabindex="-1"></a><span class="co"># check</span></span>
<span id="cb137-5"><a href="beyondML.html#cb137-5" tabindex="-1"></a><span class="fu">with</span>(fir, <span class="fu">table</span>(cones <span class="sc">==</span> <span class="fu">round</span>(cones)))</span></code></pre></div>
<pre><code>## 
## TRUE 
##  242</code></pre>
<p>Like Bolker, we will assume that the average number of cones produced (<span class="math inline">\(\mu\)</span>) has a power-law relationship with tree dbh (<span class="math inline">\(x\)</span>). We will also assume that the actual number of cones produced (<span class="math inline">\(Y\)</span>) takes a negative binomial distribution with size-dependent mean and overdispersion parameter <span class="math inline">\(k\)</span>. That is, our model is
<span class="math display">\[\begin{align*}
\mu(x) &amp; = a x ^ b \\
Y &amp; \sim \mbox{NB}(\mu(x), k)
\end{align*}\]</span></p>
<p>To head in a slightly different direction from Bolker, we will compare two models. In the first, or reduced, model the same parameters will prevail for both wave and non-wave populations. Thus this model has three parameters: <span class="math inline">\(a\)</span>, <span class="math inline">\(b\)</span>, and <span class="math inline">\(k\)</span>. In the second, or full, model, we will allow the <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> parameters to differ between the wave and non-wave populations. (We will continue to assume a common <span class="math inline">\(k\)</span> for both population types.) Using subscripts on <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> to distinguish population types, the full model then has 5 parameters: <span class="math inline">\(a_w\)</span>, <span class="math inline">\(a_n\)</span>, <span class="math inline">\(b_w\)</span>, <span class="math inline">\(b_n\)</span>, and <span class="math inline">\(k\)</span>. We’ll fit the reduced model first. To do so, we’ll use the <code>dnbinom</code> function in R, in which the <span class="math inline">\(k\)</span> parameter is located in the formal argument “size”.</p>
<div class="sourceCode" id="cb139"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb139-1"><a href="beyondML.html#cb139-1" tabindex="-1"></a>fir.neg.ll <span class="ot">&lt;-</span> <span class="cf">function</span>(parms, x, y){</span>
<span id="cb139-2"><a href="beyondML.html#cb139-2" tabindex="-1"></a> </span>
<span id="cb139-3"><a href="beyondML.html#cb139-3" tabindex="-1"></a>  a <span class="ot">&lt;-</span> parms[<span class="dv">1</span>]</span>
<span id="cb139-4"><a href="beyondML.html#cb139-4" tabindex="-1"></a>  b <span class="ot">&lt;-</span> parms[<span class="dv">2</span>]</span>
<span id="cb139-5"><a href="beyondML.html#cb139-5" tabindex="-1"></a>  k <span class="ot">&lt;-</span> parms[<span class="dv">3</span>]</span>
<span id="cb139-6"><a href="beyondML.html#cb139-6" tabindex="-1"></a>   </span>
<span id="cb139-7"><a href="beyondML.html#cb139-7" tabindex="-1"></a>  my.mu <span class="ot">&lt;-</span> a <span class="sc">*</span> x<span class="sc">^</span>b</span>
<span id="cb139-8"><a href="beyondML.html#cb139-8" tabindex="-1"></a>  ll.values <span class="ot">&lt;-</span> <span class="fu">dnbinom</span>(y, <span class="at">size =</span> k, <span class="at">mu =</span> my.mu, <span class="at">log =</span> <span class="cn">TRUE</span>)</span>
<span id="cb139-9"><a href="beyondML.html#cb139-9" tabindex="-1"></a>  </span>
<span id="cb139-10"><a href="beyondML.html#cb139-10" tabindex="-1"></a>  neg.ll <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">1</span> <span class="sc">*</span> <span class="fu">sum</span>(ll.values)</span>
<span id="cb139-11"><a href="beyondML.html#cb139-11" tabindex="-1"></a>  <span class="fu">return</span>(neg.ll)</span>
<span id="cb139-12"><a href="beyondML.html#cb139-12" tabindex="-1"></a>}</span></code></pre></div>
<p>Note a subtle difference here. In preparation for fitting this same model to different subsets of the data, the function <code>fir.neg.ll</code> has formal arguments that receive the values of the <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> variables. In the call to <code>optim</code>, we can supply those additional values as subsequent arguments in the <code>optim</code> function, as illustrated below.</p>
<div class="sourceCode" id="cb140"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb140-1"><a href="beyondML.html#cb140-1" tabindex="-1"></a><span class="co"># fit reduced model</span></span>
<span id="cb140-2"><a href="beyondML.html#cb140-2" tabindex="-1"></a></span>
<span id="cb140-3"><a href="beyondML.html#cb140-3" tabindex="-1"></a>(fir.reduced <span class="ot">&lt;-</span> <span class="fu">optim</span>(<span class="at">f   =</span> fir.neg.ll,</span>
<span id="cb140-4"><a href="beyondML.html#cb140-4" tabindex="-1"></a>                      <span class="at">par =</span> <span class="fu">c</span>(<span class="at">a =</span> <span class="dv">1</span>, <span class="at">b =</span> <span class="dv">1</span>, <span class="at">k =</span> <span class="dv">1</span>),</span>
<span id="cb140-5"><a href="beyondML.html#cb140-5" tabindex="-1"></a>                      <span class="at">x   =</span> fir<span class="sc">$</span>dbh,</span>
<span id="cb140-6"><a href="beyondML.html#cb140-6" tabindex="-1"></a>                      <span class="at">y   =</span> fir<span class="sc">$</span>cones))</span></code></pre></div>
<pre><code>## $par
##         a         b         k 
## 0.3041425 2.3190142 1.5033525 
## 
## $value
## [1] 1136.015
## 
## $counts
## function gradient 
##      134       NA 
## 
## $convergence
## [1] 0
## 
## $message
## NULL</code></pre>
<div class="sourceCode" id="cb142"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb142-1"><a href="beyondML.html#cb142-1" tabindex="-1"></a>a.mle <span class="ot">&lt;-</span> fir.reduced<span class="sc">$</span>par[<span class="dv">1</span>]</span>
<span id="cb142-2"><a href="beyondML.html#cb142-2" tabindex="-1"></a>b.mle <span class="ot">&lt;-</span> fir.reduced<span class="sc">$</span>par[<span class="dv">2</span>]</span>
<span id="cb142-3"><a href="beyondML.html#cb142-3" tabindex="-1"></a>k.mle <span class="ot">&lt;-</span> fir.reduced<span class="sc">$</span>par[<span class="dv">3</span>]</span></code></pre></div>
<p>Make a plot of the reduced model fit, with both populations pooled together:</p>
<div class="sourceCode" id="cb143"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb143-1"><a href="beyondML.html#cb143-1" tabindex="-1"></a>dbh.vals <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="fu">min</span>(fir<span class="sc">$</span>dbh), <span class="at">to =</span> <span class="fu">max</span>(fir<span class="sc">$</span>dbh), <span class="at">length =</span> <span class="dv">100</span>)</span>
<span id="cb143-2"><a href="beyondML.html#cb143-2" tabindex="-1"></a>fit.vals <span class="ot">&lt;-</span> <span class="fu">double</span>(<span class="at">length =</span> <span class="fu">length</span>(dbh.vals))</span>
<span id="cb143-3"><a href="beyondML.html#cb143-3" tabindex="-1"></a></span>
<span id="cb143-4"><a href="beyondML.html#cb143-4" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="fu">seq</span>(<span class="at">along =</span> dbh.vals)) {</span>
<span id="cb143-5"><a href="beyondML.html#cb143-5" tabindex="-1"></a> </span>
<span id="cb143-6"><a href="beyondML.html#cb143-6" tabindex="-1"></a>  fit.vals[i] <span class="ot">&lt;-</span> a.mle <span class="sc">*</span> dbh.vals[i] <span class="sc">^</span> b.mle  </span>
<span id="cb143-7"><a href="beyondML.html#cb143-7" tabindex="-1"></a>}</span>
<span id="cb143-8"><a href="beyondML.html#cb143-8" tabindex="-1"></a></span>
<span id="cb143-9"><a href="beyondML.html#cb143-9" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>))  <span class="co"># don&#39;t break the next figure into two panels</span></span>
<span id="cb143-10"><a href="beyondML.html#cb143-10" tabindex="-1"></a><span class="fu">with</span>(fir, <span class="fu">plot</span>(cones <span class="sc">~</span> dbh))  <span class="co"># plot the data points</span></span>
<span id="cb143-11"><a href="beyondML.html#cb143-11" tabindex="-1"></a><span class="fu">lines</span>(fit.vals <span class="sc">~</span> dbh.vals, <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>)  </span></code></pre></div>
<p><img src="02-LikelihoodConfideceRegions_files/figure-html/unnamed-chunk-30-1.png" width="672" /></p>
<p>Now fit the full model with separate values of <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> for each population:</p>
<div class="sourceCode" id="cb144"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb144-1"><a href="beyondML.html#cb144-1" tabindex="-1"></a>fir.neg.ll.full <span class="ot">&lt;-</span> <span class="cf">function</span>(parms) {</span>
<span id="cb144-2"><a href="beyondML.html#cb144-2" tabindex="-1"></a>  </span>
<span id="cb144-3"><a href="beyondML.html#cb144-3" tabindex="-1"></a>  a.w <span class="ot">&lt;-</span> parms[<span class="dv">1</span>]</span>
<span id="cb144-4"><a href="beyondML.html#cb144-4" tabindex="-1"></a>  b.w <span class="ot">&lt;-</span> parms[<span class="dv">2</span>]</span>
<span id="cb144-5"><a href="beyondML.html#cb144-5" tabindex="-1"></a>  </span>
<span id="cb144-6"><a href="beyondML.html#cb144-6" tabindex="-1"></a>  a.n <span class="ot">&lt;-</span> parms[<span class="dv">3</span>]</span>
<span id="cb144-7"><a href="beyondML.html#cb144-7" tabindex="-1"></a>  b.n <span class="ot">&lt;-</span> parms[<span class="dv">4</span>]</span>
<span id="cb144-8"><a href="beyondML.html#cb144-8" tabindex="-1"></a>  </span>
<span id="cb144-9"><a href="beyondML.html#cb144-9" tabindex="-1"></a>  k   <span class="ot">&lt;-</span> parms[<span class="dv">5</span>]</span>
<span id="cb144-10"><a href="beyondML.html#cb144-10" tabindex="-1"></a>  </span>
<span id="cb144-11"><a href="beyondML.html#cb144-11" tabindex="-1"></a>  wave    <span class="ot">&lt;-</span> <span class="fu">subset</span>(fir, wave <span class="sc">==</span> <span class="st">&quot;w&quot;</span>)</span>
<span id="cb144-12"><a href="beyondML.html#cb144-12" tabindex="-1"></a>  nonwave <span class="ot">&lt;-</span> <span class="fu">subset</span>(fir, wave <span class="sc">==</span> <span class="st">&quot;n&quot;</span>) </span>
<span id="cb144-13"><a href="beyondML.html#cb144-13" tabindex="-1"></a>  </span>
<span id="cb144-14"><a href="beyondML.html#cb144-14" tabindex="-1"></a>  <span class="co"># note how we call fir.neg.ll here, but each time only</span></span>
<span id="cb144-15"><a href="beyondML.html#cb144-15" tabindex="-1"></a>  <span class="co"># passing a subset of the data</span></span>
<span id="cb144-16"><a href="beyondML.html#cb144-16" tabindex="-1"></a>  </span>
<span id="cb144-17"><a href="beyondML.html#cb144-17" tabindex="-1"></a>  neg.ll.wave     <span class="ot">&lt;-</span> <span class="fu">fir.neg.ll</span>(<span class="at">parms =</span> <span class="fu">c</span>(<span class="at">a =</span> a.w, <span class="at">b =</span> b.w, <span class="at">k =</span> k),</span>
<span id="cb144-18"><a href="beyondML.html#cb144-18" tabindex="-1"></a>                                <span class="at">x     =</span> wave<span class="sc">$</span>dbh,</span>
<span id="cb144-19"><a href="beyondML.html#cb144-19" tabindex="-1"></a>                                <span class="at">y     =</span> wave<span class="sc">$</span>cones)</span>
<span id="cb144-20"><a href="beyondML.html#cb144-20" tabindex="-1"></a>  </span>
<span id="cb144-21"><a href="beyondML.html#cb144-21" tabindex="-1"></a>  neg.ll.nonwave  <span class="ot">&lt;-</span> <span class="fu">fir.neg.ll</span>(<span class="at">parms =</span> <span class="fu">c</span>(<span class="at">a =</span> a.n, <span class="at">b =</span> b.n, <span class="at">k =</span> k),</span>
<span id="cb144-22"><a href="beyondML.html#cb144-22" tabindex="-1"></a>                                <span class="at">x     =</span> nonwave<span class="sc">$</span>dbh,</span>
<span id="cb144-23"><a href="beyondML.html#cb144-23" tabindex="-1"></a>                                <span class="at">y     =</span> nonwave<span class="sc">$</span>cones)</span>
<span id="cb144-24"><a href="beyondML.html#cb144-24" tabindex="-1"></a>  </span>
<span id="cb144-25"><a href="beyondML.html#cb144-25" tabindex="-1"></a>  total.ll <span class="ot">&lt;-</span> neg.ll.wave <span class="sc">+</span> neg.ll.nonwave</span>
<span id="cb144-26"><a href="beyondML.html#cb144-26" tabindex="-1"></a>  </span>
<span id="cb144-27"><a href="beyondML.html#cb144-27" tabindex="-1"></a>  <span class="fu">return</span>(total.ll)</span>
<span id="cb144-28"><a href="beyondML.html#cb144-28" tabindex="-1"></a>}</span>
<span id="cb144-29"><a href="beyondML.html#cb144-29" tabindex="-1"></a></span>
<span id="cb144-30"><a href="beyondML.html#cb144-30" tabindex="-1"></a>(fir.full <span class="ot">&lt;-</span> <span class="fu">optim</span>(<span class="at">f      =</span> fir.neg.ll.full,</span>
<span id="cb144-31"><a href="beyondML.html#cb144-31" tabindex="-1"></a>                  <span class="at">par    =</span> <span class="fu">c</span>(<span class="at">a.w =</span> <span class="dv">1</span>, <span class="at">b.w =</span> <span class="dv">1</span>, <span class="at">a.n =</span> <span class="dv">1</span>, <span class="at">b.n =</span> <span class="dv">1</span>, <span class="at">k =</span> <span class="dv">1</span>)))</span></code></pre></div>
<pre><code>## $par
##       a.w       b.w       a.n       b.n         k 
## 0.4136414 2.1417941 0.2874122 2.3550753 1.5083974 
## 
## $value
## [1] 1135.677
## 
## $counts
## function gradient 
##      502       NA 
## 
## $convergence
## [1] 1
## 
## $message
## NULL</code></pre>
<p>Let’s make a plot to show the different fits.</p>
<div class="sourceCode" id="cb146"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb146-1"><a href="beyondML.html#cb146-1" tabindex="-1"></a>a.w.mle <span class="ot">&lt;-</span> fir.full<span class="sc">$</span>par[<span class="dv">1</span>]</span>
<span id="cb146-2"><a href="beyondML.html#cb146-2" tabindex="-1"></a>b.w.mle <span class="ot">&lt;-</span> fir.full<span class="sc">$</span>par[<span class="dv">2</span>]</span>
<span id="cb146-3"><a href="beyondML.html#cb146-3" tabindex="-1"></a>a.n.mle <span class="ot">&lt;-</span> fir.full<span class="sc">$</span>par[<span class="dv">3</span>]</span>
<span id="cb146-4"><a href="beyondML.html#cb146-4" tabindex="-1"></a>b.n.mle <span class="ot">&lt;-</span> fir.full<span class="sc">$</span>par[<span class="dv">4</span>]</span>
<span id="cb146-5"><a href="beyondML.html#cb146-5" tabindex="-1"></a></span>
<span id="cb146-6"><a href="beyondML.html#cb146-6" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb146-7"><a href="beyondML.html#cb146-7" tabindex="-1"></a></span>
<span id="cb146-8"><a href="beyondML.html#cb146-8" tabindex="-1"></a><span class="co"># wave populations</span></span>
<span id="cb146-9"><a href="beyondML.html#cb146-9" tabindex="-1"></a></span>
<span id="cb146-10"><a href="beyondML.html#cb146-10" tabindex="-1"></a>fit.vals.wave <span class="ot">&lt;-</span> fit.vals.non <span class="ot">&lt;-</span> <span class="fu">double</span>(<span class="at">length =</span> <span class="fu">length</span>(dbh.vals))</span>
<span id="cb146-11"><a href="beyondML.html#cb146-11" tabindex="-1"></a></span>
<span id="cb146-12"><a href="beyondML.html#cb146-12" tabindex="-1"></a><span class="fu">plot</span>(cones <span class="sc">~</span> dbh, <span class="at">data =</span> fir, <span class="at">type =</span> <span class="st">&quot;n&quot;</span>, <span class="at">main =</span> <span class="st">&quot;wave&quot;</span>)</span>
<span id="cb146-13"><a href="beyondML.html#cb146-13" tabindex="-1"></a><span class="fu">points</span>(cones <span class="sc">~</span> dbh, <span class="at">data =</span> <span class="fu">subset</span>(fir, wave <span class="sc">==</span> <span class="st">&quot;w&quot;</span>))</span>
<span id="cb146-14"><a href="beyondML.html#cb146-14" tabindex="-1"></a></span>
<span id="cb146-15"><a href="beyondML.html#cb146-15" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="fu">seq</span>(<span class="at">along =</span> dbh.vals)) {</span>
<span id="cb146-16"><a href="beyondML.html#cb146-16" tabindex="-1"></a> </span>
<span id="cb146-17"><a href="beyondML.html#cb146-17" tabindex="-1"></a>  fit.vals.wave[i] <span class="ot">&lt;-</span> a.w.mle <span class="sc">*</span> dbh.vals[i] <span class="sc">^</span> b.w.mle  </span>
<span id="cb146-18"><a href="beyondML.html#cb146-18" tabindex="-1"></a>}</span>
<span id="cb146-19"><a href="beyondML.html#cb146-19" tabindex="-1"></a></span>
<span id="cb146-20"><a href="beyondML.html#cb146-20" tabindex="-1"></a><span class="fu">lines</span>(fit.vals.wave <span class="sc">~</span> dbh.vals, <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>)  </span>
<span id="cb146-21"><a href="beyondML.html#cb146-21" tabindex="-1"></a></span>
<span id="cb146-22"><a href="beyondML.html#cb146-22" tabindex="-1"></a><span class="co"># non-wave populations</span></span>
<span id="cb146-23"><a href="beyondML.html#cb146-23" tabindex="-1"></a></span>
<span id="cb146-24"><a href="beyondML.html#cb146-24" tabindex="-1"></a><span class="fu">plot</span>(cones <span class="sc">~</span> dbh, <span class="at">data =</span> fir, <span class="at">type =</span> <span class="st">&quot;n&quot;</span>, <span class="at">main =</span> <span class="st">&quot;non-wave&quot;</span>)</span>
<span id="cb146-25"><a href="beyondML.html#cb146-25" tabindex="-1"></a><span class="fu">points</span>(cones <span class="sc">~</span> dbh, <span class="at">data =</span> <span class="fu">subset</span>(fir, wave <span class="sc">==</span> <span class="st">&quot;n&quot;</span>))</span>
<span id="cb146-26"><a href="beyondML.html#cb146-26" tabindex="-1"></a></span>
<span id="cb146-27"><a href="beyondML.html#cb146-27" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="fu">seq</span>(<span class="at">along =</span> dbh.vals)) {</span>
<span id="cb146-28"><a href="beyondML.html#cb146-28" tabindex="-1"></a> </span>
<span id="cb146-29"><a href="beyondML.html#cb146-29" tabindex="-1"></a>  fit.vals.non[i] <span class="ot">&lt;-</span> a.n.mle <span class="sc">*</span> dbh.vals[i] <span class="sc">^</span> b.n.mle  </span>
<span id="cb146-30"><a href="beyondML.html#cb146-30" tabindex="-1"></a>}</span>
<span id="cb146-31"><a href="beyondML.html#cb146-31" tabindex="-1"></a></span>
<span id="cb146-32"><a href="beyondML.html#cb146-32" tabindex="-1"></a><span class="fu">lines</span>(fit.vals.non <span class="sc">~</span> dbh.vals, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)  </span></code></pre></div>
<p><img src="02-LikelihoodConfideceRegions_files/figure-html/unnamed-chunk-32-1.png" width="672" /></p>
<p>Note that to compute the negative log likelihood for the full model, we compute the negative log likelihood for each population separately, and then sum the two negative log likelihoods. We can see the justification for doing so by writing out the log likelihood function explicitly:
<span class="math display">\[\begin{eqnarray*}
\ln L(a_w, a_n, b_w, b_n, k; \mathbf{y}) &amp; = &amp; \ln \prod_{i \in \left\{w, n \right\}} \prod_{j=1}^{n_i} f(y_{ij}; a_w, a_n, b_w, b_n, k) \\
&amp; = &amp; \sum_{i \in \left\{w, n \right\}} \sum_{j=1}^{n_i} \ln  f(y_{ij}; a_w, a_n, b_w, b_n, k) \\
&amp; = &amp; \sum_{j=1}^{n_w} \ln  f(y_{w,j}; a_w, b_w, k) + \sum_{j=1}^{n_n} \ln  f(y_{2, n}; a_n, b_n, k)
\end{eqnarray*}\]</span></p>
<p>Now conduct the likelihood ratio test:</p>
<div class="sourceCode" id="cb147"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb147-1"><a href="beyondML.html#cb147-1" tabindex="-1"></a>(lrt.stat <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">*</span> (fir.reduced<span class="sc">$</span>value <span class="sc">-</span> fir.full<span class="sc">$</span>value))  <span class="co"># compute the likelihood ratio test statistic</span></span></code></pre></div>
<pre><code>## [1] 0.6762567</code></pre>
<div class="sourceCode" id="cb149"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb149-1"><a href="beyondML.html#cb149-1" tabindex="-1"></a>(lrt.pvalue <span class="ot">&lt;-</span> <span class="fu">pchisq</span>(<span class="at">q =</span> lrt.stat, <span class="at">df =</span> <span class="dv">2</span>, <span class="at">lower.tail =</span> <span class="cn">FALSE</span>))  <span class="co"># calculate the p-vlaue</span></span></code></pre></div>
<pre><code>## [1] 0.7131037</code></pre>
<p>The LRT suggests that the full model does not provide a significantly better fit than the reduced model (<span class="math inline">\(\chi^2_2 = 0.676\)</span>, <span class="math inline">\(p=0.71\)</span>). In other words, there is no evidence that the two population types have different relationships between tree size and avearage fecundity.</p>
<p>Now compare AIC values for the two models. Because we have already done the LRT, this AIC comparison is for illustration.</p>
<div class="sourceCode" id="cb151"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb151-1"><a href="beyondML.html#cb151-1" tabindex="-1"></a>(aic.reduced <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">*</span> fir.reduced<span class="sc">$</span>value <span class="sc">+</span> <span class="dv">2</span> <span class="sc">*</span> <span class="dv">3</span>)</span></code></pre></div>
<pre><code>## [1] 2278.03</code></pre>
<div class="sourceCode" id="cb153"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb153-1"><a href="beyondML.html#cb153-1" tabindex="-1"></a>(aic.full    <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">*</span> fir.full<span class="sc">$</span>value    <span class="sc">+</span> <span class="dv">2</span> <span class="sc">*</span> <span class="dv">5</span>)</span></code></pre></div>
<pre><code>## [1] 2281.354</code></pre>
<div class="sourceCode" id="cb155"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb155-1"><a href="beyondML.html#cb155-1" tabindex="-1"></a>(delta.aic   <span class="ot">&lt;-</span> aic.full <span class="sc">-</span> aic.reduced) </span></code></pre></div>
<pre><code>## [1] 3.323743</code></pre>
<p>The reduced model is AIC-best, although the <span class="math inline">\(\Delta AIC\)</span> is only moderately large.</p>
<p>We can also fit a Poisson model to these data. Because we have ruled out the need for different models for the two population type, we fit a Poisson model to the data with the two populations pooled together.</p>
<div class="sourceCode" id="cb157"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb157-1"><a href="beyondML.html#cb157-1" tabindex="-1"></a>fir.neg.ll.pois <span class="ot">&lt;-</span> <span class="cf">function</span>(parms, x, y){</span>
<span id="cb157-2"><a href="beyondML.html#cb157-2" tabindex="-1"></a>  </span>
<span id="cb157-3"><a href="beyondML.html#cb157-3" tabindex="-1"></a>  a <span class="ot">&lt;-</span> parms[<span class="dv">1</span>]</span>
<span id="cb157-4"><a href="beyondML.html#cb157-4" tabindex="-1"></a>  b <span class="ot">&lt;-</span> parms[<span class="dv">2</span>]</span>
<span id="cb157-5"><a href="beyondML.html#cb157-5" tabindex="-1"></a>  </span>
<span id="cb157-6"><a href="beyondML.html#cb157-6" tabindex="-1"></a>  my.mu <span class="ot">&lt;-</span> a <span class="sc">*</span> x<span class="sc">^</span>b</span>
<span id="cb157-7"><a href="beyondML.html#cb157-7" tabindex="-1"></a>  ll.values <span class="ot">&lt;-</span> <span class="fu">dpois</span>(y, <span class="at">lambda =</span> my.mu, <span class="at">log =</span> <span class="cn">TRUE</span>)</span>
<span id="cb157-8"><a href="beyondML.html#cb157-8" tabindex="-1"></a>  </span>
<span id="cb157-9"><a href="beyondML.html#cb157-9" tabindex="-1"></a>  <span class="sc">-</span><span class="dv">1</span> <span class="sc">*</span> <span class="fu">sum</span>(ll.values)</span>
<span id="cb157-10"><a href="beyondML.html#cb157-10" tabindex="-1"></a>}</span>
<span id="cb157-11"><a href="beyondML.html#cb157-11" tabindex="-1"></a></span>
<span id="cb157-12"><a href="beyondML.html#cb157-12" tabindex="-1"></a>(fir.pois <span class="ot">&lt;-</span> <span class="fu">optim</span>(<span class="at">f   =</span> fir.neg.ll.pois,</span>
<span id="cb157-13"><a href="beyondML.html#cb157-13" tabindex="-1"></a>                  <span class="at">par =</span> <span class="fu">c</span>(<span class="at">a =</span> <span class="dv">1</span>, <span class="at">b =</span> <span class="dv">1</span>),</span>
<span id="cb157-14"><a href="beyondML.html#cb157-14" tabindex="-1"></a>                  <span class="at">x   =</span> fir<span class="sc">$</span>dbh,</span>
<span id="cb157-15"><a href="beyondML.html#cb157-15" tabindex="-1"></a>                  <span class="at">y   =</span> fir<span class="sc">$</span>cones))</span></code></pre></div>
<pre><code>## $par
##         a         b 
## 0.2613297 2.3883860 
## 
## $value
## [1] 3161.832
## 
## $counts
## function gradient 
##      115       NA 
## 
## $convergence
## [1] 0
## 
## $message
## NULL</code></pre>
<div class="sourceCode" id="cb159"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb159-1"><a href="beyondML.html#cb159-1" tabindex="-1"></a>a.mle.pois <span class="ot">&lt;-</span> fir.pois<span class="sc">$</span>par[<span class="dv">1</span>]</span>
<span id="cb159-2"><a href="beyondML.html#cb159-2" tabindex="-1"></a>b.mle.pois <span class="ot">&lt;-</span> fir.pois<span class="sc">$</span>par[<span class="dv">2</span>]</span></code></pre></div>
<p>Calculate the AIC for this model:</p>
<div class="sourceCode" id="cb160"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb160-1"><a href="beyondML.html#cb160-1" tabindex="-1"></a><span class="co"># calculate AIC</span></span>
<span id="cb160-2"><a href="beyondML.html#cb160-2" tabindex="-1"></a>(aic.pois <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">*</span> fir.pois<span class="sc">$</span>value <span class="sc">+</span> <span class="dv">2</span> <span class="sc">*</span> <span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 6327.664</code></pre>
<p>Whoa! The AIC suggests the negative binomial model is an overwhelmingly better fit.</p>
<p>Finally, make a plot to compare the two fits:</p>
<div class="sourceCode" id="cb162"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb162-1"><a href="beyondML.html#cb162-1" tabindex="-1"></a><span class="fu">with</span>(fir, <span class="fu">plot</span>(cones <span class="sc">~</span> dbh))</span>
<span id="cb162-2"><a href="beyondML.html#cb162-2" tabindex="-1"></a></span>
<span id="cb162-3"><a href="beyondML.html#cb162-3" tabindex="-1"></a><span class="fu">lines</span>(fit.vals <span class="sc">~</span> dbh.vals, <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>)  <span class="co"># plot the fit from the NegBin model</span></span>
<span id="cb162-4"><a href="beyondML.html#cb162-4" tabindex="-1"></a></span>
<span id="cb162-5"><a href="beyondML.html#cb162-5" tabindex="-1"></a><span class="do">## calculate and plot the fit for the Poisson model</span></span>
<span id="cb162-6"><a href="beyondML.html#cb162-6" tabindex="-1"></a>fit.vals.pois <span class="ot">&lt;-</span> <span class="fu">double</span>(<span class="at">length =</span> <span class="fu">length</span>(dbh.vals))</span>
<span id="cb162-7"><a href="beyondML.html#cb162-7" tabindex="-1"></a></span>
<span id="cb162-8"><a href="beyondML.html#cb162-8" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="fu">seq</span>(<span class="at">along =</span> dbh.vals)) {</span>
<span id="cb162-9"><a href="beyondML.html#cb162-9" tabindex="-1"></a>  </span>
<span id="cb162-10"><a href="beyondML.html#cb162-10" tabindex="-1"></a>  fit.vals.pois[i] <span class="ot">&lt;-</span> a.mle.pois <span class="sc">*</span> dbh.vals[i] <span class="sc">^</span> b.mle.pois  </span>
<span id="cb162-11"><a href="beyondML.html#cb162-11" tabindex="-1"></a>}</span>
<span id="cb162-12"><a href="beyondML.html#cb162-12" tabindex="-1"></a></span>
<span id="cb162-13"><a href="beyondML.html#cb162-13" tabindex="-1"></a><span class="fu">lines</span>(fit.vals.pois <span class="sc">~</span> dbh.vals, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span>
<span id="cb162-14"><a href="beyondML.html#cb162-14" tabindex="-1"></a><span class="fu">legend</span>(<span class="at">x =</span> <span class="dv">4</span>, <span class="at">y =</span> <span class="dv">280</span>, </span>
<span id="cb162-15"><a href="beyondML.html#cb162-15" tabindex="-1"></a>       <span class="at">leg =</span> <span class="fu">c</span>(<span class="st">&quot;Neg Bin&quot;</span>, <span class="st">&quot;Poisson&quot;</span>),</span>
<span id="cb162-16"><a href="beyondML.html#cb162-16" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&quot;blue&quot;</span>, <span class="st">&quot;red&quot;</span>),</span>
<span id="cb162-17"><a href="beyondML.html#cb162-17" tabindex="-1"></a>       <span class="at">pch =</span> <span class="dv">16</span>,</span>
<span id="cb162-18"><a href="beyondML.html#cb162-18" tabindex="-1"></a>       <span class="at">bty =</span> <span class="st">&quot;n&quot;</span>)</span></code></pre></div>
<p><img src="02-LikelihoodConfideceRegions_files/figure-html/unnamed-chunk-37-1.png" width="672" /></p>
</div>
<div id="the-negative-binomial-distriution-revisited" class="section level2 hasAnchor" number="2.5">
<h2><span class="header-section-number">2.5</span> The negative binomial distriution, revisited<a href="beyondML.html#the-negative-binomial-distriution-revisited" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The negative binomial distribution is a funny distribution that is frequently misunderstood by ecologists. In ecology, the negative binomial distribution is typically parameterized by the distribution’s mean (which we typically write as <span class="math inline">\(\mu\)</span>) and the “overdispersion parameter”, almost always written as <span class="math inline">\(k\)</span>. In this parameterization, if <span class="math inline">\(X\)</span> has a negative binomial distribution with mean <span class="math inline">\(\mu\)</span> and overdispersion parameter <span class="math inline">\(k\)</span>, then the variance of <span class="math inline">\(X\)</span> is
<span class="math display">\[
Var(X) = \mu + \frac{\mu^2}{k}
\]</span>
Thus, for fixed <span class="math inline">\(\mu\)</span>, the variance increases as <span class="math inline">\(k\)</span> decreases. As <span class="math inline">\(k\)</span> gets large, the variance approaches <span class="math inline">\(\mu\)</span>, and the negative binomial distribution approaches a Poisson distribution.</p>
<p>There are a few occasions in ecology where the overdispersion parameter <span class="math inline">\(k\)</span> has a mechanistic interpretation. In all other cases, though, <span class="math inline">\(k\)</span> is merely a phenomenological descriptor that captures the relationship between the mean and variance for one particular value of <span class="math inline">\(\mu\)</span>. The error that most ecologists make is to assume that a single value of <span class="math inline">\(k\)</span> should prevail across several values of <span class="math inline">\(\mu\)</span>. If <span class="math inline">\(k\)</span> is phenomenological, there is no reason that <span class="math inline">\(k\)</span> should remain fixed as <span class="math inline">\(\mu\)</span> changes. The fit to the fir data exemplifies this error, as so far we have assumed that one value of <span class="math inline">\(k\)</span> must prevail across all sizes of trees. By assuming that <span class="math inline">\(k\)</span> is fixed, we impose a relationship on the data where the variance must increase quadratically as the mean increases. This may be a reasonable model for the relationship between the variance and the mean, or it may not be.</p>
<p>Instead of assuming <span class="math inline">\(k\)</span> constant, another equally viable approach might be to assume that <span class="math inline">\(k\)</span> is a linear function of <span class="math inline">\(\mu\)</span>. In other words, We might set <span class="math inline">\(k = \kappa \mu\)</span> for some value of <span class="math inline">\(\kappa\)</span>. In this case, for a given mean <span class="math inline">\(\mu\)</span>, the variance would be <span class="math inline">\(\mu + \frac{\mu^2}{\kappa \mu} = \mu \left(1 + \frac{1}{\kappa}\right)\)</span>, so that the variance would increase linearly as the mean increases. We can try fitting this alternative model to the fir tree data, again pooling wave and non-wave populations together.</p>
<div class="sourceCode" id="cb163"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb163-1"><a href="beyondML.html#cb163-1" tabindex="-1"></a>fir.alt.neg.ll <span class="ot">&lt;-</span> <span class="cf">function</span>(parms, x, y){</span>
<span id="cb163-2"><a href="beyondML.html#cb163-2" tabindex="-1"></a>  </span>
<span id="cb163-3"><a href="beyondML.html#cb163-3" tabindex="-1"></a>  a <span class="ot">&lt;-</span> <span class="fu">exp</span>(parms[<span class="dv">1</span>])</span>
<span id="cb163-4"><a href="beyondML.html#cb163-4" tabindex="-1"></a>  b <span class="ot">&lt;-</span> parms[<span class="dv">2</span>]</span>
<span id="cb163-5"><a href="beyondML.html#cb163-5" tabindex="-1"></a>  k <span class="ot">&lt;-</span> <span class="fu">exp</span>(parms[<span class="dv">3</span>])</span>
<span id="cb163-6"><a href="beyondML.html#cb163-6" tabindex="-1"></a>  </span>
<span id="cb163-7"><a href="beyondML.html#cb163-7" tabindex="-1"></a>  my.mu <span class="ot">&lt;-</span> a <span class="sc">*</span> x<span class="sc">^</span>b</span>
<span id="cb163-8"><a href="beyondML.html#cb163-8" tabindex="-1"></a>  ll.values <span class="ot">&lt;-</span> <span class="fu">dnbinom</span>(y, <span class="at">size =</span> k <span class="sc">*</span> my.mu, <span class="at">mu =</span> my.mu, <span class="at">log =</span> <span class="cn">TRUE</span>)</span>
<span id="cb163-9"><a href="beyondML.html#cb163-9" tabindex="-1"></a>  </span>
<span id="cb163-10"><a href="beyondML.html#cb163-10" tabindex="-1"></a>  <span class="sc">-</span><span class="dv">1</span> <span class="sc">*</span> <span class="fu">sum</span>(ll.values)</span>
<span id="cb163-11"><a href="beyondML.html#cb163-11" tabindex="-1"></a>}</span>
<span id="cb163-12"><a href="beyondML.html#cb163-12" tabindex="-1"></a></span>
<span id="cb163-13"><a href="beyondML.html#cb163-13" tabindex="-1"></a>(fir.alt <span class="ot">&lt;-</span> <span class="fu">optim</span>(<span class="at">f   =</span> fir.alt.neg.ll,</span>
<span id="cb163-14"><a href="beyondML.html#cb163-14" tabindex="-1"></a>                  <span class="at">par =</span> <span class="fu">c</span>(<span class="at">a =</span> <span class="dv">0</span>, <span class="at">b =</span> <span class="dv">1</span>, <span class="at">k =</span> <span class="dv">0</span>),</span>
<span id="cb163-15"><a href="beyondML.html#cb163-15" tabindex="-1"></a>                  <span class="at">x   =</span> fir<span class="sc">$</span>dbh,</span>
<span id="cb163-16"><a href="beyondML.html#cb163-16" tabindex="-1"></a>                  <span class="at">y   =</span> fir<span class="sc">$</span>cones))</span></code></pre></div>
<pre><code>## $par
##         a         b         k 
## -1.008373  2.243545 -3.278311 
## 
## $value
## [1] 1128.403
## 
## $counts
## function gradient 
##      182       NA 
## 
## $convergence
## [1] 0
## 
## $message
## NULL</code></pre>
<div class="sourceCode" id="cb165"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb165-1"><a href="beyondML.html#cb165-1" tabindex="-1"></a>(a.mle.alt <span class="ot">&lt;-</span> <span class="fu">exp</span>(fir.alt<span class="sc">$</span>par[<span class="dv">1</span>]))</span></code></pre></div>
<pre><code>##         a 
## 0.3648121</code></pre>
<div class="sourceCode" id="cb167"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb167-1"><a href="beyondML.html#cb167-1" tabindex="-1"></a>(b.mle.alt <span class="ot">&lt;-</span> fir.alt<span class="sc">$</span>par[<span class="dv">2</span>])</span></code></pre></div>
<pre><code>##        b 
## 2.243545</code></pre>
<div class="sourceCode" id="cb169"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb169-1"><a href="beyondML.html#cb169-1" tabindex="-1"></a>(k.mle.alt <span class="ot">&lt;-</span> <span class="fu">exp</span>(fir.alt<span class="sc">$</span>par[<span class="dv">3</span>]))</span></code></pre></div>
<pre><code>##          k 
## 0.03769186</code></pre>
<p>If we compare the fits graphically, the alternative model doesn’t generate a dramatically different fit for the relationship between the average cone production and tree size:</p>
<div class="sourceCode" id="cb171"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb171-1"><a href="beyondML.html#cb171-1" tabindex="-1"></a>fit.vals.alt <span class="ot">&lt;-</span> <span class="fu">double</span>(<span class="at">length =</span> <span class="fu">length</span>(dbh.vals))</span>
<span id="cb171-2"><a href="beyondML.html#cb171-2" tabindex="-1"></a></span>
<span id="cb171-3"><a href="beyondML.html#cb171-3" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="fu">seq</span>(<span class="at">along =</span> dbh.vals)) {</span>
<span id="cb171-4"><a href="beyondML.html#cb171-4" tabindex="-1"></a>  </span>
<span id="cb171-5"><a href="beyondML.html#cb171-5" tabindex="-1"></a>  fit.vals.alt[i] <span class="ot">&lt;-</span> a.mle.alt <span class="sc">*</span> dbh.vals[i] <span class="sc">^</span> b.mle.alt  </span>
<span id="cb171-6"><a href="beyondML.html#cb171-6" tabindex="-1"></a>}</span>
<span id="cb171-7"><a href="beyondML.html#cb171-7" tabindex="-1"></a></span>
<span id="cb171-8"><a href="beyondML.html#cb171-8" tabindex="-1"></a><span class="fu">with</span>(fir, <span class="fu">plot</span>(cones <span class="sc">~</span> dbh))</span>
<span id="cb171-9"><a href="beyondML.html#cb171-9" tabindex="-1"></a><span class="fu">lines</span>(fit.vals <span class="sc">~</span> dbh.vals, <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>)</span>
<span id="cb171-10"><a href="beyondML.html#cb171-10" tabindex="-1"></a><span class="fu">lines</span>(fit.vals.alt <span class="sc">~</span> dbh.vals, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span>
<span id="cb171-11"><a href="beyondML.html#cb171-11" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topleft&quot;</span>, <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&quot;blue&quot;</span>, <span class="st">&quot;red&quot;</span>), <span class="at">pch =</span> <span class="dv">16</span>, <span class="at">leg =</span> <span class="fu">c</span>(<span class="st">&quot;original&quot;</span>, <span class="st">&quot;alternate&quot;</span>))</span></code></pre></div>
<p><img src="02-LikelihoodConfideceRegions_files/figure-html/unnamed-chunk-39-1.png" width="672" /></p>
<p>However, the two models imply very different relationships between the variance in cone production and tree size. Let’s look at the implied relationship between the standard deviation of cone production and tree size:</p>
<div class="sourceCode" id="cb172"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb172-1"><a href="beyondML.html#cb172-1" tabindex="-1"></a>mu.vals <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="fu">max</span>(fit.vals), <span class="at">length =</span> <span class="dv">100</span>)</span>
<span id="cb172-2"><a href="beyondML.html#cb172-2" tabindex="-1"></a></span>
<span id="cb172-3"><a href="beyondML.html#cb172-3" tabindex="-1"></a>sd.vals.nb1 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(mu.vals <span class="sc">+</span> mu.vals <span class="sc">^</span> <span class="dv">2</span> <span class="sc">/</span> k.mle)</span>
<span id="cb172-4"><a href="beyondML.html#cb172-4" tabindex="-1"></a>sd.vals.nb2 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(mu.vals <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="dv">1</span> <span class="sc">/</span> k.mle.alt))</span>
<span id="cb172-5"><a href="beyondML.html#cb172-5" tabindex="-1"></a></span>
<span id="cb172-6"><a href="beyondML.html#cb172-6" tabindex="-1"></a><span class="fu">plot</span>(mu.vals, sd.vals.nb1, <span class="at">xlab =</span> <span class="st">&quot;mean&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;SD&quot;</span>, <span class="at">type =</span> <span class="st">&quot;l&quot;</span>, <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>)</span>
<span id="cb172-7"><a href="beyondML.html#cb172-7" tabindex="-1"></a><span class="fu">lines</span>(mu.vals, sd.vals.nb2, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span>
<span id="cb172-8"><a href="beyondML.html#cb172-8" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topleft&quot;</span>, <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&quot;blue&quot;</span>, <span class="st">&quot;red&quot;</span>), <span class="at">pch =</span> <span class="dv">16</span>, <span class="at">leg =</span> <span class="fu">c</span>(<span class="st">&quot;original&quot;</span>, <span class="st">&quot;alternate&quot;</span>))</span></code></pre></div>
<p><img src="02-LikelihoodConfideceRegions_files/figure-html/unnamed-chunk-40-1.png" width="672" /></p>
<p>We can calculate the AIC for this alternate parameterization as well:</p>
<div class="sourceCode" id="cb173"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb173-1"><a href="beyondML.html#cb173-1" tabindex="-1"></a>(aic.alt <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">*</span> fir.alt<span class="sc">$</span>value <span class="sc">+</span> <span class="dv">2</span> <span class="sc">*</span> <span class="dv">3</span>)</span></code></pre></div>
<pre><code>## [1] 2262.805</code></pre>
<p>Recall that the AIC value for the original fit was 2278.0. Thus the model with the alternative parameterization is considerably better by AIC.</p>

</div>
</div>
<h3>Bibliography<a href="bibliography.html#bibliography" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-bolker2008" class="csl-entry">
Bolker, Benjamin M. 2008. <em>Ecological Models and Data in <span>R</span></em>. Princeton University Press.
</div>
<div id="ref-kendall1979" class="csl-entry">
Kendall, Maurice George, and Alan Stuart. 1979. <em>The Advanced Theory of Statistics. Vol. 2: Inference and Relationship</em>. 4th ed. London: Griffin.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="4">
<li id="fn4"><p>See section 6.4.1.1 of Bolker to see how this follows from a result about the likelihood ratio.<a href="beyondML.html#fnref4" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="bayesian-computation.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "serif",
    "size": 2
  },
  "edit": {
    "link": null,
    "text": null
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "section"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
