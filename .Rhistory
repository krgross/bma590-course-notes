}
plot(x = a.values, y = a.profile, xlab = "a", ylab = "profile log-likelihood", type = "l")
cut.off <- profile.ll(a.mle) + qchisq(0.95, df = 1) / 2
abline(h = cut.off, col = "blue", lty = "dashed")
(lower <- uniroot(f = function(x) cut.off - profile.ll(x) ,
interval = c(0.3, a.mle)))
(upper <- uniroot(f = function(x) cut.off - profile.ll(x) ,
interval = c(a.mle, 0.8)))
abline(v = c(lower$root, upper$root), col = "blue")
horse <- read.table("../data/horse.txt", header = TRUE)
horse <- read.table("../../general/data/horse.txt", header = TRUE)
horse.neg.ll <- function(my.lambda) {
ll.vals <- dpois(x = horse$deaths, lambda = my.lambda, log = TRUE)
-1 * sum(ll.vals)
}
# create a vector of lambda values using the 'seq'uence command
lambda.vals <- seq(from = 0.5, to = 1.0, by = 0.01)
# create an empty vector to store the values of the log-likelihood
ll.vals <- double(length = length(lambda.vals))
# use a loop to find the log-likelihood for each value in lambda.vals
for (i.lambda in 1:length(lambda.vals)) {
ll.vals[i.lambda] <- horse.neg.ll(lambda.vals[i.lambda])
}
plot(ll.vals ~ lambda.vals, xlab = "lambda", ylab = "negative log likelihood", type = "l")
horse.neg.ll(0.7)
qchisq(0.95, df = 1) / 2
(cutoff.ll <- horse.neg.ll(0.7) + qchisq(0.95, df = 1) / 2)
abline(h = cutoff.ll, col = "red", lty = "dashed")
my.function <- function(my.lambda){
cutoff.ll - horse.neg.ll(my.lambda)
}
(lower <- uniroot(f = my.function, interval = c(0.6, 0.7)))
abline(v = lower$root, col = "red")
(upper <- uniroot(f = my.function, interval = c(0.7, 0.9)))
abline(v = upper$root, col = "red")
numDeriv::hessian(func = horse.neg.ll, x = 0.7)
approx.ll <- function(lambda) horse.neg.ll(0.7) + (1/2) * (lambda - 0.7)^2 * horse.D2(1e-04)
curve(approx.ll, from = min(lambda.vals), to = max(lambda.vals), add = TRUE, col = "blue")
(horse.curv <- numDeriv::hessian(func = horse.neg.ll, x = 0.7))
approx.ll <- function(lambda) horse.neg.ll(0.7) + (1/2) * (lambda - 0.7)^2 * horse.curv
curve(approx.ll, from = min(lambda.vals), to = max(lambda.vals), add = TRUE, col = "blue")
(horse.curv <- as.numeric(numDeriv::hessian(func = horse.neg.ll, x = 0.7)))
(horse.curv <- as.numeric(horse.curv))
approx.ll <- function(lambda) horse.neg.ll(0.7) + (1/2) * (lambda - 0.7)^2 * horse.curv
curve(approx.ll, from = min(lambda.vals), to = max(lambda.vals), add = TRUE, col = "blue")
horse <- read.table("../../general/data/horse.txt", header = TRUE)
horse.neg.ll <- function(my.lambda) {
ll.vals <- dpois(x = horse$deaths, lambda = my.lambda, log = TRUE)
-1 * sum(ll.vals)
}
# create a vector of lambda values using the 'seq'uence command
lambda.vals <- seq(from = 0.5, to = 1.0, by = 0.01)
# create an empty vector to store the values of the log-likelihood
ll.vals <- double(length = length(lambda.vals))
# use a loop to find the log-likelihood for each value in lambda.vals
for (i.lambda in 1:length(lambda.vals)) {
ll.vals[i.lambda] <- horse.neg.ll(lambda.vals[i.lambda])
}
plot(ll.vals ~ lambda.vals, xlab = "lambda", ylab = "negative log likelihood", type = "l")
horse.neg.ll(0.7)
qchisq(0.95, df = 1) / 2
(cutoff.ll <- horse.neg.ll(0.7) + qchisq(0.95, df = 1) / 2)
abline(h = cutoff.ll, col = "red", lty = "dashed")
my.function <- function(my.lambda){
cutoff.ll - horse.neg.ll(my.lambda)
}
(lower <- uniroot(f = my.function, interval = c(0.6, 0.7)))
abline(v = lower$root, col = "red")
(upper <- uniroot(f = my.function, interval = c(0.7, 0.9)))
abline(v = upper$root, col = "red")
(horse.curv <- numDeriv::hessian(func = horse.neg.ll, x = 0.7))
(horse.curv <- as.numeric(horse.curv))
approx.ll <- function(lambda) horse.neg.ll(0.7) + (1/2) * (lambda - 0.7)^2 * horse.curv
curve(approx.ll, from = min(lambda.vals), to = max(lambda.vals), add = TRUE, col = "blue")
(lambda.se <- sqrt(1 / horse.curv))
(lower.approx <- 0.7 - qnorm(.975) * lambda.se)
(upper.approx <- 0.7 + qnorm(.975) * lambda.se)
abline(v = c(lower.approx, upper.approx), col = "blue")
horse.D2 <- function(delta.l) {
(horse.neg.ll(0.7 + delta.l) - 2 * horse.neg.ll(0.7) + horse.neg.ll(0.7 - delta.l)) / delta.l ^ 2
}
horse.D2(1e-04)
horse.D2(1e-05)
# clean up
rm(list = ls())
library(emdbook)
data("ReedfrogFuncresp")
frog <- ReedfrogFuncresp
rm(ReedfrogFuncresp)
frog.neg.ll <- function(params){
a <- params[1]
h <- params[2]
prob.vals <- a / (1 + a * h * frog$Initial)
ll.vals <- dbinom(frog$Killed, size = frog$Initial, prob = prob.vals, log = TRUE)
-1 * sum(ll.vals)
}
frog.mle <- optim(par = c(0.5, 1/80),
fn  = frog.neg.ll)
a.mle <- frog.mle$par[1]
h.mle <- frog.mle$par[2]
a.vals <- seq(from = 0.3, to = 0.75, by = 0.01)
h.vals <- seq(from = 0.001, to = 0.03, by = 0.001)
ll.vals <- matrix(nrow = length(a.vals), ncol = length(h.vals))
for (i.a in 1:length(a.vals)) {
for(i.h in 1:length(h.vals)) {
ll.vals[i.a, i.h] <- frog.neg.ll(c(a.vals[i.a], h.vals[i.h]))
}
}
contour(x = a.vals, y = h.vals, z = ll.vals, nlevels = 100,
xlab = "a", ylab = "h")
points(x = a.mle, y = h.mle, col = "red")
(cutoff.ll <- frog.neg.ll(c(a.mle, h.mle)) +
(1 / 2) * qchisq(.95, df = 2))
contour(x = a.vals, y = h.vals, z = ll.vals,
levels = frog.neg.ll(c(a.mle, h.mle)) + (1 / 2) * qchisq(.95, df = 2),
add = TRUE, col = "red", lwd = 2)
profile.ll <- function(my.a) {
# Calculate the minimum log likelihood value for a given value of a, the attack rate
my.ll <- function(h) frog.neg.ll(c(my.a, h))
my.profile <- optimize(f = my.ll,
interval = c(0, 0.03),
maximum = FALSE)
return(my.profile$objective)
}
a.values <- seq(from = 0.3, to = 0.8, by = 0.01)
a.profile <- double(length = length(a.values))
for (i in 1:length(a.values)) {
a.profile[i] <- profile.ll(a.values[i])
}
plot(x = a.values, y = a.profile, xlab = "a", ylab = "profile log-likelihood", type = "l")
cut.off <- profile.ll(a.mle) + qchisq(0.95, df = 1) / 2
abline(h = cut.off, col = "blue", lty = "dashed")
(lower <- uniroot(f = function(x) cut.off - profile.ll(x) ,
interval = c(0.3, a.mle)))
(upper <- uniroot(f = function(x) cut.off - profile.ll(x) ,
interval = c(a.mle, 0.8)))
abline(v = c(lower$root, upper$root), col = "blue")
(D2 <- numDeriv::hessian(func = frog.neg.ll, x = c(a.mle, h.mle)))
# invert to get var-cov matrix
(var.matrix <- solve(D2))
cov2cor(var.matrix)
(a.se <- sqrt(var.matrix[1, 1]))
(h.se <- sqrt(var.matrix[2, 2]))
(lower.approx <- a.mle - qnorm(.975) * a.se)
(upper.approx <- a.mle + qnorm(.975) * a.se)
abline(v = c(lower.approx, upper.approx), col = "red")
approx.ll <- function(a) profile.ll(a.mle) + (1/2) * (a - a.mle)^2 * var.matrix[1, 1]
curve(approx.ll, from = min(a.values), to = max(a.values), add = TRUE, col = "blue")
approx.ll <- function(a) profile.ll(a.mle) + (1/2) * (a - a.mle)^2 * (1 / var.matrix[1, 1])
curve(approx.ll, from = min(a.values), to = max(a.values), add = TRUE, col = "blue")
library(emdbook)
data("ReedfrogFuncresp")
frog <- ReedfrogFuncresp
rm(ReedfrogFuncresp)
frog.neg.ll <- function(params){
a <- params[1]
h <- params[2]
prob.vals <- a / (1 + a * h * frog$Initial)
ll.vals <- dbinom(frog$Killed, size = frog$Initial, prob = prob.vals, log = TRUE)
-1 * sum(ll.vals)
}
frog.mle <- optim(par = c(0.5, 1/80),
fn  = frog.neg.ll)
a.mle <- frog.mle$par[1]
h.mle <- frog.mle$par[2]
a.vals <- seq(from = 0.3, to = 0.75, by = 0.01)
h.vals <- seq(from = 0.001, to = 0.03, by = 0.001)
ll.vals <- matrix(nrow = length(a.vals), ncol = length(h.vals))
for (i.a in 1:length(a.vals)) {
for(i.h in 1:length(h.vals)) {
ll.vals[i.a, i.h] <- frog.neg.ll(c(a.vals[i.a], h.vals[i.h]))
}
}
contour(x = a.vals, y = h.vals, z = ll.vals, nlevels = 100,
xlab = "a", ylab = "h")
points(x = a.mle, y = h.mle, col = "red")
(cutoff.ll <- frog.neg.ll(c(a.mle, h.mle)) +
(1 / 2) * qchisq(.95, df = 2))
contour(x = a.vals, y = h.vals, z = ll.vals,
levels = frog.neg.ll(c(a.mle, h.mle)) + (1 / 2) * qchisq(.95, df = 2),
add = TRUE, col = "red", lwd = 2)
profile.ll <- function(my.a) {
# Calculate the minimum log likelihood value for a given value of a, the attack rate
my.ll <- function(h) frog.neg.ll(c(my.a, h))
my.profile <- optimize(f = my.ll,
interval = c(0, 0.03),
maximum = FALSE)
return(my.profile$objective)
}
a.values <- seq(from = 0.3, to = 0.8, by = 0.01)
a.profile <- double(length = length(a.values))
for (i in 1:length(a.values)) {
a.profile[i] <- profile.ll(a.values[i])
}
plot(x = a.values, y = a.profile, xlab = "a", ylab = "profile log-likelihood", type = "l")
cut.off <- profile.ll(a.mle) + qchisq(0.95, df = 1) / 2
abline(h = cut.off, col = "red", lty = "dashed")
(lower <- uniroot(f = function(x) cut.off - profile.ll(x) ,
interval = c(0.3, a.mle)))
(upper <- uniroot(f = function(x) cut.off - profile.ll(x) ,
interval = c(a.mle, 0.8)))
abline(v = c(lower$root, upper$root), col = "red")
(D2 <- numDeriv::hessian(func = frog.neg.ll, x = c(a.mle, h.mle)))
# invert to get var-cov matrix
(var.matrix <- solve(D2))
cov2cor(var.matrix)
(a.se <- sqrt(var.matrix[1, 1]))
(h.se <- sqrt(var.matrix[2, 2]))
approx.ll <- function(a) profile.ll(a.mle) + (1/2) * (a - a.mle)^2 * (1 / var.matrix[1, 1])
curve(approx.ll, from = min(a.values), to = max(a.values), add = TRUE, col = "blue")
(lower.approx <- a.mle - qnorm(.975) * a.se)
(upper.approx <- a.mle + qnorm(.975) * a.se)
abline(v = c(lower.approx, upper.approx), col = "blue")
library(emdbook)
data("ReedfrogFuncresp")
frog <- ReedfrogFuncresp
rm(ReedfrogFuncresp)
frog.neg.ll <- function(params){
a <- params[1]
h <- params[2]
prob.vals <- a / (1 + a * h * frog$Initial)
ll.vals <- dbinom(frog$Killed, size = frog$Initial, prob = prob.vals, log = TRUE)
-1 * sum(ll.vals)
}
frog.mle <- optim(par = c(0.5, 1/80),
fn  = frog.neg.ll)
a.mle <- frog.mle$par[1]
h.mle <- frog.mle$par[2]
a.vals <- seq(from = 0.3, to = 0.75, by = 0.01)
h.vals <- seq(from = 0.001, to = 0.03, by = 0.001)
ll.vals <- matrix(nrow = length(a.vals), ncol = length(h.vals))
for (i.a in 1:length(a.vals)) {
for(i.h in 1:length(h.vals)) {
ll.vals[i.a, i.h] <- frog.neg.ll(c(a.vals[i.a], h.vals[i.h]))
}
}
contour(x = a.vals, y = h.vals, z = ll.vals, nlevels = 100,
xlab = "a", ylab = "h")
points(x = a.mle, y = h.mle, col = "red", pch = 16)
frog.neg.ll(c(a.mle, h.mle))
(cutoff.ll <- frog.neg.ll(c(a.mle, h.mle)) +
(1 / 2) * qchisq(.95, df = 2))
contour(x = a.vals, y = h.vals, z = ll.vals,
levels = cutoff.ll,
add = TRUE, col = "red", lwd = 2)
horse <- read.table("../../general/data/horse.txt", header = TRUE)
horse.neg.ll <- function(my.lambda) {
ll.vals <- dpois(x = horse$deaths, lambda = my.lambda, log = TRUE)
-1 * sum(ll.vals)
}
# create a vector of lambda values using the 'seq'uence command
lambda.vals <- seq(from = 0.5, to = 1.0, by = 0.01)
# create an empty vector to store the values of the log-likelihood
ll.vals <- double(length = length(lambda.vals))
# use a loop to find the log-likelihood for each value in lambda.vals
for (i.lambda in 1:length(lambda.vals)) {
ll.vals[i.lambda] <- horse.neg.ll(lambda.vals[i.lambda])
}
plot(ll.vals ~ lambda.vals, xlab = "lambda", ylab = "negative log likelihood", type = "l")
horse.neg.ll(0.7)
qchisq(0.95, df = 1) / 2
(cutoff.ll <- horse.neg.ll(0.7) + qchisq(0.95, df = 1) / 2)
abline(h = cutoff.ll, col = "red", lty = "dashed")
my.function <- function(my.lambda){
cutoff.ll - horse.neg.ll(my.lambda)
}
(lower <- uniroot(f = my.function, interval = c(0.6, 0.7)))
abline(v = lower$root, col = "red")
(upper <- uniroot(f = my.function, interval = c(0.7, 0.9)))
abline(v = upper$root, col = "red")
(horse.curv <- numDeriv::hessian(func = horse.neg.ll, x = 0.7))
(horse.curv <- as.numeric(horse.curv))
approx.ll <- function(lambda) horse.neg.ll(0.7) + (1/2) * (lambda - 0.7)^2 * horse.curv
curve(approx.ll, from = min(lambda.vals), to = max(lambda.vals), add = TRUE, col = "blue")
(lambda.se <- sqrt(1 / horse.curv))
(horse.curv <- numDeriv::hessian(func = horse.neg.ll, x = 0.7))
(horse.curv <- as.numeric(horse.curv))
approx.ll <- function(lambda) horse.neg.ll(0.7) + (1/2) * (lambda - 0.7)^2 * horse.curv
curve(approx.ll, from = min(lambda.vals), to = max(lambda.vals), add = TRUE, col = "blue")
library(emdbook)
data("ReedfrogFuncresp")
frog <- ReedfrogFuncresp
rm(ReedfrogFuncresp)
frog.neg.ll <- function(params){
a <- params[1]
h <- params[2]
prob.vals <- a / (1 + a * h * frog$Initial)
ll.vals <- dbinom(frog$Killed, size = frog$Initial, prob = prob.vals, log = TRUE)
-1 * sum(ll.vals)
}
frog.mle <- optim(par = c(0.5, 1/80),
fn  = frog.neg.ll)
a.mle <- frog.mle$par[1]
h.mle <- frog.mle$par[2]
a.vals <- seq(from = 0.3, to = 0.75, by = 0.01)
h.vals <- seq(from = 0.001, to = 0.03, by = 0.001)
ll.vals <- matrix(nrow = length(a.vals), ncol = length(h.vals))
for (i.a in 1:length(a.vals)) {
for(i.h in 1:length(h.vals)) {
ll.vals[i.a, i.h] <- frog.neg.ll(c(a.vals[i.a], h.vals[i.h]))
}
}
contour(x = a.vals, y = h.vals, z = ll.vals, nlevels = 100,
xlab = "a", ylab = "h")
points(x = a.mle, y = h.mle, col = "red")
(cutoff.ll <- frog.neg.ll(c(a.mle, h.mle)) +
(1 / 2) * qchisq(.95, df = 2))
contour(x = a.vals, y = h.vals, z = ll.vals,
levels = frog.neg.ll(c(a.mle, h.mle)) + (1 / 2) * qchisq(.95, df = 2),
add = TRUE, col = "red", lwd = 2)
profile.ll <- function(my.a) {
# Calculate the minimum log likelihood value for a given value of a, the attack rate
my.ll <- function(h) frog.neg.ll(c(my.a, h))
my.profile <- optimize(f = my.ll,
interval = c(0, 0.03),
maximum = FALSE)
return(my.profile$objective)
}
a.values <- seq(from = 0.3, to = 0.8, by = 0.01)
a.profile <- double(length = length(a.values))
for (i in 1:length(a.values)) {
a.profile[i] <- profile.ll(a.values[i])
}
plot(x = a.values, y = a.profile, xlab = "a", ylab = "profile log-likelihood", type = "l")
cut.off <- profile.ll(a.mle) + qchisq(0.95, df = 1) / 2
abline(h = cut.off, col = "red", lty = "dashed")
(lower <- uniroot(f = function(x) cut.off - profile.ll(x) ,
interval = c(0.3, a.mle)))
(upper <- uniroot(f = function(x) cut.off - profile.ll(x) ,
interval = c(a.mle, 0.8)))
abline(v = c(lower$root, upper$root), col = "red")
(D2 <- numDeriv::hessian(func = frog.neg.ll, x = c(a.mle, h.mle)))
# invert to get var-cov matrix
(var.matrix <- solve(D2))
(a.se <- sqrt(var.matrix[1, 1]))
(h.se <- sqrt(var.matrix[2, 2]))
cov2cor(var.matrix)
require(emdbook)
data("FirDBHFec")
fir <- FirDBHFec
rm(FirDBHFec)
names(fir)
fir <- fir[, c("WAVE_NON", "DBH", "TOTCONES")]
names(fir) <- c("wave", "dbh", "cones")
summary(fir)
head(fir)
fir <- na.omit(fir)
summary(fir)
with(fir, table(cones == round(cones)))
# round the non-integral values
fir$cones <- round(fir$cones)
# check
with(fir, table(cones == round(cones)))
par(mfrow = c(1, 2))
plot(cones ~ dbh, data = fir, type = "n", main = "wave")
points(cones ~ dbh, data = subset(fir, wave == "w"))
plot(cones ~ dbh, data = fir, type = "n", main = "non-wave")
points(cones ~ dbh, data = subset(fir, wave == "n"))
?dnbinom
fir.neg.ll <- function(parms, x, y){
a <- parms[1]
b <- parms[2]
k <- parms[3]
my.mu <- a * x^b
ll.values <- dnbinom(y, size = k, mu = my.mu, log = TRUE)
-1 * sum(ll.values)
}
(fir.reduced <- optim(f   = fir.neg.ll,
par = c(a = 1, b = 1, k = 1),
x   = fir$dbh,
y   = fir$cones))
a.mle <- fir.reduced$par[1]
b.mle <- fir.reduced$par[2]
k.mle <- fir.reduced$par[3]
par(mfrow = c(1, 1))  # don't break the next figure into two panels
with(fir, plot(cones ~ dbh))
dbh.vals <- seq(from = min(fir$dbh), to = max(fir$dbh), length = 100)
fit.vals <- double(length = length(dbh.vals))
for (i in seq(along = dbh.vals)) fit.vals[i] <- a.mle * dbh.vals[i] ^ b.mle
lines(fit.vals ~ dbh.vals, col = "blue")
fir.neg.ll.full <- function(parms, mydata) {
a.w <- parms[1]
b.w <- parms[2]
a.n <- parms[3]
b.n <- parms[4]
k   <- parms[5]
wave    <- subset(mydata, wave == "w")
nonwave <- subset(mydata, wave == "n")
neg.ll.wave     <- fir.neg.ll(parms = c(a = a.w, b = b.w, k = k),
x     = wave$dbh,
y     = wave$cones)
neg.ll.nonwave  <- fir.neg.ll(parms = c(a = a.n, b = b.n, k = k),
x     = nonwave$dbh,
y     = nonwave$cones)
neg.ll.wave + neg.ll.nonwave
}
(fir.full <- optim(f      = fir.neg.ll.full,
par    = c(a.w = 1, b.w = 1, a.n = 1, b.n = 1, k = 1),
mydata = fir))
a.w.mle <- fir.full$par[1]
b.w.mle <- fir.full$par[2]
a.n.mle <- fir.full$par[3]
b.n.mle <- fir.full$par[4]
par(mfrow = c(1, 2))
fit.vals.wave <- fit.vals.non <- double(length = length(dbh.vals))
plot(cones ~ dbh, data = fir, type = "n", main = "wave")
points(cones ~ dbh, data = subset(fir, wave == "w"))
for (i in seq(along = dbh.vals)) {
fit.vals.wave[i] <- a.w.mle * dbh.vals[i] ^ b.w.mle
}
lines(fit.vals.wave ~ dbh.vals, col = "blue")
plot(cones ~ dbh, data = fir, type = "n", main = "non-wave")
points(cones ~ dbh, data = subset(fir, wave == "n"))
for (i in seq(along = dbh.vals)) {
fit.vals.non[i] <- a.n.mle * dbh.vals[i] ^ b.n.mle
}
lines(fit.vals.non ~ dbh.vals, col = "red")
(lrt.stat <- 2 * (fir.reduced$value - fir.full$value))  # compute the likelihood ratio test statistic
(lrt.pvalue <- pchisq(q = lrt.stat, df = 2, lower.tail = FALSE))  # calculate the p-vlaue
(aic.reduced <- 2 * fir.reduced$value + 2 * 3)
(aic.full    <- 2 * fir.full$value    + 2 * 5)
fir.neg.ll.pois <- function(parms, x, y){
a <- parms[1]
b <- parms[2]
my.mu <- a * x^b
ll.values <- dpois(y, lambda = my.mu, log = TRUE)
-1 * sum(ll.values)
}
(fir.pois <- optim(f   = fir.neg.ll.pois,
par = c(a = 1, b = 1),
x   = fir$dbh,
y   = fir$cones))
a.mle.pois <- fir.pois$par[1]
b.mle.pois <- fir.pois$par[2]
fit.vals.pois <- double(length = length(dbh.vals))
for (i in seq(along = dbh.vals)) {
fit.vals.pois[i] <- a.mle.pois * dbh.vals[i] ^ b.mle.pois
}
par(mfrow = c(1, 1))
with(fir, plot(cones ~ dbh))
lines(fit.vals ~ dbh.vals, col = "blue")
lines(fit.vals.pois ~ dbh.vals, col = "red")
# calculate AIC
(aic.reduced.pois <- 2 * fir.pois$value + 2 * 2)
# LRT of Poisson model vs NegBin model
(lrt.stat <- 2 * (fir.pois$value - fir.reduced$value))
(lrt.pvalue <- pchisq(q = lrt.stat, df = 1, lower.tail = FALSE))
require(emdbook)
data("FirDBHFec")
fir <- FirDBHFec
rm(FirDBHFec)
names(fir)
fir <- fir[, c("WAVE_NON", "DBH", "TOTCONES")]
names(fir) <- c("wave", "dbh", "cones")
summary(fir)
?anova
library(bbmle)
?bbmle::mle2
library(emdbook)
data("ReedfrogFuncresp")
frog <- ReedfrogFuncresp
rm(ReedfrogFuncresp)
frog.neg.ll <- function(params){
a <- params[1]
h <- params[2]
prob.vals <- a / (1 + a * h * frog$Initial)
ll.vals <- dbinom(frog$Killed, size = frog$Initial, prob = prob.vals, log = TRUE)
-1 * sum(ll.vals)
}
frog.mle <- optim(par = c(0.5, 1/80),
fn  = frog.neg.ll)
a.mle <- frog.mle$par[1]
h.mle <- frog.mle$par[2]
a.vals <- seq(from = 0.3, to = 0.75, by = 0.01)
h.vals <- seq(from = 0.001, to = 0.03, by = 0.001)
ll.vals <- matrix(nrow = length(a.vals), ncol = length(h.vals))
for (i.a in 1:length(a.vals)) {
for(i.h in 1:length(h.vals)) {
ll.vals[i.a, i.h] <- frog.neg.ll(c(a.vals[i.a], h.vals[i.h]))
}
}
contour(x = a.vals, y = h.vals, z = ll.vals, nlevels = 100,
xlab = "a", ylab = "h")
points(x = a.mle, y = h.mle, col = "red", pch = 16)
frog.neg.ll(c(a.mle, h.mle))
(cutoff.ll <- frog.neg.ll(c(a.mle, h.mle)) +
(1 / 2) * qchisq(.95, df = 2))
contour(x = a.vals, y = h.vals, z = ll.vals,
levels = cutoff.ll,
add = TRUE, col = "red", lwd = 2)
slice_a <- function(a) frog.neg.ll(c(a, h.mle))
profile.ll <- function(my.a) {
# Calculate the minimum log likelihood value for a given value of a, the attack rate
my.ll <- function(h) frog.neg.ll(c(my.a, h))
my.profile <- optimize(f = my.ll,
interval = c(0, 0.03),
maximum = FALSE)
return(my.profile$objective)
}
debugonce(profile.ll)
profile.ll(0.6)
my.profile
getwd()
setwd("C:/Users/krgross/Documents/GitHub/bma590-course-notes/")
bookdown::preview_chapter("02-LikelihoodConfideceRegions.Rmd", "bookdown::gitbook")
bookdown::preview_chapter("02-LikelihoodConfideceRegions.Rmd", "bookdown::gitbook")
bookdown::preview_chapter("02-LikelihoodConfideceRegions.Rmd", "bookdown::gitbook")
bookdown::preview_chapter("02-LikelihoodConfideceRegions.Rmd", "bookdown::gitbook")
setwd("C:/Users/krgross/Documents/GitHub/bma590-course-notes/")
bookdown::preview_chapter("02-LikelihoodConfideceRegions.Rmd", "bookdown::gitbook")
bookdown::preview_chapter("02-LikelihoodConfideceRegions.Rmd", "bookdown::gitbook")
bookdown::preview_chapter("02-LikelihoodConfideceRegions.Rmd", "bookdown::gitbook")
